{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[previous file - EDA](2022-03-31_train-test_EDA.ipynb)\n",
    "\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import filterwarnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from lib.model_related import *\n",
    "\n",
    "sns.set()\n",
    "filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115367, 30), (34686, 28))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_parquet(\"data/2022-04-08_train_pre-model.parquet\")\n",
    "test_raw = pd.read_parquet(\"data/2022-04-08_test_pre-model.parquet\")\n",
    "\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_dict = {\n",
    "    \"2020-10-20\": 77.9241,\n",
    "    \"2020-10-19\": 77.9644,\n",
    "    \"2020-10-21\": 77.7780,\n",
    "    \"2020-10-25\": 76.4667,\n",
    "    \"2020-10-24\": 76.4667,\n",
    "    \"2020-10-26\": 76.4667,\n",
    "    \"2020-09-09\": 75.9645,\n",
    "    \"2021-09-27\": 73.0081,\n",
    "    \"2021-09-30\": 72.7608,\n",
    "    \"2021-09-26\": 73.0081,\n",
    "    \"2021-09-28\": 72.6613,\n",
    "    \"2021-09-29\": 72.5083,\n",
    "    \"2021-10-01\": 72.6642,\n",
    "}\n",
    "\n",
    "\n",
    "def submit(hold_out: pd.DataFrame, model, name=\"submission\"):\n",
    "    preds = model.predict(hold_out)\n",
    "    submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "    submission[\"price\"] = preds\n",
    "    submission.to_csv(f\"{name}.csv\", index=False)\n",
    "    \n",
    "    \n",
    "def submit_log(hold_out: pd.DataFrame, model, name=\"submission\"):\n",
    "    preds = model.predict(hold_out)\n",
    "    submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "    submission[\"price\"] = np.exp(preds)\n",
    "    submission.to_csv(f\"{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158409758714.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[\"price\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw[\"train/test\"] = \"train\"\n",
    "test_raw[\"train/test\"] = \"test\"\n",
    "\n",
    "data = train_raw.append(test_raw)\n",
    "data[\"ptc\"].fillna(\"Оригинал\", inplace=True)\n",
    "\n",
    "data[data.select_dtypes(\"object\").columns.tolist()] = data[\n",
    "    data.select_dtypes(\"object\").columns.tolist()\n",
    "].astype(str)\n",
    "\n",
    "for col in set(data.select_dtypes(exclude=(\"object\")).columns) - {\"price\"}:\n",
    "    data[col] = (\n",
    "        RobustScaler().fit_transform(data[col].values.reshape(-1, 1)).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "for col in [\"model_name\"]:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col].astype(\"str\"))\n",
    "\n",
    "data = pd.get_dummies(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"vehicle_transmission\",\n",
    "        \"vendor\",\n",
    "        \"brand\",\n",
    "        \"fuel_type\",\n",
    "        \"body_type\",\n",
    "        \"color\",\n",
    "        \"ptc\",\n",
    "        \"drive\",\n",
    "        \"wheel\",\n",
    "        \"age_cat\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "train = data.loc[data[\"train/test\"] == \"train\"]\n",
    "\n",
    "train_jane = train.loc[train[\"sample\"] == \"jane\"]\n",
    "train_sokolov = train.loc[train[\"sample\"] == \"sokolov\"]\n",
    "train_jane[\"price\"] = train_jane[\"price\"] * 0.86\n",
    "train = train_jane.append(train_sokolov)\n",
    "\n",
    "train.drop(columns=[\"sample\", \"description\", \"train/test\"], inplace=True)\n",
    "test = data.loc[data[\"train/test\"] == \"test\"].drop(\n",
    "    columns=[\"sample\", \"description\", \"train/test\", \"price\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151033359642.84"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"price\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86525, 112), (86525,), (28842, 112), (28842,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop(columns=\"price\"), train[\"price\"], random_state = 42, shuffle=True)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "knn = KNeighborsRegressor().fit(X_train, y_train)\n",
    "lightgbm = LGBMRegressor(random_state=42, silent=True).fit(X_train, y_train)\n",
    "catboost = CatBoostRegressor(random_state=42, silent=True).fit(X_train, y_train)\n",
    "rf = RandomForestRegressor(random_state=42).fit(X_train, y_train)\n",
    "rf_log = RandomForestRegressor(random_state=42).fit(X_train, np.log(y_train))\n",
    "etr = ExtraTreesRegressor(random_state=42).fit(X_train, y_train)\n",
    "etr_log = ExtraTreesRegressor(random_state=42).fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.7946185682561607\n",
      "knn 0.16951330279094057\n",
      "lightgbm 0.19102466397466208\n",
      "catboost 0.1584574973807607\n",
      "rf 0.13804863667174702\n"
     ]
    }
   ],
   "source": [
    "print(\"lr\", mean_absolute_percentage_error(y_valid, lr.predict(X_valid)))\n",
    "print(\"knn\", mean_absolute_percentage_error(y_valid, knn.predict(X_valid)))\n",
    "print(\"lightgbm\", mean_absolute_percentage_error(y_valid, lightgbm.predict(X_valid)))\n",
    "print(\"catboost\", mean_absolute_percentage_error(y_valid, catboost.predict(X_valid)))\n",
    "print(\"rf\", mean_absolute_percentage_error(y_valid, rf.predict(X_valid)))\n",
    "print(\"rf_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_log.predict(X_valid))))\n",
    "print(\"etr\", mean_absolute_percentage_error(y_valid, etr.predict(X_valid)))\n",
    "print(\"etr_log\", mean_absolute_percentage_error(y_valid, np.exp(etr.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dumb model submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(test, lr, \"lr\")\n",
    "submit(test, knn, \"knn\")\n",
    "submit(test, lightgbm, \"lightgbm\")\n",
    "submit(test, catboost, \"catboost\")\n",
    "submit(test, rf, \"rf\")\n",
    "submit(test, etr, \"etr\")\n",
    "submit_log(test, rf_log, \"rf_log\")\n",
    "submit_log(test, etr_log, \"etr_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(test, etr, \"etr\")\n",
    "submit_log(test, etr_log, \"etr_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:35:33,204]\u001b[0m Using an existing study with name 'LGBMClassifier' instead of creating a new one.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:35:47,095]\u001b[0m Trial 5 finished with value: -0.20253670583254396 and parameters: {'learning_rate': 0.07992724445501892, 'lambda_l1': 1.8270468476213303e-05, 'lambda_l2': 0.012791850966944924, 'num_leaves': 28, 'feature_fraction': 0.7698606143353843, 'bagging_fraction': 0.8695690383435876, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 5 with value: -0.20253670583254396.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:35:59,590]\u001b[0m Trial 6 finished with value: -0.257565168367874 and parameters: {'learning_rate': 0.744263685304623, 'lambda_l1': 7.552664420954056e-07, 'lambda_l2': 1.9963207632140944e-05, 'num_leaves': 201, 'feature_fraction': 0.7340966128567723, 'bagging_fraction': 0.6079090066839168, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 5 with value: -0.20253670583254396.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:08,280]\u001b[0m Trial 7 finished with value: -0.1745456552518454 and parameters: {'learning_rate': 0.4216546930140595, 'lambda_l1': 5.529044942764546e-08, 'lambda_l2': 0.49107163604631077, 'num_leaves': 142, 'feature_fraction': 0.5426396065593337, 'bagging_fraction': 0.6354145080468188, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 7 with value: -0.1745456552518454.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:18,834]\u001b[0m Trial 8 finished with value: -0.2432717613049581 and parameters: {'learning_rate': 0.7172956964597691, 'lambda_l1': 5.858478690290897e-06, 'lambda_l2': 3.9449322532268776e-08, 'num_leaves': 154, 'feature_fraction': 0.679286165875125, 'bagging_fraction': 0.6779233529792716, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 7 with value: -0.1745456552518454.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:28,581]\u001b[0m Trial 9 finished with value: -0.1567960005144171 and parameters: {'learning_rate': 0.24273738931459424, 'lambda_l1': 0.0007127314011370048, 'lambda_l2': 1.4991431139899208e-08, 'num_leaves': 129, 'feature_fraction': 0.716472706585253, 'bagging_fraction': 0.9079273070338828, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:38,610]\u001b[0m Trial 10 finished with value: -0.3571169344261295 and parameters: {'learning_rate': 0.9494423379774705, 'lambda_l1': 8.976874193475037e-05, 'lambda_l2': 0.00024184845376432643, 'num_leaves': 160, 'feature_fraction': 0.6342281343794924, 'bagging_fraction': 0.52462564650187, 'bagging_freq': 5, 'min_child_samples': 74}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:50,387]\u001b[0m Trial 11 finished with value: -0.22698765690534695 and parameters: {'learning_rate': 0.773164422222387, 'lambda_l1': 1.8437884236649082, 'lambda_l2': 5.646369546324295e-07, 'num_leaves': 225, 'feature_fraction': 0.6137958863887523, 'bagging_fraction': 0.7728914806928449, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:37:03,343]\u001b[0m Trial 12 finished with value: -0.25967795465332394 and parameters: {'learning_rate': 0.02716689002528746, 'lambda_l1': 0.655717669029221, 'lambda_l2': 3.8521960471096605e-07, 'num_leaves': 225, 'feature_fraction': 0.7442760753734905, 'bagging_fraction': 0.4972661166651129, 'bagging_freq': 2, 'min_child_samples': 78}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:37:13,613]\u001b[0m Trial 13 finished with value: -0.15895263105959045 and parameters: {'learning_rate': 0.25542847231451854, 'lambda_l1': 5.5278340137009336e-08, 'lambda_l2': 5.616679588596495e-07, 'num_leaves': 112, 'feature_fraction': 0.7415789372960532, 'bagging_fraction': 0.9710703037180636, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:37:24,776]\u001b[0m Trial 14 finished with value: -0.25642212193797126 and parameters: {'learning_rate': 0.9889916200650344, 'lambda_l1': 1.31641269168062e-07, 'lambda_l2': 0.001308364765353021, 'num_leaves': 181, 'feature_fraction': 0.814929774720756, 'bagging_fraction': 0.8175936493895224, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mape\",\n",
    "        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.001, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    gbm = LGBMRegressor(**param, silent=True)\n",
    "    cv_roc_auc = cross_val_score(gbm, X_train, y_train, cv=8, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///LGBMRegressor.db\",\n",
    "    study_name=\"LGBMRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, timeout=600, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9079273070338828,\n",
       " 'bagging_freq': 4,\n",
       " 'feature_fraction': 0.716472706585253,\n",
       " 'lambda_l1': 0.0007127314011370048,\n",
       " 'lambda_l2': 1.4991431139899208e-08,\n",
       " 'learning_rate': 0.24273738931459424,\n",
       " 'min_child_samples': 27,\n",
       " 'num_leaves': 129}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "lightgbm_optuned 0.1562352982059385\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned = LGBMRegressor(\n",
    "    **{\n",
    "        \"bagging_fraction\": 0.9079273070338828,\n",
    "        \"bagging_freq\": 4,\n",
    "        \"feature_fraction\": 0.716472706585253,\n",
    "        \"lambda_l1\": 0.0007127314011370048,\n",
    "        \"lambda_l2\": 1.4991431139899208e-08,\n",
    "        \"learning_rate\": 0.24273738931459424,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"num_leaves\": 129,\n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True,\n",
    "    }\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"lightgbm_optuned\", mean_absolute_percentage_error(y_valid, lightgbm_optuned.predict(X_valid)))\n",
    "submit(test, lightgbm_optuned, \"lightgbm_optuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7849386830734889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849386830734889\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6405456215002115e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6405456215002115e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.999471799816821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.999471799816821\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9256724979441087, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9256724979441087\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "lightgbm_optuned_1899_log 0.1266083430966481\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned_1899 = LGBMRegressor(\n",
    "    **{\n",
    "        'learning_rate': 0.2200394016092361, \n",
    "        'lambda_l1': 3.6405456215002115e-08, \n",
    "        'lambda_l2': 3.9256724979441087, \n",
    "        'num_leaves': 251, \n",
    "        'feature_fraction': 0.7849386830734889, \n",
    "        'bagging_fraction': 0.999471799816821, \n",
    "        'bagging_freq': 7, \n",
    "        'min_child_samples': 5, \n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))\n",
    "\n",
    "print(\"lightgbm_optuned_1899_log\", mean_absolute_percentage_error(y_valid, np.exp(lightgbm_optuned_1899.predict(X_valid))))\n",
    "submit_log(test, lightgbm_optuned_1899, \"lightgbm_optuned_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-13 18:13:06,186]\u001b[0m Using an existing study with name 'KNNRegressor' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:23:22,123]\u001b[0m Trial 47 finished with value: -0.1642623637534808 and parameters: {'n_neighbors': 7, 'leaf_size': 38, 'p': 2, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 44 with value: -0.15464020043822252.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:33:32,685]\u001b[0m Trial 48 finished with value: -0.1582071567694789 and parameters: {'n_neighbors': 8, 'leaf_size': 45, 'p': 2, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 44 with value: -0.15464020043822252.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        'n_neighbors': trial.suggest_int(\"n_neighbors\", 1, 30),\n",
    "        'leaf_size': trial.suggest_int(\"leaf_size\", 1, 50),\n",
    "        'p': trial.suggest_int(\"p\", 1, 2),\n",
    "        'weights': trial.suggest_categorical(\"weights\", ['uniform', 'distance']),\n",
    "        'metric': trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski'])\n",
    "    }\n",
    "\n",
    "    knn = KNeighborsRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(knn, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///KNNRegressor.db\",\n",
    "    study_name=\"KNNRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 41,\n",
       " 'metric': 'manhattan',\n",
       " 'n_neighbors': 8,\n",
       " 'p': 2,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_optuned_32 0.14258679506496774\n"
     ]
    }
   ],
   "source": [
    "knn_optuned_32 = KNeighborsRegressor(\n",
    "    **{\n",
    "        'n_neighbors': 9, \n",
    "        'leaf_size': 41, \n",
    "        'p': 1, \n",
    "        'weights': 'distance', \n",
    "        'metric': 'manhattan'\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))\n",
    "\n",
    "print(\"knn_optuned_32\", mean_absolute_percentage_error(y_valid, np.exp(knn_optuned_32.predict(X_valid))))\n",
    "submit_log(test, knn_optuned_32, \"knn_optuned_32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-13 18:46:09,425]\u001b[0m Using an existing study with name 'RFRRegressor' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:46:22,263]\u001b[0m Trial 7 finished with value: -0.2503358825689884 and parameters: {'n_estimators': 209, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_samples': 0.6170731668968928, 'max_features': 'log2'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:46:41,167]\u001b[0m Trial 8 finished with value: -0.20956902989733972 and parameters: {'n_estimators': 239, 'min_samples_split': 8, 'min_samples_leaf': 11, 'max_samples': 0.6960737412613612, 'max_features': 'sqrt'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:47:20,333]\u001b[0m Trial 9 finished with value: -0.18754078091628576 and parameters: {'n_estimators': 472, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9109759310947507, 'max_features': 'log2'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:47:39,851]\u001b[0m Trial 10 finished with value: -0.20136877770336822 and parameters: {'n_estimators': 226, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_samples': 0.8806474785871083, 'max_features': 'sqrt'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "        'max_samples': trial.suggest_uniform('max_samples', 0.6, 0.99),\n",
    "        'max_features': trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", 'log2']),\n",
    "        'max_depth': None,\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rfr_o = RandomForestRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(rfr_o, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///RFRRegressor.db\",\n",
    "    study_name=\"RFRRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuned by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',\n",
    "    max_depth=None,\n",
    "    bootstrap=True\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_tuned_log 0.1315354887566232\n"
     ]
    }
   ],
   "source": [
    "print(\"rf_tuned_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_tuned.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-14 11:02:52,619]\u001b[0m Using an existing study with name 'ETRRegressor' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 11:20:48,809]\u001b[0m Trial 44 finished with value: -0.14031671545863925 and parameters: {'n_estimators': 950, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9666845348937461, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 11:34:15,964]\u001b[0m Trial 45 finished with value: -0.1427228867461674 and parameters: {'n_estimators': 829, 'min_samples_split': 5, 'min_samples_leaf': 3, 'max_samples': 0.9302304299278186, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 11:35:58,464]\u001b[0m Trial 46 finished with value: -0.1419002199476845 and parameters: {'n_estimators': 105, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.635460897607993, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 11:37:49,319]\u001b[0m Trial 47 finished with value: -0.2595879798664651 and parameters: {'n_estimators': 949, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_samples': 0.9891701465840957, 'max_features': 'log2'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 11:52:06,317]\u001b[0m Trial 48 finished with value: -0.14089433449138838 and parameters: {'n_estimators': 892, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_samples': 0.8745209279661367, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 11:54:01,462]\u001b[0m Trial 49 finished with value: -0.2564346569330365 and parameters: {'n_estimators': 838, 'min_samples_split': 6, 'min_samples_leaf': 9, 'max_samples': 0.8319838954462071, 'max_features': 'sqrt'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 12:06:57,752]\u001b[0m Trial 50 finished with value: -0.14007377447225552 and parameters: {'n_estimators': 790, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.8936316243274866, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 12:14:01,845]\u001b[0m Trial 51 finished with value: -0.1418942012271324 and parameters: {'n_estimators': 514, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.6878814948960403, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 12:29:42,967]\u001b[0m Trial 52 finished with value: -0.14006165637062792 and parameters: {'n_estimators': 905, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9273222953371656, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 12:47:40,915]\u001b[0m Trial 53 finished with value: -0.13996593557803097 and parameters: {'n_estimators': 969, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.8964817605165449, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 13:04:35,526]\u001b[0m Trial 54 finished with value: -0.13993890147224805 and parameters: {'n_estimators': 971, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.8941134860273983, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 13:21:08,595]\u001b[0m Trial 55 finished with value: -0.14411737619015091 and parameters: {'n_estimators': 973, 'min_samples_split': 13, 'min_samples_leaf': 2, 'max_samples': 0.9533632135517428, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 13:35:30,230]\u001b[0m Trial 56 finished with value: -0.14288362817650657 and parameters: {'n_estimators': 851, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_samples': 0.8993280215872888, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 13:51:53,694]\u001b[0m Trial 57 finished with value: -0.13991691920007593 and parameters: {'n_estimators': 932, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9237242595565909, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 14:07:47,341]\u001b[0m Trial 58 finished with value: -0.14164252624904589 and parameters: {'n_estimators': 941, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_samples': 0.9710821930047945, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 14:09:27,277]\u001b[0m Trial 59 finished with value: -0.23178395595181023 and parameters: {'n_estimators': 968, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.943032227394155, 'max_features': 'log2'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 14:24:08,068]\u001b[0m Trial 60 finished with value: -0.14536028196541806 and parameters: {'n_estimators': 913, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_samples': 0.9246431047694932, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 14:25:52,041]\u001b[0m Trial 61 finished with value: -0.2675915118546491 and parameters: {'n_estimators': 857, 'min_samples_split': 4, 'min_samples_leaf': 12, 'max_samples': 0.9766398413241889, 'max_features': 'sqrt'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 14:42:40,808]\u001b[0m Trial 62 finished with value: -0.14017129447436524 and parameters: {'n_estimators': 969, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.8693706769791172, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 14:59:21,781]\u001b[0m Trial 63 finished with value: -0.14009006601572413 and parameters: {'n_estimators': 920, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.8844757415130194, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 15:11:33,924]\u001b[0m Trial 64 finished with value: -0.14063360133180938 and parameters: {'n_estimators': 870, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9009515526203669, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 15:23:16,599]\u001b[0m Trial 65 finished with value: -0.13998077127258618 and parameters: {'n_estimators': 804, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.9192178573478638, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 15:35:48,723]\u001b[0m Trial 66 finished with value: -0.1399763649664251 and parameters: {'n_estimators': 757, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.9536007042607311, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 15:49:03,534]\u001b[0m Trial 67 finished with value: -0.1427135122862874 and parameters: {'n_estimators': 760, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_samples': 0.9474524302597436, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 16:06:19,277]\u001b[0m Trial 68 finished with value: -0.1405062642549834 and parameters: {'n_estimators': 936, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9632194482399544, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 16:14:19,468]\u001b[0m Trial 69 finished with value: -0.14034345362094555 and parameters: {'n_estimators': 442, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_samples': 0.9366670224365926, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 16:25:36,827]\u001b[0m Trial 70 finished with value: -0.14053154357074052 and parameters: {'n_estimators': 603, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.9578549054724731, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 16:27:37,153]\u001b[0m Trial 71 finished with value: -0.26052377848449654 and parameters: {'n_estimators': 981, 'min_samples_split': 4, 'min_samples_leaf': 3, 'max_samples': 0.9765902787694396, 'max_features': 'log2'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 16:41:38,164]\u001b[0m Trial 72 finished with value: -0.14000610571802471 and parameters: {'n_estimators': 717, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.9179375562603285, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 16:57:58,781]\u001b[0m Trial 73 finished with value: -0.13999356931629484 and parameters: {'n_estimators': 803, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.9174021621627724, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 17:13:28,705]\u001b[0m Trial 74 finished with value: -0.14055320359523948 and parameters: {'n_estimators': 883, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9362942284955262, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 17:30:38,170]\u001b[0m Trial 75 finished with value: -0.13996438280739043 and parameters: {'n_estimators': 823, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_samples': 0.9509987926046393, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 17:48:41,757]\u001b[0m Trial 76 finished with value: -0.13981520740869655 and parameters: {'n_estimators': 934, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9535340279440764, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 18:06:11,951]\u001b[0m Trial 77 finished with value: -0.1404155051194483 and parameters: {'n_estimators': 998, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9747288799086186, 'max_features': 'auto'}. Best is trial 25 with value: -0.1397990866734321.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 18:23:44,825]\u001b[0m Trial 78 finished with value: -0.13977216199292827 and parameters: {'n_estimators': 936, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9894458395539251, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 18:27:29,296]\u001b[0m Trial 79 finished with value: -0.18553531137162718 and parameters: {'n_estimators': 922, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9654913965074379, 'max_features': 'sqrt'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 18:43:22,190]\u001b[0m Trial 80 finished with value: -0.1398798197844739 and parameters: {'n_estimators': 883, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9879974934583681, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 18:57:35,987]\u001b[0m Trial 81 finished with value: -0.14290240052548706 and parameters: {'n_estimators': 894, 'min_samples_split': 8, 'min_samples_leaf': 3, 'max_samples': 0.9898544112626231, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 19:15:35,053]\u001b[0m Trial 82 finished with value: -0.13995458639460354 and parameters: {'n_estimators': 936, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9470641192377844, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 19:32:59,356]\u001b[0m Trial 83 finished with value: -0.1398730565925168 and parameters: {'n_estimators': 946, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9750044304475518, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 19:46:28,235]\u001b[0m Trial 84 finished with value: -0.14039242593142467 and parameters: {'n_estimators': 952, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9807134781695395, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 19:59:31,912]\u001b[0m Trial 85 finished with value: -0.13986955830763234 and parameters: {'n_estimators': 903, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9611932211448742, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 20:11:51,100]\u001b[0m Trial 86 finished with value: -0.14001935134823495 and parameters: {'n_estimators': 875, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_samples': 0.9719800205039537, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 20:24:15,814]\u001b[0m Trial 87 finished with value: -0.1403874278276798 and parameters: {'n_estimators': 897, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9801982335030409, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 20:27:57,429]\u001b[0m Trial 88 finished with value: -0.15549946330337547 and parameters: {'n_estimators': 304, 'min_samples_split': 4, 'min_samples_leaf': 8, 'max_samples': 0.9623448728964851, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 20:39:19,207]\u001b[0m Trial 89 finished with value: -0.1414789534744986 and parameters: {'n_estimators': 851, 'min_samples_split': 9, 'min_samples_leaf': 1, 'max_samples': 0.9396706887092375, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 20:40:51,930]\u001b[0m Trial 90 finished with value: -0.23159808042894203 and parameters: {'n_estimators': 920, 'min_samples_split': 5, 'min_samples_leaf': 2, 'max_samples': 0.98987150681792, 'max_features': 'log2'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 20:55:06,026]\u001b[0m Trial 91 finished with value: -0.13985129890483092 and parameters: {'n_estimators': 951, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9697700484222097, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 21:09:15,256]\u001b[0m Trial 92 finished with value: -0.13983212268300052 and parameters: {'n_estimators': 958, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9732379182059744, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 21:22:37,362]\u001b[0m Trial 93 finished with value: -0.13992113099836073 and parameters: {'n_estimators': 947, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9698029994174875, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 21:37:22,598]\u001b[0m Trial 94 finished with value: -0.13985654190715913 and parameters: {'n_estimators': 988, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9801450306717586, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 21:49:39,739]\u001b[0m Trial 95 finished with value: -0.15031900405850923 and parameters: {'n_estimators': 989, 'min_samples_split': 3, 'min_samples_leaf': 6, 'max_samples': 0.9804814631331633, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 22:02:45,415]\u001b[0m Trial 96 finished with value: -0.14047915431166666 and parameters: {'n_estimators': 957, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9578849381861805, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 22:16:29,043]\u001b[0m Trial 97 finished with value: -0.13995040671437922 and parameters: {'n_estimators': 906, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9835165196049324, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 22:19:15,325]\u001b[0m Trial 98 finished with value: -0.1632511110177325 and parameters: {'n_estimators': 980, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9670069523123377, 'max_features': 'sqrt'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 22:31:26,875]\u001b[0m Trial 99 finished with value: -0.140345724551326 and parameters: {'n_estimators': 881, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9758946186555926, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 22:46:28,814]\u001b[0m Trial 100 finished with value: -0.13989364921965766 and parameters: {'n_estimators': 998, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.957039225729881, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 22:59:45,751]\u001b[0m Trial 101 finished with value: -0.14029256525128397 and parameters: {'n_estimators': 959, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.9894015396954431, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 23:14:27,643]\u001b[0m Trial 102 finished with value: -0.13992315655631796 and parameters: {'n_estimators': 998, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9524377517646677, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 23:28:11,351]\u001b[0m Trial 103 finished with value: -0.13996138439648276 and parameters: {'n_estimators': 929, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9700306813719162, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 23:41:31,305]\u001b[0m Trial 104 finished with value: -0.1397887241400452 and parameters: {'n_estimators': 908, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9603143423919838, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-14 23:53:25,499]\u001b[0m Trial 105 finished with value: -0.14035476366284846 and parameters: {'n_estimators': 863, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9815715825634331, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 00:06:25,115]\u001b[0m Trial 106 finished with value: -0.13994254759734462 and parameters: {'n_estimators': 907, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9352461742983459, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 00:19:10,925]\u001b[0m Trial 107 finished with value: -0.140466274901039 and parameters: {'n_estimators': 945, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.9459112849432773, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 00:29:10,907]\u001b[0m Trial 108 finished with value: -0.1408476712504302 and parameters: {'n_estimators': 838, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_samples': 0.748718358491763, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 00:41:54,610]\u001b[0m Trial 109 finished with value: -0.1425651132344454 and parameters: {'n_estimators': 966, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_samples': 0.9617202060664778, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 00:44:00,156]\u001b[0m Trial 110 finished with value: -0.17630804140436288 and parameters: {'n_estimators': 917, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9732982005345303, 'max_features': 'log2'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 00:55:04,886]\u001b[0m Trial 111 finished with value: -0.1528740107033549 and parameters: {'n_estimators': 895, 'min_samples_split': 3, 'min_samples_leaf': 7, 'max_samples': 0.982697495880821, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 01:08:52,202]\u001b[0m Trial 112 finished with value: -0.13980161870788774 and parameters: {'n_estimators': 936, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9567596329036404, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 01:23:26,224]\u001b[0m Trial 113 finished with value: -0.13992958006538042 and parameters: {'n_estimators': 981, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9627474139352304, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 01:36:08,303]\u001b[0m Trial 114 finished with value: -0.1404436428335021 and parameters: {'n_estimators': 939, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.9496954676947714, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 01:50:14,223]\u001b[0m Trial 115 finished with value: -0.13992749439164023 and parameters: {'n_estimators': 961, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9720283798830606, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 02:03:43,711]\u001b[0m Trial 116 finished with value: -0.13984812738783736 and parameters: {'n_estimators': 928, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9412971166941787, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 02:17:10,105]\u001b[0m Trial 117 finished with value: -0.13994888129729158 and parameters: {'n_estimators': 931, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9274499779585562, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 02:18:40,783]\u001b[0m Trial 118 finished with value: -0.2776410328610646 and parameters: {'n_estimators': 915, 'min_samples_split': 3, 'min_samples_leaf': 14, 'max_samples': 0.9417022883413139, 'max_features': 'sqrt'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 02:29:05,775]\u001b[0m Trial 119 finished with value: -0.14207080924072743 and parameters: {'n_estimators': 982, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.6463494277158539, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 02:38:43,265]\u001b[0m Trial 120 finished with value: -0.16690485393349963 and parameters: {'n_estimators': 862, 'min_samples_split': 3, 'min_samples_leaf': 13, 'max_samples': 0.9069335952340819, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 02:52:34,377]\u001b[0m Trial 121 finished with value: -0.13989735244546217 and parameters: {'n_estimators': 953, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9326037073483654, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 03:05:03,313]\u001b[0m Trial 122 finished with value: -0.13997601763730586 and parameters: {'n_estimators': 883, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9551436487908223, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 03:18:21,849]\u001b[0m Trial 123 finished with value: -0.13990203730585885 and parameters: {'n_estimators': 906, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9665841615661245, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 03:29:25,716]\u001b[0m Trial 124 finished with value: -0.15982277454463642 and parameters: {'n_estimators': 933, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_samples': 0.9773433497692972, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 03:43:36,097]\u001b[0m Trial 125 finished with value: -0.1399240747752982 and parameters: {'n_estimators': 888, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9855542655064288, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 03:56:57,453]\u001b[0m Trial 126 finished with value: -0.14041160697365243 and parameters: {'n_estimators': 972, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_samples': 0.9597158026175081, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 04:10:16,084]\u001b[0m Trial 127 finished with value: -0.14001621402098932 and parameters: {'n_estimators': 946, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_samples': 0.9444295874312221, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 04:22:03,637]\u001b[0m Trial 128 finished with value: -0.14027858308846178 and parameters: {'n_estimators': 848, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_samples': 0.9897556505616386, 'max_features': 'auto'}. Best is trial 78 with value: -0.13977216199292827.\u001b[0m\n",
      "\u001b[32m[I 2022-04-15 04:34:11,304]\u001b[0m Trial 129 finished with value: -0.1397623392737653 and parameters: {'n_estimators': 823, 'min_samples_split': 3, 'min_samples_leaf': 1, 'max_samples': 0.9707575238413855, 'max_features': 'auto'}. Best is trial 129 with value: -0.1397623392737653.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "        'max_samples': trial.suggest_uniform('max_samples', 0.6, 0.99),\n",
    "        'max_features': trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", 'log2']),\n",
    "        'max_depth': None,\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    etr_o = ExtraTreesRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(etr_o, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///ETRRegressor.db\",\n",
    "    study_name=\"ETRRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "etr_cust = ExtraTreesRegressor(\n",
    "    n_estimators=800,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    max_depth=15,\n",
    "    bootstrap=True,\n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_cust_log 0.1376278076519815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"etr_cust_log\", mean_absolute_percentage_error(y_valid, np.exp(etr_cust.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_optuna_129 0.12431610359952552\n"
     ]
    }
   ],
   "source": [
    "etr_optuna_129 = ExtraTreesRegressor(\n",
    "    **{\n",
    "        'n_estimators': 823, \n",
    "        'min_samples_split': 3, \n",
    "        'min_samples_leaf': 1, \n",
    "        'max_samples': 0.9707575238413855, \n",
    "        'max_features': 'auto',\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42, \n",
    "        'n_jobs': -1,\n",
    "        'verbose': 0\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))\n",
    "print(\"etr_optuna_129\", mean_absolute_percentage_error(y_valid, np.exp(etr_optuna_129.predict(X_valid))))\n",
    "submit_log(test, etr_optuna_129, \"etr_optuna_129\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbgr_custom = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=12,\n",
    "    alpha=1,\n",
    "    n_estimators=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbgr_custom_log 0.1196754346388126\n"
     ]
    }
   ],
   "source": [
    "print(\"xbgr_custom_log\", mean_absolute_percentage_error(y_valid, np.exp(xbgr_custom.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_log(test, xbgr_custom, \"xbgr_custom_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.082841\n",
      "0:\tlearn: 1707761.0355068\ttotal: 7.34ms\tremaining: 7.34s\n",
      "1:\tlearn: 1591308.9956367\ttotal: 18.8ms\tremaining: 9.37s\n",
      "2:\tlearn: 1485016.6045297\ttotal: 27.9ms\tremaining: 9.26s\n",
      "3:\tlearn: 1389132.0663577\ttotal: 33.5ms\tremaining: 8.34s\n",
      "4:\tlearn: 1301083.1721720\ttotal: 39.4ms\tremaining: 7.85s\n",
      "5:\tlearn: 1222258.3138665\ttotal: 49.4ms\tremaining: 8.19s\n",
      "6:\tlearn: 1151623.2575788\ttotal: 60.6ms\tremaining: 8.59s\n",
      "7:\tlearn: 1087972.9192920\ttotal: 68ms\tremaining: 8.43s\n",
      "8:\tlearn: 1031155.5343144\ttotal: 75.5ms\tremaining: 8.32s\n",
      "9:\tlearn: 979258.6823138\ttotal: 87.1ms\tremaining: 8.62s\n",
      "10:\tlearn: 932809.8153230\ttotal: 97.4ms\tremaining: 8.75s\n",
      "11:\tlearn: 891337.1185731\ttotal: 104ms\tremaining: 8.53s\n",
      "12:\tlearn: 854549.2845555\ttotal: 115ms\tremaining: 8.75s\n",
      "13:\tlearn: 821883.9703170\ttotal: 125ms\tremaining: 8.78s\n",
      "14:\tlearn: 792350.4434531\ttotal: 131ms\tremaining: 8.58s\n",
      "15:\tlearn: 766710.8522203\ttotal: 137ms\tremaining: 8.4s\n",
      "16:\tlearn: 744290.4031460\ttotal: 147ms\tremaining: 8.52s\n",
      "17:\tlearn: 724742.0957451\ttotal: 157ms\tremaining: 8.58s\n",
      "18:\tlearn: 706692.4037712\ttotal: 163ms\tremaining: 8.43s\n",
      "19:\tlearn: 690999.1293535\ttotal: 169ms\tremaining: 8.26s\n",
      "20:\tlearn: 678075.1999889\ttotal: 180ms\tremaining: 8.4s\n",
      "21:\tlearn: 666118.7658835\ttotal: 192ms\tremaining: 8.53s\n",
      "22:\tlearn: 656446.0935742\ttotal: 200ms\tremaining: 8.5s\n",
      "23:\tlearn: 647975.6075938\ttotal: 213ms\tremaining: 8.66s\n",
      "24:\tlearn: 640145.7065022\ttotal: 224ms\tremaining: 8.73s\n",
      "25:\tlearn: 633896.4711586\ttotal: 232ms\tremaining: 8.69s\n",
      "26:\tlearn: 627724.9457684\ttotal: 243ms\tremaining: 8.76s\n",
      "27:\tlearn: 622667.1620037\ttotal: 255ms\tremaining: 8.84s\n",
      "28:\tlearn: 618316.6749124\ttotal: 264ms\tremaining: 8.84s\n",
      "29:\tlearn: 614679.0694758\ttotal: 277ms\tremaining: 8.96s\n",
      "30:\tlearn: 611456.1659712\ttotal: 290ms\tremaining: 9.07s\n",
      "31:\tlearn: 608073.7229648\ttotal: 298ms\tremaining: 9s\n",
      "32:\tlearn: 605862.4680825\ttotal: 310ms\tremaining: 9.09s\n",
      "33:\tlearn: 603197.2341765\ttotal: 323ms\tremaining: 9.17s\n",
      "34:\tlearn: 601185.1880461\ttotal: 331ms\tremaining: 9.12s\n",
      "35:\tlearn: 599254.6218741\ttotal: 344ms\tremaining: 9.2s\n",
      "36:\tlearn: 597582.0207128\ttotal: 356ms\tremaining: 9.27s\n",
      "37:\tlearn: 596394.2339303\ttotal: 365ms\tremaining: 9.24s\n",
      "38:\tlearn: 595464.6155259\ttotal: 383ms\tremaining: 9.43s\n",
      "39:\tlearn: 593817.8372398\ttotal: 404ms\tremaining: 9.7s\n",
      "40:\tlearn: 592567.2728344\ttotal: 421ms\tremaining: 9.85s\n",
      "41:\tlearn: 591858.1562677\ttotal: 434ms\tremaining: 9.9s\n",
      "42:\tlearn: 591150.5409063\ttotal: 454ms\tremaining: 10.1s\n",
      "43:\tlearn: 589905.7413134\ttotal: 468ms\tremaining: 10.2s\n",
      "44:\tlearn: 589368.9446530\ttotal: 488ms\tremaining: 10.4s\n",
      "45:\tlearn: 588365.9904203\ttotal: 502ms\tremaining: 10.4s\n",
      "46:\tlearn: 587863.3434828\ttotal: 518ms\tremaining: 10.5s\n",
      "47:\tlearn: 587482.9842910\ttotal: 533ms\tremaining: 10.6s\n",
      "48:\tlearn: 586672.1003254\ttotal: 550ms\tremaining: 10.7s\n",
      "49:\tlearn: 586342.9053082\ttotal: 565ms\tremaining: 10.7s\n",
      "50:\tlearn: 586005.9708095\ttotal: 583ms\tremaining: 10.8s\n",
      "51:\tlearn: 585740.8685774\ttotal: 599ms\tremaining: 10.9s\n",
      "52:\tlearn: 585013.2271195\ttotal: 620ms\tremaining: 11.1s\n",
      "53:\tlearn: 584718.4812970\ttotal: 639ms\tremaining: 11.2s\n",
      "54:\tlearn: 583997.8681836\ttotal: 652ms\tremaining: 11.2s\n",
      "55:\tlearn: 583434.3395654\ttotal: 664ms\tremaining: 11.2s\n",
      "56:\tlearn: 582993.9295036\ttotal: 680ms\tremaining: 11.2s\n",
      "57:\tlearn: 582817.5044718\ttotal: 690ms\tremaining: 11.2s\n",
      "58:\tlearn: 582260.8961948\ttotal: 698ms\tremaining: 11.1s\n",
      "59:\tlearn: 582017.7265508\ttotal: 712ms\tremaining: 11.2s\n",
      "60:\tlearn: 581725.4481631\ttotal: 730ms\tremaining: 11.2s\n",
      "61:\tlearn: 581064.5161028\ttotal: 744ms\tremaining: 11.3s\n",
      "62:\tlearn: 580935.2188386\ttotal: 761ms\tremaining: 11.3s\n",
      "63:\tlearn: 580363.3298322\ttotal: 776ms\tremaining: 11.3s\n",
      "64:\tlearn: 579942.0771184\ttotal: 791ms\tremaining: 11.4s\n",
      "65:\tlearn: 579839.7460124\ttotal: 805ms\tremaining: 11.4s\n",
      "66:\tlearn: 579417.1974053\ttotal: 821ms\tremaining: 11.4s\n",
      "67:\tlearn: 579288.1034855\ttotal: 833ms\tremaining: 11.4s\n",
      "68:\tlearn: 578853.1611817\ttotal: 852ms\tremaining: 11.5s\n",
      "69:\tlearn: 578233.5569761\ttotal: 861ms\tremaining: 11.4s\n",
      "70:\tlearn: 578129.1476794\ttotal: 873ms\tremaining: 11.4s\n",
      "71:\tlearn: 578040.8220263\ttotal: 886ms\tremaining: 11.4s\n",
      "72:\tlearn: 577947.4359740\ttotal: 897ms\tremaining: 11.4s\n",
      "73:\tlearn: 577874.3792402\ttotal: 911ms\tremaining: 11.4s\n",
      "74:\tlearn: 577798.3923441\ttotal: 922ms\tremaining: 11.4s\n",
      "75:\tlearn: 577462.9929015\ttotal: 934ms\tremaining: 11.4s\n",
      "76:\tlearn: 577076.3484135\ttotal: 946ms\tremaining: 11.3s\n",
      "77:\tlearn: 576955.1956198\ttotal: 954ms\tremaining: 11.3s\n",
      "78:\tlearn: 576699.9446231\ttotal: 969ms\tremaining: 11.3s\n",
      "79:\tlearn: 576626.7095964\ttotal: 985ms\tremaining: 11.3s\n",
      "80:\tlearn: 575803.5934140\ttotal: 995ms\tremaining: 11.3s\n",
      "81:\tlearn: 575711.2019290\ttotal: 1.02s\tremaining: 11.4s\n",
      "82:\tlearn: 575645.9626618\ttotal: 1.04s\tremaining: 11.5s\n",
      "83:\tlearn: 575326.5509329\ttotal: 1.05s\tremaining: 11.5s\n",
      "84:\tlearn: 575296.1876752\ttotal: 1.07s\tremaining: 11.5s\n",
      "85:\tlearn: 574869.1451908\ttotal: 1.08s\tremaining: 11.5s\n",
      "86:\tlearn: 574576.7847852\ttotal: 1.09s\tremaining: 11.4s\n",
      "87:\tlearn: 574351.3526442\ttotal: 1.1s\tremaining: 11.4s\n",
      "88:\tlearn: 573669.9427206\ttotal: 1.11s\tremaining: 11.4s\n",
      "89:\tlearn: 573613.4903643\ttotal: 1.12s\tremaining: 11.3s\n",
      "90:\tlearn: 573561.4232504\ttotal: 1.13s\tremaining: 11.3s\n",
      "91:\tlearn: 573106.3817740\ttotal: 1.14s\tremaining: 11.3s\n",
      "92:\tlearn: 572993.4698453\ttotal: 1.15s\tremaining: 11.2s\n",
      "93:\tlearn: 572892.4053610\ttotal: 1.16s\tremaining: 11.2s\n",
      "94:\tlearn: 572797.3363973\ttotal: 1.18s\tremaining: 11.2s\n",
      "95:\tlearn: 572382.7803655\ttotal: 1.18s\tremaining: 11.1s\n",
      "96:\tlearn: 571920.1749744\ttotal: 1.2s\tremaining: 11.1s\n",
      "97:\tlearn: 571680.1651560\ttotal: 1.21s\tremaining: 11.1s\n",
      "98:\tlearn: 571471.6015136\ttotal: 1.21s\tremaining: 11s\n",
      "99:\tlearn: 571437.4305755\ttotal: 1.23s\tremaining: 11.1s\n",
      "100:\tlearn: 571250.6811455\ttotal: 1.24s\tremaining: 11.1s\n",
      "101:\tlearn: 571134.8074885\ttotal: 1.25s\tremaining: 11s\n",
      "102:\tlearn: 571036.7340015\ttotal: 1.27s\tremaining: 11.1s\n",
      "103:\tlearn: 570731.5543788\ttotal: 1.28s\tremaining: 11s\n",
      "104:\tlearn: 570505.7397752\ttotal: 1.3s\tremaining: 11.1s\n",
      "105:\tlearn: 570473.9556182\ttotal: 1.31s\tremaining: 11s\n",
      "106:\tlearn: 570407.3926257\ttotal: 1.32s\tremaining: 11s\n",
      "107:\tlearn: 570356.9277656\ttotal: 1.34s\tremaining: 11.1s\n",
      "108:\tlearn: 570234.6655303\ttotal: 1.35s\tremaining: 11.1s\n",
      "109:\tlearn: 570184.3856185\ttotal: 1.37s\tremaining: 11.1s\n",
      "110:\tlearn: 569980.6735612\ttotal: 1.37s\tremaining: 11s\n",
      "111:\tlearn: 569478.8877689\ttotal: 1.38s\tremaining: 11s\n",
      "112:\tlearn: 569466.0634916\ttotal: 1.4s\tremaining: 11s\n",
      "113:\tlearn: 569110.7563831\ttotal: 1.41s\tremaining: 10.9s\n",
      "114:\tlearn: 568848.9761462\ttotal: 1.42s\tremaining: 10.9s\n",
      "115:\tlearn: 568736.9903783\ttotal: 1.43s\tremaining: 10.9s\n",
      "116:\tlearn: 568691.1200314\ttotal: 1.44s\tremaining: 10.9s\n",
      "117:\tlearn: 568573.6801096\ttotal: 1.46s\tremaining: 10.9s\n",
      "118:\tlearn: 568517.1955322\ttotal: 1.47s\tremaining: 10.9s\n",
      "119:\tlearn: 568483.3349218\ttotal: 1.48s\tremaining: 10.8s\n",
      "120:\tlearn: 568360.7691325\ttotal: 1.49s\tremaining: 10.8s\n",
      "121:\tlearn: 568276.3582029\ttotal: 1.5s\tremaining: 10.8s\n",
      "122:\tlearn: 568227.2534572\ttotal: 1.51s\tremaining: 10.8s\n",
      "123:\tlearn: 568085.4375155\ttotal: 1.53s\tremaining: 10.8s\n",
      "124:\tlearn: 568062.1675843\ttotal: 1.53s\tremaining: 10.7s\n",
      "125:\tlearn: 567864.2499375\ttotal: 1.54s\tremaining: 10.7s\n",
      "126:\tlearn: 567428.8553376\ttotal: 1.55s\tremaining: 10.7s\n",
      "127:\tlearn: 567366.3087547\ttotal: 1.56s\tremaining: 10.6s\n",
      "128:\tlearn: 567118.6563033\ttotal: 1.57s\tremaining: 10.6s\n",
      "129:\tlearn: 567067.4049017\ttotal: 1.57s\tremaining: 10.5s\n",
      "130:\tlearn: 567040.2812115\ttotal: 1.59s\tremaining: 10.5s\n",
      "131:\tlearn: 566623.3830289\ttotal: 1.59s\tremaining: 10.5s\n",
      "132:\tlearn: 566569.6713343\ttotal: 1.6s\tremaining: 10.4s\n",
      "133:\tlearn: 566514.3548411\ttotal: 1.6s\tremaining: 10.4s\n",
      "134:\tlearn: 566454.6542255\ttotal: 1.62s\tremaining: 10.4s\n",
      "135:\tlearn: 566383.9290872\ttotal: 1.63s\tremaining: 10.3s\n",
      "136:\tlearn: 566290.9367772\ttotal: 1.63s\tremaining: 10.3s\n",
      "137:\tlearn: 566079.4602598\ttotal: 1.65s\tremaining: 10.3s\n",
      "138:\tlearn: 565986.2799350\ttotal: 1.66s\tremaining: 10.3s\n",
      "139:\tlearn: 565921.6151774\ttotal: 1.67s\tremaining: 10.2s\n",
      "140:\tlearn: 565851.3034377\ttotal: 1.68s\tremaining: 10.2s\n",
      "141:\tlearn: 565624.3115119\ttotal: 1.69s\tremaining: 10.2s\n",
      "142:\tlearn: 565564.7608014\ttotal: 1.7s\tremaining: 10.2s\n",
      "143:\tlearn: 565228.1658117\ttotal: 1.71s\tremaining: 10.1s\n",
      "144:\tlearn: 565172.7209381\ttotal: 1.72s\tremaining: 10.1s\n",
      "145:\tlearn: 564857.4122376\ttotal: 1.72s\tremaining: 10.1s\n",
      "146:\tlearn: 564803.7752737\ttotal: 1.73s\tremaining: 10.1s\n",
      "147:\tlearn: 564725.5643339\ttotal: 1.75s\tremaining: 10.1s\n",
      "148:\tlearn: 564566.3040882\ttotal: 1.75s\tremaining: 10s\n",
      "149:\tlearn: 564210.7206582\ttotal: 1.76s\tremaining: 9.98s\n",
      "150:\tlearn: 564125.4753767\ttotal: 1.77s\tremaining: 9.98s\n",
      "151:\tlearn: 563843.6819062\ttotal: 1.78s\tremaining: 9.95s\n",
      "152:\tlearn: 563642.4780509\ttotal: 1.79s\tremaining: 9.91s\n",
      "153:\tlearn: 563411.6330742\ttotal: 1.8s\tremaining: 9.87s\n",
      "154:\tlearn: 563015.0543511\ttotal: 1.8s\tremaining: 9.84s\n",
      "155:\tlearn: 562811.2675655\ttotal: 1.81s\tremaining: 9.82s\n",
      "156:\tlearn: 562608.9266563\ttotal: 1.82s\tremaining: 9.78s\n",
      "157:\tlearn: 562405.6473028\ttotal: 1.83s\tremaining: 9.76s\n",
      "158:\tlearn: 562115.0510021\ttotal: 1.84s\tremaining: 9.75s\n",
      "159:\tlearn: 561896.4847302\ttotal: 1.85s\tremaining: 9.71s\n",
      "160:\tlearn: 561551.2652601\ttotal: 1.86s\tremaining: 9.68s\n",
      "161:\tlearn: 561514.7077302\ttotal: 1.86s\tremaining: 9.64s\n",
      "162:\tlearn: 561310.8827170\ttotal: 1.88s\tremaining: 9.64s\n",
      "163:\tlearn: 561026.1990209\ttotal: 1.88s\tremaining: 9.6s\n",
      "164:\tlearn: 560882.3911256\ttotal: 1.89s\tremaining: 9.57s\n",
      "165:\tlearn: 560817.9686000\ttotal: 1.9s\tremaining: 9.56s\n",
      "166:\tlearn: 560614.6443414\ttotal: 1.91s\tremaining: 9.54s\n",
      "167:\tlearn: 560429.8919755\ttotal: 1.92s\tremaining: 9.51s\n",
      "168:\tlearn: 560257.4262769\ttotal: 1.93s\tremaining: 9.47s\n",
      "169:\tlearn: 560114.4987214\ttotal: 1.94s\tremaining: 9.47s\n",
      "170:\tlearn: 560057.3117608\ttotal: 1.95s\tremaining: 9.44s\n",
      "171:\tlearn: 559866.1294250\ttotal: 1.95s\tremaining: 9.4s\n",
      "172:\tlearn: 559809.3512687\ttotal: 1.96s\tremaining: 9.38s\n",
      "173:\tlearn: 559617.1522802\ttotal: 1.97s\tremaining: 9.37s\n",
      "174:\tlearn: 559571.9180149\ttotal: 1.99s\tremaining: 9.36s\n",
      "175:\tlearn: 559412.2618666\ttotal: 1.99s\tremaining: 9.32s\n",
      "176:\tlearn: 559302.1197847\ttotal: 2s\tremaining: 9.32s\n",
      "177:\tlearn: 558995.3935550\ttotal: 2.01s\tremaining: 9.28s\n",
      "178:\tlearn: 558865.6038784\ttotal: 2.02s\tremaining: 9.25s\n",
      "179:\tlearn: 558687.9031820\ttotal: 2.02s\tremaining: 9.22s\n",
      "180:\tlearn: 558642.9442527\ttotal: 2.04s\tremaining: 9.24s\n",
      "181:\tlearn: 558501.9322921\ttotal: 2.05s\tremaining: 9.21s\n",
      "182:\tlearn: 558282.9212186\ttotal: 2.06s\tremaining: 9.19s\n",
      "183:\tlearn: 558252.7943801\ttotal: 2.07s\tremaining: 9.18s\n",
      "184:\tlearn: 558195.3025903\ttotal: 2.08s\tremaining: 9.15s\n",
      "185:\tlearn: 558145.1479888\ttotal: 2.08s\tremaining: 9.12s\n",
      "186:\tlearn: 557953.2312390\ttotal: 2.09s\tremaining: 9.09s\n",
      "187:\tlearn: 557811.9574720\ttotal: 2.1s\tremaining: 9.08s\n",
      "188:\tlearn: 557620.2015681\ttotal: 2.11s\tremaining: 9.05s\n",
      "189:\tlearn: 557495.4363739\ttotal: 2.12s\tremaining: 9.02s\n",
      "190:\tlearn: 557324.8719059\ttotal: 2.13s\tremaining: 9.01s\n",
      "191:\tlearn: 557181.0556276\ttotal: 2.13s\tremaining: 8.99s\n",
      "192:\tlearn: 557132.3855578\ttotal: 2.14s\tremaining: 8.96s\n",
      "193:\tlearn: 557018.1771092\ttotal: 2.15s\tremaining: 8.93s\n",
      "194:\tlearn: 556991.6036212\ttotal: 2.16s\tremaining: 8.92s\n",
      "195:\tlearn: 556833.5241229\ttotal: 2.17s\tremaining: 8.9s\n",
      "196:\tlearn: 556772.2655777\ttotal: 2.18s\tremaining: 8.88s\n",
      "197:\tlearn: 556696.0938832\ttotal: 2.19s\tremaining: 8.85s\n",
      "198:\tlearn: 556583.8641088\ttotal: 2.2s\tremaining: 8.85s\n",
      "199:\tlearn: 556270.2515045\ttotal: 2.21s\tremaining: 8.84s\n",
      "200:\tlearn: 556090.2964282\ttotal: 2.22s\tremaining: 8.82s\n",
      "201:\tlearn: 555962.8610817\ttotal: 2.23s\tremaining: 8.81s\n",
      "202:\tlearn: 555895.1435750\ttotal: 2.24s\tremaining: 8.8s\n",
      "203:\tlearn: 555681.8018169\ttotal: 2.26s\tremaining: 8.82s\n",
      "204:\tlearn: 555651.8576829\ttotal: 2.27s\tremaining: 8.82s\n",
      "205:\tlearn: 555604.6104375\ttotal: 2.29s\tremaining: 8.81s\n",
      "206:\tlearn: 555532.5690814\ttotal: 2.3s\tremaining: 8.8s\n",
      "207:\tlearn: 555508.4613637\ttotal: 2.3s\tremaining: 8.78s\n",
      "208:\tlearn: 555331.8668196\ttotal: 2.31s\tremaining: 8.75s\n",
      "209:\tlearn: 555193.9201394\ttotal: 2.32s\tremaining: 8.73s\n",
      "210:\tlearn: 555006.0826205\ttotal: 2.33s\tremaining: 8.73s\n",
      "211:\tlearn: 554928.1551242\ttotal: 2.34s\tremaining: 8.71s\n",
      "212:\tlearn: 554743.4691701\ttotal: 2.35s\tremaining: 8.69s\n",
      "213:\tlearn: 554691.0756652\ttotal: 2.36s\tremaining: 8.68s\n",
      "214:\tlearn: 554553.2595626\ttotal: 2.37s\tremaining: 8.66s\n",
      "215:\tlearn: 554518.2188789\ttotal: 2.38s\tremaining: 8.66s\n",
      "216:\tlearn: 554467.3391535\ttotal: 2.4s\tremaining: 8.65s\n",
      "217:\tlearn: 554358.4079945\ttotal: 2.41s\tremaining: 8.63s\n",
      "218:\tlearn: 554337.1357208\ttotal: 2.42s\tremaining: 8.63s\n",
      "219:\tlearn: 554283.7056604\ttotal: 2.43s\tremaining: 8.62s\n",
      "220:\tlearn: 554156.3486563\ttotal: 2.44s\tremaining: 8.59s\n",
      "221:\tlearn: 553987.9346553\ttotal: 2.44s\tremaining: 8.57s\n",
      "222:\tlearn: 553950.5192523\ttotal: 2.46s\tremaining: 8.56s\n",
      "223:\tlearn: 553742.5753085\ttotal: 2.46s\tremaining: 8.54s\n",
      "224:\tlearn: 553658.0963057\ttotal: 2.47s\tremaining: 8.51s\n",
      "225:\tlearn: 553608.0254306\ttotal: 2.48s\tremaining: 8.5s\n",
      "226:\tlearn: 553447.5075313\ttotal: 2.5s\tremaining: 8.5s\n",
      "227:\tlearn: 553425.4519415\ttotal: 2.5s\tremaining: 8.48s\n",
      "228:\tlearn: 553336.5927709\ttotal: 2.51s\tremaining: 8.45s\n",
      "229:\tlearn: 553251.6353318\ttotal: 2.52s\tremaining: 8.45s\n",
      "230:\tlearn: 553231.7026469\ttotal: 2.53s\tremaining: 8.43s\n",
      "231:\tlearn: 553208.7347058\ttotal: 2.54s\tremaining: 8.41s\n",
      "232:\tlearn: 553152.8744836\ttotal: 2.56s\tremaining: 8.42s\n",
      "233:\tlearn: 553107.7066654\ttotal: 2.56s\tremaining: 8.4s\n",
      "234:\tlearn: 553064.4766869\ttotal: 2.57s\tremaining: 8.37s\n",
      "235:\tlearn: 553027.8665228\ttotal: 2.59s\tremaining: 8.37s\n",
      "236:\tlearn: 552959.7299239\ttotal: 2.6s\tremaining: 8.37s\n",
      "237:\tlearn: 552843.5907204\ttotal: 2.6s\tremaining: 8.34s\n",
      "238:\tlearn: 552739.4982200\ttotal: 2.62s\tremaining: 8.34s\n",
      "239:\tlearn: 552597.9680809\ttotal: 2.63s\tremaining: 8.31s\n",
      "240:\tlearn: 552510.3235357\ttotal: 2.63s\tremaining: 8.29s\n",
      "241:\tlearn: 552484.5510454\ttotal: 2.65s\tremaining: 8.29s\n",
      "242:\tlearn: 552438.8375228\ttotal: 2.66s\tremaining: 8.29s\n",
      "243:\tlearn: 552372.6827266\ttotal: 2.67s\tremaining: 8.27s\n",
      "244:\tlearn: 552357.1090272\ttotal: 2.68s\tremaining: 8.27s\n",
      "245:\tlearn: 552200.4460055\ttotal: 2.69s\tremaining: 8.25s\n",
      "246:\tlearn: 552008.4422250\ttotal: 2.7s\tremaining: 8.22s\n",
      "247:\tlearn: 551957.2501427\ttotal: 2.71s\tremaining: 8.22s\n",
      "248:\tlearn: 551781.0536568\ttotal: 2.72s\tremaining: 8.21s\n",
      "249:\tlearn: 551722.8837691\ttotal: 2.73s\tremaining: 8.19s\n",
      "250:\tlearn: 551645.3656186\ttotal: 2.74s\tremaining: 8.17s\n",
      "251:\tlearn: 551540.8802225\ttotal: 2.75s\tremaining: 8.15s\n",
      "252:\tlearn: 551401.1125020\ttotal: 2.75s\tremaining: 8.14s\n",
      "253:\tlearn: 551289.8598244\ttotal: 2.76s\tremaining: 8.11s\n",
      "254:\tlearn: 551252.2881470\ttotal: 2.77s\tremaining: 8.1s\n",
      "255:\tlearn: 551188.9990109\ttotal: 2.78s\tremaining: 8.09s\n",
      "256:\tlearn: 551046.7753880\ttotal: 2.79s\tremaining: 8.06s\n",
      "257:\tlearn: 551006.0711514\ttotal: 2.79s\tremaining: 8.04s\n",
      "258:\tlearn: 550883.3981483\ttotal: 2.8s\tremaining: 8.02s\n",
      "259:\tlearn: 550760.3834095\ttotal: 2.81s\tremaining: 8.01s\n",
      "260:\tlearn: 550590.3126585\ttotal: 2.82s\tremaining: 7.99s\n",
      "261:\tlearn: 550495.1064472\ttotal: 2.83s\tremaining: 7.96s\n",
      "262:\tlearn: 550460.8679982\ttotal: 2.84s\tremaining: 7.95s\n",
      "263:\tlearn: 550428.7603618\ttotal: 2.85s\tremaining: 7.95s\n",
      "264:\tlearn: 550360.1525133\ttotal: 2.86s\tremaining: 7.92s\n",
      "265:\tlearn: 550285.5881843\ttotal: 2.86s\tremaining: 7.91s\n",
      "266:\tlearn: 550177.8912975\ttotal: 2.88s\tremaining: 7.9s\n",
      "267:\tlearn: 550160.3787204\ttotal: 2.88s\tremaining: 7.88s\n",
      "268:\tlearn: 550050.0935547\ttotal: 2.89s\tremaining: 7.85s\n",
      "269:\tlearn: 549964.4488865\ttotal: 2.9s\tremaining: 7.84s\n",
      "270:\tlearn: 549903.8285369\ttotal: 2.92s\tremaining: 7.85s\n",
      "271:\tlearn: 549886.1525026\ttotal: 2.92s\tremaining: 7.83s\n",
      "272:\tlearn: 549846.0858058\ttotal: 2.94s\tremaining: 7.83s\n",
      "273:\tlearn: 549797.2189264\ttotal: 2.95s\tremaining: 7.82s\n",
      "274:\tlearn: 549723.6567892\ttotal: 2.96s\tremaining: 7.8s\n",
      "275:\tlearn: 549609.5619078\ttotal: 2.97s\tremaining: 7.79s\n",
      "276:\tlearn: 549576.1346785\ttotal: 2.98s\tremaining: 7.78s\n",
      "277:\tlearn: 549456.7584253\ttotal: 2.99s\tremaining: 7.76s\n",
      "278:\tlearn: 549396.2016571\ttotal: 3s\tremaining: 7.75s\n",
      "279:\tlearn: 549350.7995796\ttotal: 3.02s\tremaining: 7.75s\n",
      "280:\tlearn: 549332.4556915\ttotal: 3.02s\tremaining: 7.74s\n",
      "281:\tlearn: 549279.7568224\ttotal: 3.04s\tremaining: 7.74s\n",
      "282:\tlearn: 549223.0956332\ttotal: 3.05s\tremaining: 7.72s\n",
      "283:\tlearn: 549185.3414669\ttotal: 3.06s\tremaining: 7.71s\n",
      "284:\tlearn: 549080.1978363\ttotal: 3.07s\tremaining: 7.7s\n",
      "285:\tlearn: 549010.6255410\ttotal: 3.08s\tremaining: 7.68s\n",
      "286:\tlearn: 548998.9564636\ttotal: 3.08s\tremaining: 7.67s\n",
      "287:\tlearn: 548972.5858636\ttotal: 3.1s\tremaining: 7.66s\n",
      "288:\tlearn: 548955.2304136\ttotal: 3.11s\tremaining: 7.64s\n",
      "289:\tlearn: 548930.7850918\ttotal: 3.11s\tremaining: 7.62s\n",
      "290:\tlearn: 548831.1612597\ttotal: 3.12s\tremaining: 7.61s\n",
      "291:\tlearn: 548781.5410034\ttotal: 3.13s\tremaining: 7.6s\n",
      "292:\tlearn: 548744.3206110\ttotal: 3.14s\tremaining: 7.58s\n",
      "293:\tlearn: 548650.9285073\ttotal: 3.15s\tremaining: 7.56s\n",
      "294:\tlearn: 548634.4210410\ttotal: 3.16s\tremaining: 7.55s\n",
      "295:\tlearn: 548492.5772064\ttotal: 3.17s\tremaining: 7.54s\n",
      "296:\tlearn: 548409.1768300\ttotal: 3.18s\tremaining: 7.52s\n",
      "297:\tlearn: 548371.2031598\ttotal: 3.18s\tremaining: 7.5s\n",
      "298:\tlearn: 548300.2033299\ttotal: 3.19s\tremaining: 7.48s\n",
      "299:\tlearn: 548193.7722481\ttotal: 3.2s\tremaining: 7.47s\n",
      "300:\tlearn: 548064.1498064\ttotal: 3.21s\tremaining: 7.45s\n",
      "301:\tlearn: 547976.3176809\ttotal: 3.21s\tremaining: 7.43s\n",
      "302:\tlearn: 547878.7597606\ttotal: 3.23s\tremaining: 7.42s\n",
      "303:\tlearn: 547843.1128897\ttotal: 3.23s\tremaining: 7.41s\n",
      "304:\tlearn: 547810.3213424\ttotal: 3.24s\tremaining: 7.39s\n",
      "305:\tlearn: 547692.6010025\ttotal: 3.25s\tremaining: 7.37s\n",
      "306:\tlearn: 547646.4987007\ttotal: 3.26s\tremaining: 7.37s\n",
      "307:\tlearn: 547620.6141397\ttotal: 3.27s\tremaining: 7.35s\n",
      "308:\tlearn: 547536.5903816\ttotal: 3.28s\tremaining: 7.33s\n",
      "309:\tlearn: 547441.1682313\ttotal: 3.29s\tremaining: 7.33s\n",
      "310:\tlearn: 547433.3166655\ttotal: 3.3s\tremaining: 7.31s\n",
      "311:\tlearn: 547418.2194263\ttotal: 3.31s\tremaining: 7.3s\n",
      "312:\tlearn: 547355.9983527\ttotal: 3.32s\tremaining: 7.28s\n",
      "313:\tlearn: 547342.7756355\ttotal: 3.33s\tremaining: 7.28s\n",
      "314:\tlearn: 547301.0473341\ttotal: 3.34s\tremaining: 7.26s\n",
      "315:\tlearn: 547262.2170988\ttotal: 3.35s\tremaining: 7.25s\n",
      "316:\tlearn: 547188.4856194\ttotal: 3.36s\tremaining: 7.25s\n",
      "317:\tlearn: 547140.3892032\ttotal: 3.37s\tremaining: 7.23s\n",
      "318:\tlearn: 547072.1041072\ttotal: 3.38s\tremaining: 7.21s\n",
      "319:\tlearn: 547029.0713362\ttotal: 3.39s\tremaining: 7.2s\n",
      "320:\tlearn: 546936.8263603\ttotal: 3.4s\tremaining: 7.18s\n",
      "321:\tlearn: 546859.6957777\ttotal: 3.4s\tremaining: 7.16s\n",
      "322:\tlearn: 546755.3980806\ttotal: 3.41s\tremaining: 7.14s\n",
      "323:\tlearn: 546732.2832856\ttotal: 3.42s\tremaining: 7.14s\n",
      "324:\tlearn: 546627.7327271\ttotal: 3.43s\tremaining: 7.13s\n",
      "325:\tlearn: 546549.0193076\ttotal: 3.44s\tremaining: 7.11s\n",
      "326:\tlearn: 546458.1367522\ttotal: 3.44s\tremaining: 7.09s\n",
      "327:\tlearn: 546402.0885009\ttotal: 3.45s\tremaining: 7.07s\n",
      "328:\tlearn: 546339.7726092\ttotal: 3.46s\tremaining: 7.06s\n",
      "329:\tlearn: 546320.9057911\ttotal: 3.47s\tremaining: 7.04s\n",
      "330:\tlearn: 546255.3411198\ttotal: 3.48s\tremaining: 7.03s\n",
      "331:\tlearn: 546204.5514050\ttotal: 3.49s\tremaining: 7.02s\n",
      "332:\tlearn: 546168.9492908\ttotal: 3.5s\tremaining: 7s\n",
      "333:\tlearn: 546128.1691158\ttotal: 3.5s\tremaining: 6.99s\n",
      "334:\tlearn: 546107.8923256\ttotal: 3.52s\tremaining: 6.98s\n",
      "335:\tlearn: 546080.7196975\ttotal: 3.53s\tremaining: 6.97s\n",
      "336:\tlearn: 546025.3650099\ttotal: 3.53s\tremaining: 6.95s\n",
      "337:\tlearn: 545953.7333819\ttotal: 3.54s\tremaining: 6.94s\n",
      "338:\tlearn: 545908.9905759\ttotal: 3.56s\tremaining: 6.93s\n",
      "339:\tlearn: 545805.0431750\ttotal: 3.56s\tremaining: 6.91s\n",
      "340:\tlearn: 545722.8848619\ttotal: 3.57s\tremaining: 6.89s\n",
      "341:\tlearn: 545703.5112381\ttotal: 3.58s\tremaining: 6.88s\n",
      "342:\tlearn: 545692.0695717\ttotal: 3.59s\tremaining: 6.87s\n",
      "343:\tlearn: 545675.7048524\ttotal: 3.6s\tremaining: 6.86s\n",
      "344:\tlearn: 545637.1728752\ttotal: 3.6s\tremaining: 6.84s\n",
      "345:\tlearn: 545593.4123400\ttotal: 3.61s\tremaining: 6.83s\n",
      "346:\tlearn: 545581.7222330\ttotal: 3.63s\tremaining: 6.83s\n",
      "347:\tlearn: 545543.3200391\ttotal: 3.63s\tremaining: 6.81s\n",
      "348:\tlearn: 545529.8319387\ttotal: 3.65s\tremaining: 6.81s\n",
      "349:\tlearn: 545446.8241385\ttotal: 3.66s\tremaining: 6.8s\n",
      "350:\tlearn: 545373.4517575\ttotal: 3.67s\tremaining: 6.78s\n",
      "351:\tlearn: 545364.4805661\ttotal: 3.68s\tremaining: 6.77s\n",
      "352:\tlearn: 545351.0954709\ttotal: 3.69s\tremaining: 6.76s\n",
      "353:\tlearn: 545322.7058286\ttotal: 3.69s\tremaining: 6.74s\n",
      "354:\tlearn: 545304.3701663\ttotal: 3.71s\tremaining: 6.73s\n",
      "355:\tlearn: 545247.7573150\ttotal: 3.72s\tremaining: 6.72s\n",
      "356:\tlearn: 545225.8114355\ttotal: 3.72s\tremaining: 6.71s\n",
      "357:\tlearn: 545193.1547103\ttotal: 3.73s\tremaining: 6.69s\n",
      "358:\tlearn: 545149.9190496\ttotal: 3.75s\tremaining: 6.69s\n",
      "359:\tlearn: 545084.2579158\ttotal: 3.76s\tremaining: 6.68s\n",
      "360:\tlearn: 544997.7230561\ttotal: 3.76s\tremaining: 6.66s\n",
      "361:\tlearn: 544941.7809562\ttotal: 3.77s\tremaining: 6.64s\n",
      "362:\tlearn: 544864.8013158\ttotal: 3.78s\tremaining: 6.63s\n",
      "363:\tlearn: 544774.1163429\ttotal: 3.79s\tremaining: 6.62s\n",
      "364:\tlearn: 544680.5971961\ttotal: 3.79s\tremaining: 6.6s\n",
      "365:\tlearn: 544591.3145175\ttotal: 3.8s\tremaining: 6.59s\n",
      "366:\tlearn: 544582.1226634\ttotal: 3.81s\tremaining: 6.58s\n",
      "367:\tlearn: 544521.5057432\ttotal: 3.82s\tremaining: 6.56s\n",
      "368:\tlearn: 544465.7253839\ttotal: 3.83s\tremaining: 6.55s\n",
      "369:\tlearn: 544456.3245245\ttotal: 3.84s\tremaining: 6.54s\n",
      "370:\tlearn: 544444.4760575\ttotal: 3.85s\tremaining: 6.53s\n",
      "371:\tlearn: 544367.5208396\ttotal: 3.86s\tremaining: 6.51s\n",
      "372:\tlearn: 544350.2303334\ttotal: 3.87s\tremaining: 6.5s\n",
      "373:\tlearn: 544330.8921689\ttotal: 3.88s\tremaining: 6.49s\n",
      "374:\tlearn: 544280.9738697\ttotal: 3.88s\tremaining: 6.47s\n",
      "375:\tlearn: 544172.7494402\ttotal: 3.89s\tremaining: 6.46s\n",
      "376:\tlearn: 544102.8080329\ttotal: 3.9s\tremaining: 6.44s\n",
      "377:\tlearn: 544055.2995067\ttotal: 3.91s\tremaining: 6.43s\n",
      "378:\tlearn: 544023.1357394\ttotal: 3.92s\tremaining: 6.42s\n",
      "379:\tlearn: 543944.8724906\ttotal: 3.92s\tremaining: 6.4s\n",
      "380:\tlearn: 543877.7925072\ttotal: 3.93s\tremaining: 6.39s\n",
      "381:\tlearn: 543853.7746515\ttotal: 3.94s\tremaining: 6.38s\n",
      "382:\tlearn: 543798.6738957\ttotal: 3.95s\tremaining: 6.36s\n",
      "383:\tlearn: 543744.3131853\ttotal: 3.95s\tremaining: 6.34s\n",
      "384:\tlearn: 543713.4104355\ttotal: 3.96s\tremaining: 6.33s\n",
      "385:\tlearn: 543681.2829815\ttotal: 3.97s\tremaining: 6.32s\n",
      "386:\tlearn: 543613.5789062\ttotal: 3.98s\tremaining: 6.3s\n",
      "387:\tlearn: 543593.8739671\ttotal: 3.99s\tremaining: 6.29s\n",
      "388:\tlearn: 543530.2543587\ttotal: 4s\tremaining: 6.28s\n",
      "389:\tlearn: 543456.7538691\ttotal: 4s\tremaining: 6.26s\n",
      "390:\tlearn: 543389.3245331\ttotal: 4.01s\tremaining: 6.25s\n",
      "391:\tlearn: 543331.2493652\ttotal: 4.02s\tremaining: 6.24s\n",
      "392:\tlearn: 543311.7163008\ttotal: 4.04s\tremaining: 6.23s\n",
      "393:\tlearn: 543270.5958974\ttotal: 4.05s\tremaining: 6.23s\n",
      "394:\tlearn: 543161.3839377\ttotal: 4.05s\tremaining: 6.21s\n",
      "395:\tlearn: 543132.6178024\ttotal: 4.07s\tremaining: 6.21s\n",
      "396:\tlearn: 543080.3019105\ttotal: 4.08s\tremaining: 6.19s\n",
      "397:\tlearn: 543052.8643783\ttotal: 4.08s\tremaining: 6.18s\n",
      "398:\tlearn: 543016.4242742\ttotal: 4.09s\tremaining: 6.16s\n",
      "399:\tlearn: 543004.6664325\ttotal: 4.11s\tremaining: 6.16s\n",
      "400:\tlearn: 542936.3253473\ttotal: 4.11s\tremaining: 6.14s\n",
      "401:\tlearn: 542927.4095351\ttotal: 4.12s\tremaining: 6.12s\n",
      "402:\tlearn: 542866.5047604\ttotal: 4.13s\tremaining: 6.11s\n",
      "403:\tlearn: 542855.5514189\ttotal: 4.13s\tremaining: 6.1s\n",
      "404:\tlearn: 542796.8966706\ttotal: 4.14s\tremaining: 6.08s\n",
      "405:\tlearn: 542766.4454285\ttotal: 4.15s\tremaining: 6.07s\n",
      "406:\tlearn: 542693.5467846\ttotal: 4.15s\tremaining: 6.05s\n",
      "407:\tlearn: 542621.5210662\ttotal: 4.17s\tremaining: 6.04s\n",
      "408:\tlearn: 542560.6082028\ttotal: 4.17s\tremaining: 6.03s\n",
      "409:\tlearn: 542535.8542979\ttotal: 4.18s\tremaining: 6.02s\n",
      "410:\tlearn: 542527.0607207\ttotal: 4.19s\tremaining: 6.01s\n",
      "411:\tlearn: 542464.4386091\ttotal: 4.2s\tremaining: 6s\n",
      "412:\tlearn: 542422.8839808\ttotal: 4.21s\tremaining: 5.98s\n",
      "413:\tlearn: 542359.4590917\ttotal: 4.21s\tremaining: 5.96s\n",
      "414:\tlearn: 542347.9759894\ttotal: 4.22s\tremaining: 5.96s\n",
      "415:\tlearn: 542306.6681721\ttotal: 4.23s\tremaining: 5.94s\n",
      "416:\tlearn: 542297.6561081\ttotal: 4.24s\tremaining: 5.93s\n",
      "417:\tlearn: 542272.6874387\ttotal: 4.25s\tremaining: 5.92s\n",
      "418:\tlearn: 542244.2363055\ttotal: 4.26s\tremaining: 5.91s\n",
      "419:\tlearn: 542203.7966091\ttotal: 4.27s\tremaining: 5.9s\n",
      "420:\tlearn: 542110.8341030\ttotal: 4.28s\tremaining: 5.88s\n",
      "421:\tlearn: 542044.4842172\ttotal: 4.29s\tremaining: 5.87s\n",
      "422:\tlearn: 542012.1824079\ttotal: 4.3s\tremaining: 5.86s\n",
      "423:\tlearn: 541916.2113467\ttotal: 4.3s\tremaining: 5.84s\n",
      "424:\tlearn: 541860.4090849\ttotal: 4.31s\tremaining: 5.83s\n",
      "425:\tlearn: 541855.5240605\ttotal: 4.31s\tremaining: 5.81s\n",
      "426:\tlearn: 541817.2154441\ttotal: 4.32s\tremaining: 5.8s\n",
      "427:\tlearn: 541790.7441178\ttotal: 4.33s\tremaining: 5.79s\n",
      "428:\tlearn: 541721.7624822\ttotal: 4.34s\tremaining: 5.77s\n",
      "429:\tlearn: 541693.0315476\ttotal: 4.34s\tremaining: 5.76s\n",
      "430:\tlearn: 541670.5003753\ttotal: 4.36s\tremaining: 5.75s\n",
      "431:\tlearn: 541590.0031251\ttotal: 4.36s\tremaining: 5.74s\n",
      "432:\tlearn: 541570.4789768\ttotal: 4.37s\tremaining: 5.72s\n",
      "433:\tlearn: 541506.7210564\ttotal: 4.37s\tremaining: 5.7s\n",
      "434:\tlearn: 541465.9740839\ttotal: 4.38s\tremaining: 5.69s\n",
      "435:\tlearn: 541441.6536791\ttotal: 4.39s\tremaining: 5.68s\n",
      "436:\tlearn: 541436.0630094\ttotal: 4.4s\tremaining: 5.67s\n",
      "437:\tlearn: 541385.9517415\ttotal: 4.4s\tremaining: 5.65s\n",
      "438:\tlearn: 541344.2541670\ttotal: 4.42s\tremaining: 5.64s\n",
      "439:\tlearn: 541289.3635281\ttotal: 4.43s\tremaining: 5.63s\n",
      "440:\tlearn: 541273.6810377\ttotal: 4.44s\tremaining: 5.62s\n",
      "441:\tlearn: 541246.0405045\ttotal: 4.45s\tremaining: 5.61s\n",
      "442:\tlearn: 541189.3542819\ttotal: 4.46s\tremaining: 5.6s\n",
      "443:\tlearn: 541102.2814344\ttotal: 4.46s\tremaining: 5.59s\n",
      "444:\tlearn: 541054.7942227\ttotal: 4.47s\tremaining: 5.58s\n",
      "445:\tlearn: 541034.7261946\ttotal: 4.48s\tremaining: 5.57s\n",
      "446:\tlearn: 540959.9245585\ttotal: 4.49s\tremaining: 5.55s\n",
      "447:\tlearn: 540929.1651059\ttotal: 4.5s\tremaining: 5.54s\n",
      "448:\tlearn: 540885.0688959\ttotal: 4.5s\tremaining: 5.52s\n",
      "449:\tlearn: 540866.8566374\ttotal: 4.51s\tremaining: 5.51s\n",
      "450:\tlearn: 540815.8898874\ttotal: 4.52s\tremaining: 5.5s\n",
      "451:\tlearn: 540747.4292234\ttotal: 4.52s\tremaining: 5.49s\n",
      "452:\tlearn: 540687.6758256\ttotal: 4.53s\tremaining: 5.47s\n",
      "453:\tlearn: 540668.2214514\ttotal: 4.54s\tremaining: 5.46s\n",
      "454:\tlearn: 540639.7748695\ttotal: 4.55s\tremaining: 5.45s\n",
      "455:\tlearn: 540630.8202893\ttotal: 4.56s\tremaining: 5.44s\n",
      "456:\tlearn: 540610.1659068\ttotal: 4.57s\tremaining: 5.43s\n",
      "457:\tlearn: 540547.7774210\ttotal: 4.58s\tremaining: 5.42s\n",
      "458:\tlearn: 540540.3801376\ttotal: 4.59s\tremaining: 5.41s\n",
      "459:\tlearn: 540517.3406733\ttotal: 4.59s\tremaining: 5.39s\n",
      "460:\tlearn: 540491.3538557\ttotal: 4.6s\tremaining: 5.38s\n",
      "461:\tlearn: 540472.9026389\ttotal: 4.61s\tremaining: 5.37s\n",
      "462:\tlearn: 540441.0551548\ttotal: 4.62s\tremaining: 5.36s\n",
      "463:\tlearn: 540416.8421978\ttotal: 4.63s\tremaining: 5.35s\n",
      "464:\tlearn: 540353.1783803\ttotal: 4.64s\tremaining: 5.34s\n",
      "465:\tlearn: 540343.8278908\ttotal: 4.65s\tremaining: 5.33s\n",
      "466:\tlearn: 540306.4320450\ttotal: 4.66s\tremaining: 5.32s\n",
      "467:\tlearn: 540272.1230920\ttotal: 4.67s\tremaining: 5.3s\n",
      "468:\tlearn: 540256.5089313\ttotal: 4.68s\tremaining: 5.3s\n",
      "469:\tlearn: 540252.2319833\ttotal: 4.69s\tremaining: 5.29s\n",
      "470:\tlearn: 540194.9923181\ttotal: 4.7s\tremaining: 5.28s\n",
      "471:\tlearn: 540108.4334168\ttotal: 4.71s\tremaining: 5.27s\n",
      "472:\tlearn: 540061.9228747\ttotal: 4.72s\tremaining: 5.26s\n",
      "473:\tlearn: 540017.5173635\ttotal: 4.73s\tremaining: 5.25s\n",
      "474:\tlearn: 539995.9485365\ttotal: 4.74s\tremaining: 5.24s\n",
      "475:\tlearn: 539978.8110056\ttotal: 4.75s\tremaining: 5.23s\n",
      "476:\tlearn: 539959.0040373\ttotal: 4.76s\tremaining: 5.22s\n",
      "477:\tlearn: 539950.3536857\ttotal: 4.77s\tremaining: 5.21s\n",
      "478:\tlearn: 539930.2728204\ttotal: 4.78s\tremaining: 5.2s\n",
      "479:\tlearn: 539924.0075293\ttotal: 4.79s\tremaining: 5.19s\n",
      "480:\tlearn: 539920.0134203\ttotal: 4.8s\tremaining: 5.18s\n",
      "481:\tlearn: 539903.8397391\ttotal: 4.81s\tremaining: 5.17s\n",
      "482:\tlearn: 539866.7116034\ttotal: 4.82s\tremaining: 5.16s\n",
      "483:\tlearn: 539832.5195782\ttotal: 4.83s\tremaining: 5.15s\n",
      "484:\tlearn: 539787.2014901\ttotal: 4.84s\tremaining: 5.14s\n",
      "485:\tlearn: 539761.8113675\ttotal: 4.86s\tremaining: 5.14s\n",
      "486:\tlearn: 539749.3422551\ttotal: 4.87s\tremaining: 5.13s\n",
      "487:\tlearn: 539721.0597258\ttotal: 4.88s\tremaining: 5.12s\n",
      "488:\tlearn: 539673.5081531\ttotal: 4.89s\tremaining: 5.11s\n",
      "489:\tlearn: 539659.3917147\ttotal: 4.9s\tremaining: 5.1s\n",
      "490:\tlearn: 539547.3400996\ttotal: 4.91s\tremaining: 5.08s\n",
      "491:\tlearn: 539453.3755597\ttotal: 4.91s\tremaining: 5.07s\n",
      "492:\tlearn: 539403.7340532\ttotal: 4.92s\tremaining: 5.06s\n",
      "493:\tlearn: 539382.2071434\ttotal: 4.93s\tremaining: 5.05s\n",
      "494:\tlearn: 539348.7781444\ttotal: 4.94s\tremaining: 5.04s\n",
      "495:\tlearn: 539292.5974980\ttotal: 4.94s\tremaining: 5.02s\n",
      "496:\tlearn: 539227.4030942\ttotal: 4.95s\tremaining: 5.01s\n",
      "497:\tlearn: 539144.9018012\ttotal: 4.96s\tremaining: 5s\n",
      "498:\tlearn: 539123.7592440\ttotal: 4.97s\tremaining: 4.99s\n",
      "499:\tlearn: 539073.1970282\ttotal: 4.98s\tremaining: 4.98s\n",
      "500:\tlearn: 539059.8952083\ttotal: 4.99s\tremaining: 4.97s\n",
      "501:\tlearn: 539035.8398027\ttotal: 5s\tremaining: 4.96s\n",
      "502:\tlearn: 538921.3970431\ttotal: 5.01s\tremaining: 4.95s\n",
      "503:\tlearn: 538890.6769342\ttotal: 5.02s\tremaining: 4.94s\n",
      "504:\tlearn: 538861.3331968\ttotal: 5.03s\tremaining: 4.93s\n",
      "505:\tlearn: 538819.6697189\ttotal: 5.04s\tremaining: 4.92s\n",
      "506:\tlearn: 538792.4657693\ttotal: 5.04s\tremaining: 4.91s\n",
      "507:\tlearn: 538772.2639970\ttotal: 5.05s\tremaining: 4.89s\n",
      "508:\tlearn: 538750.4822721\ttotal: 5.07s\tremaining: 4.88s\n",
      "509:\tlearn: 538688.0799856\ttotal: 5.07s\tremaining: 4.87s\n",
      "510:\tlearn: 538672.9902604\ttotal: 5.08s\tremaining: 4.86s\n",
      "511:\tlearn: 538633.6131595\ttotal: 5.08s\tremaining: 4.84s\n",
      "512:\tlearn: 538614.7440881\ttotal: 5.09s\tremaining: 4.84s\n",
      "513:\tlearn: 538594.8246372\ttotal: 5.1s\tremaining: 4.83s\n",
      "514:\tlearn: 538540.0438527\ttotal: 5.11s\tremaining: 4.81s\n",
      "515:\tlearn: 538516.6817035\ttotal: 5.12s\tremaining: 4.8s\n",
      "516:\tlearn: 538508.9060991\ttotal: 5.13s\tremaining: 4.79s\n",
      "517:\tlearn: 538476.8209857\ttotal: 5.14s\tremaining: 4.78s\n",
      "518:\tlearn: 538441.6181392\ttotal: 5.15s\tremaining: 4.77s\n",
      "519:\tlearn: 538375.1693343\ttotal: 5.16s\tremaining: 4.76s\n",
      "520:\tlearn: 538336.7517297\ttotal: 5.17s\tremaining: 4.75s\n",
      "521:\tlearn: 538294.6025911\ttotal: 5.17s\tremaining: 4.74s\n",
      "522:\tlearn: 538233.5763043\ttotal: 5.18s\tremaining: 4.72s\n",
      "523:\tlearn: 538220.1874481\ttotal: 5.19s\tremaining: 4.71s\n",
      "524:\tlearn: 538200.9200346\ttotal: 5.2s\tremaining: 4.7s\n",
      "525:\tlearn: 538186.2306176\ttotal: 5.21s\tremaining: 4.69s\n",
      "526:\tlearn: 538133.0949283\ttotal: 5.22s\tremaining: 4.68s\n",
      "527:\tlearn: 538123.3533248\ttotal: 5.23s\tremaining: 4.67s\n",
      "528:\tlearn: 538117.9065573\ttotal: 5.24s\tremaining: 4.66s\n",
      "529:\tlearn: 538110.3674876\ttotal: 5.25s\tremaining: 4.65s\n",
      "530:\tlearn: 538102.8602745\ttotal: 5.26s\tremaining: 4.64s\n",
      "531:\tlearn: 538075.6571814\ttotal: 5.27s\tremaining: 4.63s\n",
      "532:\tlearn: 538057.3315941\ttotal: 5.27s\tremaining: 4.62s\n",
      "533:\tlearn: 538051.1712717\ttotal: 5.28s\tremaining: 4.61s\n",
      "534:\tlearn: 538034.8882906\ttotal: 5.29s\tremaining: 4.6s\n",
      "535:\tlearn: 538024.4939525\ttotal: 5.3s\tremaining: 4.58s\n",
      "536:\tlearn: 537924.2751276\ttotal: 5.3s\tremaining: 4.57s\n",
      "537:\tlearn: 537885.4996948\ttotal: 5.31s\tremaining: 4.56s\n",
      "538:\tlearn: 537856.9569798\ttotal: 5.32s\tremaining: 4.55s\n",
      "539:\tlearn: 537848.7062677\ttotal: 5.33s\tremaining: 4.54s\n",
      "540:\tlearn: 537840.8413526\ttotal: 5.34s\tremaining: 4.53s\n",
      "541:\tlearn: 537816.8258469\ttotal: 5.35s\tremaining: 4.52s\n",
      "542:\tlearn: 537811.2046724\ttotal: 5.36s\tremaining: 4.51s\n",
      "543:\tlearn: 537793.7584346\ttotal: 5.36s\tremaining: 4.49s\n",
      "544:\tlearn: 537772.8360010\ttotal: 5.37s\tremaining: 4.48s\n",
      "545:\tlearn: 537769.9359789\ttotal: 5.38s\tremaining: 4.47s\n",
      "546:\tlearn: 537763.5293259\ttotal: 5.39s\tremaining: 4.46s\n",
      "547:\tlearn: 537757.3506713\ttotal: 5.39s\tremaining: 4.45s\n",
      "548:\tlearn: 537738.8763909\ttotal: 5.4s\tremaining: 4.44s\n",
      "549:\tlearn: 537707.6695279\ttotal: 5.41s\tremaining: 4.43s\n",
      "550:\tlearn: 537664.1318967\ttotal: 5.42s\tremaining: 4.42s\n",
      "551:\tlearn: 537656.6695908\ttotal: 5.43s\tremaining: 4.41s\n",
      "552:\tlearn: 537653.1671793\ttotal: 5.44s\tremaining: 4.4s\n",
      "553:\tlearn: 537631.7310067\ttotal: 5.46s\tremaining: 4.39s\n",
      "554:\tlearn: 537610.5915776\ttotal: 5.46s\tremaining: 4.38s\n",
      "555:\tlearn: 537590.7937110\ttotal: 5.47s\tremaining: 4.37s\n",
      "556:\tlearn: 537547.6456912\ttotal: 5.48s\tremaining: 4.36s\n",
      "557:\tlearn: 537524.1405886\ttotal: 5.49s\tremaining: 4.34s\n",
      "558:\tlearn: 537457.4451742\ttotal: 5.49s\tremaining: 4.33s\n",
      "559:\tlearn: 537436.2605247\ttotal: 5.5s\tremaining: 4.32s\n",
      "560:\tlearn: 537379.7090734\ttotal: 5.51s\tremaining: 4.31s\n",
      "561:\tlearn: 537332.9980724\ttotal: 5.51s\tremaining: 4.3s\n",
      "562:\tlearn: 537318.5992191\ttotal: 5.52s\tremaining: 4.29s\n",
      "563:\tlearn: 537300.5695782\ttotal: 5.53s\tremaining: 4.27s\n",
      "564:\tlearn: 537291.5971720\ttotal: 5.54s\tremaining: 4.26s\n",
      "565:\tlearn: 537285.1244528\ttotal: 5.55s\tremaining: 4.25s\n",
      "566:\tlearn: 537278.7073407\ttotal: 5.55s\tremaining: 4.24s\n",
      "567:\tlearn: 537263.4036922\ttotal: 5.56s\tremaining: 4.23s\n",
      "568:\tlearn: 537247.6930449\ttotal: 5.57s\tremaining: 4.22s\n",
      "569:\tlearn: 537240.2280991\ttotal: 5.58s\tremaining: 4.21s\n",
      "570:\tlearn: 537215.6857332\ttotal: 5.59s\tremaining: 4.2s\n",
      "571:\tlearn: 537128.8420618\ttotal: 5.6s\tremaining: 4.19s\n",
      "572:\tlearn: 537064.6139623\ttotal: 5.61s\tremaining: 4.18s\n",
      "573:\tlearn: 537043.3229641\ttotal: 5.62s\tremaining: 4.17s\n",
      "574:\tlearn: 536991.0030104\ttotal: 5.63s\tremaining: 4.16s\n",
      "575:\tlearn: 536957.2944820\ttotal: 5.64s\tremaining: 4.15s\n",
      "576:\tlearn: 536935.9604583\ttotal: 5.65s\tremaining: 4.14s\n",
      "577:\tlearn: 536928.2960154\ttotal: 5.66s\tremaining: 4.13s\n",
      "578:\tlearn: 536916.7347878\ttotal: 5.66s\tremaining: 4.12s\n",
      "579:\tlearn: 536907.2726214\ttotal: 5.67s\tremaining: 4.11s\n",
      "580:\tlearn: 536860.9764246\ttotal: 5.68s\tremaining: 4.1s\n",
      "581:\tlearn: 536839.3771851\ttotal: 5.69s\tremaining: 4.08s\n",
      "582:\tlearn: 536824.0636265\ttotal: 5.69s\tremaining: 4.07s\n",
      "583:\tlearn: 536781.7420749\ttotal: 5.7s\tremaining: 4.06s\n",
      "584:\tlearn: 536752.7957431\ttotal: 5.71s\tremaining: 4.05s\n",
      "585:\tlearn: 536715.2431459\ttotal: 5.72s\tremaining: 4.04s\n",
      "586:\tlearn: 536705.0256596\ttotal: 5.72s\tremaining: 4.03s\n",
      "587:\tlearn: 536672.7461742\ttotal: 5.73s\tremaining: 4.02s\n",
      "588:\tlearn: 536632.9435235\ttotal: 5.74s\tremaining: 4.01s\n",
      "589:\tlearn: 536595.7484905\ttotal: 5.75s\tremaining: 3.99s\n",
      "590:\tlearn: 536584.1601189\ttotal: 5.75s\tremaining: 3.98s\n",
      "591:\tlearn: 536575.0771156\ttotal: 5.76s\tremaining: 3.97s\n",
      "592:\tlearn: 536566.2506587\ttotal: 5.77s\tremaining: 3.96s\n",
      "593:\tlearn: 536557.6995576\ttotal: 5.78s\tremaining: 3.95s\n",
      "594:\tlearn: 536528.0530879\ttotal: 5.79s\tremaining: 3.94s\n",
      "595:\tlearn: 536479.3512089\ttotal: 5.79s\tremaining: 3.93s\n",
      "596:\tlearn: 536454.3974875\ttotal: 5.81s\tremaining: 3.92s\n",
      "597:\tlearn: 536408.9687629\ttotal: 5.81s\tremaining: 3.91s\n",
      "598:\tlearn: 536361.5962225\ttotal: 5.82s\tremaining: 3.9s\n",
      "599:\tlearn: 536344.0848590\ttotal: 5.83s\tremaining: 3.89s\n",
      "600:\tlearn: 536311.8398732\ttotal: 5.84s\tremaining: 3.88s\n",
      "601:\tlearn: 536305.4004703\ttotal: 5.85s\tremaining: 3.87s\n",
      "602:\tlearn: 536226.9393286\ttotal: 5.86s\tremaining: 3.85s\n",
      "603:\tlearn: 536180.9175293\ttotal: 5.87s\tremaining: 3.85s\n",
      "604:\tlearn: 536136.3674228\ttotal: 5.87s\tremaining: 3.83s\n",
      "605:\tlearn: 536104.1329800\ttotal: 5.88s\tremaining: 3.82s\n",
      "606:\tlearn: 536095.1266159\ttotal: 5.88s\tremaining: 3.81s\n",
      "607:\tlearn: 536089.8789907\ttotal: 5.89s\tremaining: 3.8s\n",
      "608:\tlearn: 536072.2074268\ttotal: 5.9s\tremaining: 3.79s\n",
      "609:\tlearn: 536055.1783855\ttotal: 5.91s\tremaining: 3.78s\n",
      "610:\tlearn: 536017.3450612\ttotal: 5.92s\tremaining: 3.77s\n",
      "611:\tlearn: 536014.4903812\ttotal: 5.92s\tremaining: 3.75s\n",
      "612:\tlearn: 535970.2812265\ttotal: 5.93s\tremaining: 3.75s\n",
      "613:\tlearn: 535952.5841414\ttotal: 5.94s\tremaining: 3.73s\n",
      "614:\tlearn: 535914.6581250\ttotal: 5.95s\tremaining: 3.72s\n",
      "615:\tlearn: 535897.1623559\ttotal: 5.95s\tremaining: 3.71s\n",
      "616:\tlearn: 535862.2754929\ttotal: 5.96s\tremaining: 3.7s\n",
      "617:\tlearn: 535847.6716785\ttotal: 5.97s\tremaining: 3.69s\n",
      "618:\tlearn: 535840.5537367\ttotal: 5.98s\tremaining: 3.68s\n",
      "619:\tlearn: 535826.1452785\ttotal: 5.99s\tremaining: 3.67s\n",
      "620:\tlearn: 535794.5276226\ttotal: 6s\tremaining: 3.66s\n",
      "621:\tlearn: 535733.2362594\ttotal: 6.01s\tremaining: 3.65s\n",
      "622:\tlearn: 535702.4872411\ttotal: 6.01s\tremaining: 3.64s\n",
      "623:\tlearn: 535694.2333947\ttotal: 6.03s\tremaining: 3.63s\n",
      "624:\tlearn: 535665.1703463\ttotal: 6.04s\tremaining: 3.62s\n",
      "625:\tlearn: 535642.4558779\ttotal: 6.04s\tremaining: 3.61s\n",
      "626:\tlearn: 535623.7136695\ttotal: 6.05s\tremaining: 3.6s\n",
      "627:\tlearn: 535590.8215420\ttotal: 6.06s\tremaining: 3.59s\n",
      "628:\tlearn: 535565.6593403\ttotal: 6.07s\tremaining: 3.58s\n",
      "629:\tlearn: 535542.1284381\ttotal: 6.07s\tremaining: 3.57s\n",
      "630:\tlearn: 535537.9350178\ttotal: 6.08s\tremaining: 3.56s\n",
      "631:\tlearn: 535510.7231084\ttotal: 6.09s\tremaining: 3.55s\n",
      "632:\tlearn: 535500.0277899\ttotal: 6.1s\tremaining: 3.54s\n",
      "633:\tlearn: 535482.1170136\ttotal: 6.11s\tremaining: 3.52s\n",
      "634:\tlearn: 535454.8157677\ttotal: 6.12s\tremaining: 3.52s\n",
      "635:\tlearn: 535441.0132000\ttotal: 6.13s\tremaining: 3.51s\n",
      "636:\tlearn: 535435.8700697\ttotal: 6.13s\tremaining: 3.5s\n",
      "637:\tlearn: 535406.9994175\ttotal: 6.14s\tremaining: 3.48s\n",
      "638:\tlearn: 535405.4386553\ttotal: 6.15s\tremaining: 3.47s\n",
      "639:\tlearn: 535390.2931443\ttotal: 6.16s\tremaining: 3.46s\n",
      "640:\tlearn: 535374.5942259\ttotal: 6.16s\tremaining: 3.45s\n",
      "641:\tlearn: 535338.0815883\ttotal: 6.17s\tremaining: 3.44s\n",
      "642:\tlearn: 535310.3657224\ttotal: 6.18s\tremaining: 3.43s\n",
      "643:\tlearn: 535232.2263460\ttotal: 6.19s\tremaining: 3.42s\n",
      "644:\tlearn: 535205.9252412\ttotal: 6.2s\tremaining: 3.41s\n",
      "645:\tlearn: 535180.4360209\ttotal: 6.2s\tremaining: 3.4s\n",
      "646:\tlearn: 535170.9599407\ttotal: 6.22s\tremaining: 3.39s\n",
      "647:\tlearn: 535161.3904467\ttotal: 6.23s\tremaining: 3.38s\n",
      "648:\tlearn: 535137.3175995\ttotal: 6.24s\tremaining: 3.37s\n",
      "649:\tlearn: 535134.9218712\ttotal: 6.25s\tremaining: 3.36s\n",
      "650:\tlearn: 535089.3629587\ttotal: 6.25s\tremaining: 3.35s\n",
      "651:\tlearn: 535076.8972300\ttotal: 6.26s\tremaining: 3.34s\n",
      "652:\tlearn: 535053.2657049\ttotal: 6.27s\tremaining: 3.33s\n",
      "653:\tlearn: 535017.3243760\ttotal: 6.27s\tremaining: 3.32s\n",
      "654:\tlearn: 535011.5304109\ttotal: 6.29s\tremaining: 3.31s\n",
      "655:\tlearn: 534975.4545640\ttotal: 6.29s\tremaining: 3.3s\n",
      "656:\tlearn: 534939.2554661\ttotal: 6.3s\tremaining: 3.29s\n",
      "657:\tlearn: 534905.5211806\ttotal: 6.3s\tremaining: 3.27s\n",
      "658:\tlearn: 534891.5364015\ttotal: 6.31s\tremaining: 3.27s\n",
      "659:\tlearn: 534872.9506469\ttotal: 6.32s\tremaining: 3.25s\n",
      "660:\tlearn: 534844.5592893\ttotal: 6.33s\tremaining: 3.24s\n",
      "661:\tlearn: 534842.6786611\ttotal: 6.33s\tremaining: 3.23s\n",
      "662:\tlearn: 534827.6099255\ttotal: 6.34s\tremaining: 3.22s\n",
      "663:\tlearn: 534818.9548971\ttotal: 6.35s\tremaining: 3.21s\n",
      "664:\tlearn: 534809.8641065\ttotal: 6.36s\tremaining: 3.2s\n",
      "665:\tlearn: 534795.1983813\ttotal: 6.36s\tremaining: 3.19s\n",
      "666:\tlearn: 534773.8659404\ttotal: 6.37s\tremaining: 3.18s\n",
      "667:\tlearn: 534768.0172116\ttotal: 6.38s\tremaining: 3.17s\n",
      "668:\tlearn: 534761.1105993\ttotal: 6.39s\tremaining: 3.16s\n",
      "669:\tlearn: 534751.4465128\ttotal: 6.4s\tremaining: 3.15s\n",
      "670:\tlearn: 534737.9574821\ttotal: 6.41s\tremaining: 3.14s\n",
      "671:\tlearn: 534710.2386727\ttotal: 6.42s\tremaining: 3.13s\n",
      "672:\tlearn: 534698.6131510\ttotal: 6.43s\tremaining: 3.12s\n",
      "673:\tlearn: 534673.9733200\ttotal: 6.44s\tremaining: 3.11s\n",
      "674:\tlearn: 534634.3396944\ttotal: 6.44s\tremaining: 3.1s\n",
      "675:\tlearn: 534620.4672182\ttotal: 6.45s\tremaining: 3.09s\n",
      "676:\tlearn: 534600.4019933\ttotal: 6.46s\tremaining: 3.08s\n",
      "677:\tlearn: 534580.7402965\ttotal: 6.46s\tremaining: 3.07s\n",
      "678:\tlearn: 534513.6089754\ttotal: 6.47s\tremaining: 3.06s\n",
      "679:\tlearn: 534492.9233982\ttotal: 6.48s\tremaining: 3.05s\n",
      "680:\tlearn: 534481.5469067\ttotal: 6.49s\tremaining: 3.04s\n",
      "681:\tlearn: 534448.8225995\ttotal: 6.49s\tremaining: 3.03s\n",
      "682:\tlearn: 534417.9399013\ttotal: 6.5s\tremaining: 3.02s\n",
      "683:\tlearn: 534363.6147558\ttotal: 6.51s\tremaining: 3.01s\n",
      "684:\tlearn: 534342.1043239\ttotal: 6.51s\tremaining: 3s\n",
      "685:\tlearn: 534297.1286006\ttotal: 6.52s\tremaining: 2.98s\n",
      "686:\tlearn: 534236.4458367\ttotal: 6.53s\tremaining: 2.97s\n",
      "687:\tlearn: 534194.9564934\ttotal: 6.54s\tremaining: 2.96s\n",
      "688:\tlearn: 534153.8491821\ttotal: 6.55s\tremaining: 2.96s\n",
      "689:\tlearn: 534132.2188441\ttotal: 6.55s\tremaining: 2.94s\n",
      "690:\tlearn: 534109.7920772\ttotal: 6.56s\tremaining: 2.94s\n",
      "691:\tlearn: 534091.9049598\ttotal: 6.57s\tremaining: 2.92s\n",
      "692:\tlearn: 534082.5017990\ttotal: 6.58s\tremaining: 2.92s\n",
      "693:\tlearn: 534070.0300026\ttotal: 6.59s\tremaining: 2.9s\n",
      "694:\tlearn: 534036.9229478\ttotal: 6.6s\tremaining: 2.9s\n",
      "695:\tlearn: 534017.9811438\ttotal: 6.62s\tremaining: 2.89s\n",
      "696:\tlearn: 534005.1285045\ttotal: 6.63s\tremaining: 2.88s\n",
      "697:\tlearn: 533990.8259549\ttotal: 6.64s\tremaining: 2.87s\n",
      "698:\tlearn: 533977.0598585\ttotal: 6.65s\tremaining: 2.86s\n",
      "699:\tlearn: 533964.2949372\ttotal: 6.66s\tremaining: 2.85s\n",
      "700:\tlearn: 533945.8298222\ttotal: 6.67s\tremaining: 2.84s\n",
      "701:\tlearn: 533893.0897794\ttotal: 6.67s\tremaining: 2.83s\n",
      "702:\tlearn: 533875.1948026\ttotal: 6.68s\tremaining: 2.82s\n",
      "703:\tlearn: 533865.7841166\ttotal: 6.68s\tremaining: 2.81s\n",
      "704:\tlearn: 533849.7659826\ttotal: 6.69s\tremaining: 2.8s\n",
      "705:\tlearn: 533836.3283337\ttotal: 6.7s\tremaining: 2.79s\n",
      "706:\tlearn: 533789.1011886\ttotal: 6.71s\tremaining: 2.78s\n",
      "707:\tlearn: 533774.4588466\ttotal: 6.71s\tremaining: 2.77s\n",
      "708:\tlearn: 533766.4063083\ttotal: 6.72s\tremaining: 2.76s\n",
      "709:\tlearn: 533758.3656025\ttotal: 6.73s\tremaining: 2.75s\n",
      "710:\tlearn: 533746.4527548\ttotal: 6.74s\tremaining: 2.74s\n",
      "711:\tlearn: 533738.6589659\ttotal: 6.75s\tremaining: 2.73s\n",
      "712:\tlearn: 533733.4919216\ttotal: 6.76s\tremaining: 2.72s\n",
      "713:\tlearn: 533720.5296954\ttotal: 6.77s\tremaining: 2.71s\n",
      "714:\tlearn: 533707.5324222\ttotal: 6.78s\tremaining: 2.7s\n",
      "715:\tlearn: 533698.6348988\ttotal: 6.79s\tremaining: 2.69s\n",
      "716:\tlearn: 533690.7518350\ttotal: 6.8s\tremaining: 2.69s\n",
      "717:\tlearn: 533686.4473219\ttotal: 6.81s\tremaining: 2.67s\n",
      "718:\tlearn: 533681.6920109\ttotal: 6.83s\tremaining: 2.67s\n",
      "719:\tlearn: 533651.1380119\ttotal: 6.84s\tremaining: 2.66s\n",
      "720:\tlearn: 533633.2777036\ttotal: 6.85s\tremaining: 2.65s\n",
      "721:\tlearn: 533607.9229029\ttotal: 6.86s\tremaining: 2.64s\n",
      "722:\tlearn: 533601.9473765\ttotal: 6.87s\tremaining: 2.63s\n",
      "723:\tlearn: 533547.5761653\ttotal: 6.88s\tremaining: 2.62s\n",
      "724:\tlearn: 533530.2263865\ttotal: 6.88s\tremaining: 2.61s\n",
      "725:\tlearn: 533517.7051928\ttotal: 6.89s\tremaining: 2.6s\n",
      "726:\tlearn: 533495.9949170\ttotal: 6.9s\tremaining: 2.59s\n",
      "727:\tlearn: 533490.7201362\ttotal: 6.91s\tremaining: 2.58s\n",
      "728:\tlearn: 533448.9983616\ttotal: 6.91s\tremaining: 2.57s\n",
      "729:\tlearn: 533400.3772315\ttotal: 6.92s\tremaining: 2.56s\n",
      "730:\tlearn: 533376.4530399\ttotal: 6.93s\tremaining: 2.55s\n",
      "731:\tlearn: 533355.5988911\ttotal: 6.94s\tremaining: 2.54s\n",
      "732:\tlearn: 533326.0242525\ttotal: 6.95s\tremaining: 2.53s\n",
      "733:\tlearn: 533308.2725330\ttotal: 6.96s\tremaining: 2.52s\n",
      "734:\tlearn: 533290.5773128\ttotal: 6.96s\tremaining: 2.51s\n",
      "735:\tlearn: 533278.4765609\ttotal: 6.97s\tremaining: 2.5s\n",
      "736:\tlearn: 533273.2605026\ttotal: 6.98s\tremaining: 2.49s\n",
      "737:\tlearn: 533265.5000221\ttotal: 6.99s\tremaining: 2.48s\n",
      "738:\tlearn: 533228.5148102\ttotal: 7s\tremaining: 2.47s\n",
      "739:\tlearn: 533206.7606808\ttotal: 7.01s\tremaining: 2.46s\n",
      "740:\tlearn: 533186.7781948\ttotal: 7.02s\tremaining: 2.45s\n",
      "741:\tlearn: 533181.7566958\ttotal: 7.03s\tremaining: 2.44s\n",
      "742:\tlearn: 533132.0524951\ttotal: 7.04s\tremaining: 2.43s\n",
      "743:\tlearn: 533107.6049078\ttotal: 7.04s\tremaining: 2.42s\n",
      "744:\tlearn: 533079.1529498\ttotal: 7.05s\tremaining: 2.41s\n",
      "745:\tlearn: 533059.9134319\ttotal: 7.06s\tremaining: 2.4s\n",
      "746:\tlearn: 533032.1503840\ttotal: 7.07s\tremaining: 2.4s\n",
      "747:\tlearn: 533010.1676788\ttotal: 7.08s\tremaining: 2.38s\n",
      "748:\tlearn: 533003.3882224\ttotal: 7.09s\tremaining: 2.38s\n",
      "749:\tlearn: 532991.1105569\ttotal: 7.1s\tremaining: 2.37s\n",
      "750:\tlearn: 532922.4561818\ttotal: 7.1s\tremaining: 2.35s\n",
      "751:\tlearn: 532918.7732436\ttotal: 7.11s\tremaining: 2.35s\n",
      "752:\tlearn: 532898.2965830\ttotal: 7.12s\tremaining: 2.34s\n",
      "753:\tlearn: 532878.4317672\ttotal: 7.13s\tremaining: 2.33s\n",
      "754:\tlearn: 532840.2586332\ttotal: 7.14s\tremaining: 2.31s\n",
      "755:\tlearn: 532792.4481317\ttotal: 7.14s\tremaining: 2.31s\n",
      "756:\tlearn: 532781.6051324\ttotal: 7.16s\tremaining: 2.3s\n",
      "757:\tlearn: 532773.3124596\ttotal: 7.17s\tremaining: 2.29s\n",
      "758:\tlearn: 532769.7487148\ttotal: 7.17s\tremaining: 2.28s\n",
      "759:\tlearn: 532723.8167044\ttotal: 7.19s\tremaining: 2.27s\n",
      "760:\tlearn: 532706.1302890\ttotal: 7.2s\tremaining: 2.26s\n",
      "761:\tlearn: 532667.6731256\ttotal: 7.21s\tremaining: 2.25s\n",
      "762:\tlearn: 532598.7021083\ttotal: 7.22s\tremaining: 2.24s\n",
      "763:\tlearn: 532570.8524648\ttotal: 7.23s\tremaining: 2.23s\n",
      "764:\tlearn: 532565.6757136\ttotal: 7.24s\tremaining: 2.22s\n",
      "765:\tlearn: 532533.5351002\ttotal: 7.24s\tremaining: 2.21s\n",
      "766:\tlearn: 532529.9046140\ttotal: 7.25s\tremaining: 2.2s\n",
      "767:\tlearn: 532507.0766617\ttotal: 7.26s\tremaining: 2.19s\n",
      "768:\tlearn: 532502.2555166\ttotal: 7.27s\tremaining: 2.18s\n",
      "769:\tlearn: 532483.1790798\ttotal: 7.28s\tremaining: 2.17s\n",
      "770:\tlearn: 532441.9482617\ttotal: 7.28s\tremaining: 2.16s\n",
      "771:\tlearn: 532423.1822352\ttotal: 7.29s\tremaining: 2.15s\n",
      "772:\tlearn: 532408.5026124\ttotal: 7.3s\tremaining: 2.14s\n",
      "773:\tlearn: 532394.7984732\ttotal: 7.31s\tremaining: 2.13s\n",
      "774:\tlearn: 532368.1818988\ttotal: 7.32s\tremaining: 2.12s\n",
      "775:\tlearn: 532333.1216066\ttotal: 7.33s\tremaining: 2.11s\n",
      "776:\tlearn: 532329.2794239\ttotal: 7.33s\tremaining: 2.1s\n",
      "777:\tlearn: 532263.1638433\ttotal: 7.34s\tremaining: 2.09s\n",
      "778:\tlearn: 532244.5670831\ttotal: 7.35s\tremaining: 2.08s\n",
      "779:\tlearn: 532232.2379802\ttotal: 7.36s\tremaining: 2.07s\n",
      "780:\tlearn: 532170.0098076\ttotal: 7.36s\tremaining: 2.06s\n",
      "781:\tlearn: 532152.8154857\ttotal: 7.37s\tremaining: 2.05s\n",
      "782:\tlearn: 532113.2929667\ttotal: 7.37s\tremaining: 2.04s\n",
      "783:\tlearn: 532107.4095399\ttotal: 7.38s\tremaining: 2.03s\n",
      "784:\tlearn: 532096.9448800\ttotal: 7.39s\tremaining: 2.02s\n",
      "785:\tlearn: 532092.7139291\ttotal: 7.4s\tremaining: 2.02s\n",
      "786:\tlearn: 532087.3314050\ttotal: 7.41s\tremaining: 2.01s\n",
      "787:\tlearn: 532070.6215612\ttotal: 7.42s\tremaining: 2s\n",
      "788:\tlearn: 532068.5248516\ttotal: 7.43s\tremaining: 1.99s\n",
      "789:\tlearn: 532045.4662705\ttotal: 7.44s\tremaining: 1.98s\n",
      "790:\tlearn: 532028.6200522\ttotal: 7.45s\tremaining: 1.97s\n",
      "791:\tlearn: 532000.5159930\ttotal: 7.46s\tremaining: 1.96s\n",
      "792:\tlearn: 531978.9501253\ttotal: 7.46s\tremaining: 1.95s\n",
      "793:\tlearn: 531974.9122474\ttotal: 7.47s\tremaining: 1.94s\n",
      "794:\tlearn: 531938.0230338\ttotal: 7.48s\tremaining: 1.93s\n",
      "795:\tlearn: 531926.4335886\ttotal: 7.48s\tremaining: 1.92s\n",
      "796:\tlearn: 531879.5266438\ttotal: 7.49s\tremaining: 1.91s\n",
      "797:\tlearn: 531860.5897765\ttotal: 7.5s\tremaining: 1.9s\n",
      "798:\tlearn: 531845.8467161\ttotal: 7.5s\tremaining: 1.89s\n",
      "799:\tlearn: 531822.5239586\ttotal: 7.51s\tremaining: 1.88s\n",
      "800:\tlearn: 531807.3769563\ttotal: 7.52s\tremaining: 1.87s\n",
      "801:\tlearn: 531778.9386573\ttotal: 7.53s\tremaining: 1.86s\n",
      "802:\tlearn: 531747.9851956\ttotal: 7.54s\tremaining: 1.85s\n",
      "803:\tlearn: 531737.8723367\ttotal: 7.55s\tremaining: 1.84s\n",
      "804:\tlearn: 531732.9364470\ttotal: 7.56s\tremaining: 1.83s\n",
      "805:\tlearn: 531719.9529075\ttotal: 7.57s\tremaining: 1.82s\n",
      "806:\tlearn: 531693.7673038\ttotal: 7.58s\tremaining: 1.81s\n",
      "807:\tlearn: 531657.1957765\ttotal: 7.58s\tremaining: 1.8s\n",
      "808:\tlearn: 531633.6523832\ttotal: 7.59s\tremaining: 1.79s\n",
      "809:\tlearn: 531622.0242812\ttotal: 7.6s\tremaining: 1.78s\n",
      "810:\tlearn: 531578.7362939\ttotal: 7.61s\tremaining: 1.77s\n",
      "811:\tlearn: 531562.3142149\ttotal: 7.62s\tremaining: 1.76s\n",
      "812:\tlearn: 531556.1697033\ttotal: 7.62s\tremaining: 1.75s\n",
      "813:\tlearn: 531550.1569606\ttotal: 7.63s\tremaining: 1.74s\n",
      "814:\tlearn: 531538.5912417\ttotal: 7.64s\tremaining: 1.74s\n",
      "815:\tlearn: 531517.3193436\ttotal: 7.65s\tremaining: 1.73s\n",
      "816:\tlearn: 531484.7306801\ttotal: 7.66s\tremaining: 1.72s\n",
      "817:\tlearn: 531475.8710483\ttotal: 7.68s\tremaining: 1.71s\n",
      "818:\tlearn: 531456.1476750\ttotal: 7.69s\tremaining: 1.7s\n",
      "819:\tlearn: 531427.2434692\ttotal: 7.7s\tremaining: 1.69s\n",
      "820:\tlearn: 531417.6799753\ttotal: 7.71s\tremaining: 1.68s\n",
      "821:\tlearn: 531401.3717659\ttotal: 7.72s\tremaining: 1.67s\n",
      "822:\tlearn: 531374.1711454\ttotal: 7.72s\tremaining: 1.66s\n",
      "823:\tlearn: 531370.5682192\ttotal: 7.74s\tremaining: 1.65s\n",
      "824:\tlearn: 531344.6434794\ttotal: 7.74s\tremaining: 1.64s\n",
      "825:\tlearn: 531335.9213090\ttotal: 7.75s\tremaining: 1.63s\n",
      "826:\tlearn: 531325.2382756\ttotal: 7.76s\tremaining: 1.62s\n",
      "827:\tlearn: 531306.5082061\ttotal: 7.77s\tremaining: 1.61s\n",
      "828:\tlearn: 531271.5066021\ttotal: 7.77s\tremaining: 1.6s\n",
      "829:\tlearn: 531248.9784305\ttotal: 7.78s\tremaining: 1.59s\n",
      "830:\tlearn: 531216.7160237\ttotal: 7.79s\tremaining: 1.58s\n",
      "831:\tlearn: 531185.8088658\ttotal: 7.8s\tremaining: 1.57s\n",
      "832:\tlearn: 531167.0990719\ttotal: 7.81s\tremaining: 1.56s\n",
      "833:\tlearn: 531146.4729693\ttotal: 7.82s\tremaining: 1.55s\n",
      "834:\tlearn: 531117.5261200\ttotal: 7.82s\tremaining: 1.54s\n",
      "835:\tlearn: 531084.0768522\ttotal: 7.83s\tremaining: 1.54s\n",
      "836:\tlearn: 531076.5888248\ttotal: 7.84s\tremaining: 1.53s\n",
      "837:\tlearn: 531065.9499772\ttotal: 7.85s\tremaining: 1.52s\n",
      "838:\tlearn: 531052.2042453\ttotal: 7.85s\tremaining: 1.51s\n",
      "839:\tlearn: 531037.6249566\ttotal: 7.87s\tremaining: 1.5s\n",
      "840:\tlearn: 531027.3899691\ttotal: 7.88s\tremaining: 1.49s\n",
      "841:\tlearn: 531016.6296456\ttotal: 7.88s\tremaining: 1.48s\n",
      "842:\tlearn: 530992.9863747\ttotal: 7.89s\tremaining: 1.47s\n",
      "843:\tlearn: 530973.4618712\ttotal: 7.91s\tremaining: 1.46s\n",
      "844:\tlearn: 530966.9723447\ttotal: 7.92s\tremaining: 1.45s\n",
      "845:\tlearn: 530943.0644883\ttotal: 7.93s\tremaining: 1.44s\n",
      "846:\tlearn: 530929.3918143\ttotal: 7.93s\tremaining: 1.43s\n",
      "847:\tlearn: 530919.0144492\ttotal: 7.94s\tremaining: 1.42s\n",
      "848:\tlearn: 530909.1413563\ttotal: 7.95s\tremaining: 1.41s\n",
      "849:\tlearn: 530892.4257910\ttotal: 7.96s\tremaining: 1.4s\n",
      "850:\tlearn: 530889.3435423\ttotal: 7.97s\tremaining: 1.39s\n",
      "851:\tlearn: 530867.4088745\ttotal: 7.97s\tremaining: 1.38s\n",
      "852:\tlearn: 530852.3965812\ttotal: 7.98s\tremaining: 1.38s\n",
      "853:\tlearn: 530833.9759113\ttotal: 7.99s\tremaining: 1.37s\n",
      "854:\tlearn: 530829.3395920\ttotal: 8s\tremaining: 1.36s\n",
      "855:\tlearn: 530817.6650002\ttotal: 8.01s\tremaining: 1.35s\n",
      "856:\tlearn: 530802.5581057\ttotal: 8.02s\tremaining: 1.34s\n",
      "857:\tlearn: 530797.2898284\ttotal: 8.03s\tremaining: 1.33s\n",
      "858:\tlearn: 530785.1842706\ttotal: 8.04s\tremaining: 1.32s\n",
      "859:\tlearn: 530771.4352805\ttotal: 8.05s\tremaining: 1.31s\n",
      "860:\tlearn: 530762.2690066\ttotal: 8.06s\tremaining: 1.3s\n",
      "861:\tlearn: 530745.7204721\ttotal: 8.07s\tremaining: 1.29s\n",
      "862:\tlearn: 530742.6545280\ttotal: 8.07s\tremaining: 1.28s\n",
      "863:\tlearn: 530730.7444990\ttotal: 8.08s\tremaining: 1.27s\n",
      "864:\tlearn: 530714.6271207\ttotal: 8.09s\tremaining: 1.26s\n",
      "865:\tlearn: 530710.9075211\ttotal: 8.1s\tremaining: 1.25s\n",
      "866:\tlearn: 530674.1218294\ttotal: 8.11s\tremaining: 1.24s\n",
      "867:\tlearn: 530664.7327060\ttotal: 8.11s\tremaining: 1.23s\n",
      "868:\tlearn: 530634.2510638\ttotal: 8.13s\tremaining: 1.23s\n",
      "869:\tlearn: 530598.5393983\ttotal: 8.13s\tremaining: 1.22s\n",
      "870:\tlearn: 530582.6833607\ttotal: 8.14s\tremaining: 1.21s\n",
      "871:\tlearn: 530569.9863406\ttotal: 8.14s\tremaining: 1.2s\n",
      "872:\tlearn: 530548.4047221\ttotal: 8.16s\tremaining: 1.19s\n",
      "873:\tlearn: 530532.0360996\ttotal: 8.17s\tremaining: 1.18s\n",
      "874:\tlearn: 530499.2983884\ttotal: 8.17s\tremaining: 1.17s\n",
      "875:\tlearn: 530490.6383435\ttotal: 8.19s\tremaining: 1.16s\n",
      "876:\tlearn: 530478.8227033\ttotal: 8.2s\tremaining: 1.15s\n",
      "877:\tlearn: 530462.9605033\ttotal: 8.2s\tremaining: 1.14s\n",
      "878:\tlearn: 530434.2887896\ttotal: 8.21s\tremaining: 1.13s\n",
      "879:\tlearn: 530417.9306549\ttotal: 8.22s\tremaining: 1.12s\n",
      "880:\tlearn: 530406.7969604\ttotal: 8.23s\tremaining: 1.11s\n",
      "881:\tlearn: 530376.6543623\ttotal: 8.24s\tremaining: 1.1s\n",
      "882:\tlearn: 530373.4006058\ttotal: 8.25s\tremaining: 1.09s\n",
      "883:\tlearn: 530364.2558689\ttotal: 8.26s\tremaining: 1.08s\n",
      "884:\tlearn: 530346.4711191\ttotal: 8.27s\tremaining: 1.07s\n",
      "885:\tlearn: 530344.7782680\ttotal: 8.27s\tremaining: 1.06s\n",
      "886:\tlearn: 530337.5245976\ttotal: 8.28s\tremaining: 1.05s\n",
      "887:\tlearn: 530324.7484459\ttotal: 8.29s\tremaining: 1.04s\n",
      "888:\tlearn: 530314.7344979\ttotal: 8.3s\tremaining: 1.04s\n",
      "889:\tlearn: 530302.7829082\ttotal: 8.3s\tremaining: 1.03s\n",
      "890:\tlearn: 530292.1453582\ttotal: 8.31s\tremaining: 1.02s\n",
      "891:\tlearn: 530276.4599274\ttotal: 8.32s\tremaining: 1.01s\n",
      "892:\tlearn: 530260.3853486\ttotal: 8.33s\tremaining: 998ms\n",
      "893:\tlearn: 530232.4145166\ttotal: 8.33s\tremaining: 988ms\n",
      "894:\tlearn: 530222.5286896\ttotal: 8.34s\tremaining: 979ms\n",
      "895:\tlearn: 530218.0425878\ttotal: 8.35s\tremaining: 969ms\n",
      "896:\tlearn: 530212.2507443\ttotal: 8.36s\tremaining: 960ms\n",
      "897:\tlearn: 530203.1056713\ttotal: 8.37s\tremaining: 950ms\n",
      "898:\tlearn: 530176.4733858\ttotal: 8.37s\tremaining: 941ms\n",
      "899:\tlearn: 530165.5997482\ttotal: 8.39s\tremaining: 932ms\n",
      "900:\tlearn: 530157.0459153\ttotal: 8.39s\tremaining: 922ms\n",
      "901:\tlearn: 530148.6479090\ttotal: 8.4s\tremaining: 913ms\n",
      "902:\tlearn: 530144.5893522\ttotal: 8.42s\tremaining: 904ms\n",
      "903:\tlearn: 530128.8322395\ttotal: 8.43s\tremaining: 895ms\n",
      "904:\tlearn: 530118.8034462\ttotal: 8.43s\tremaining: 885ms\n",
      "905:\tlearn: 530095.0594040\ttotal: 8.44s\tremaining: 876ms\n",
      "906:\tlearn: 530091.9493247\ttotal: 8.45s\tremaining: 866ms\n",
      "907:\tlearn: 530079.6419076\ttotal: 8.45s\tremaining: 857ms\n",
      "908:\tlearn: 530070.8682416\ttotal: 8.46s\tremaining: 847ms\n",
      "909:\tlearn: 530054.9501685\ttotal: 8.47s\tremaining: 837ms\n",
      "910:\tlearn: 530042.8732684\ttotal: 8.48s\tremaining: 828ms\n",
      "911:\tlearn: 530028.8714020\ttotal: 8.49s\tremaining: 819ms\n",
      "912:\tlearn: 530024.4629273\ttotal: 8.49s\tremaining: 809ms\n",
      "913:\tlearn: 529999.8791015\ttotal: 8.5s\tremaining: 800ms\n",
      "914:\tlearn: 529987.2251453\ttotal: 8.51s\tremaining: 790ms\n",
      "915:\tlearn: 529979.3776970\ttotal: 8.52s\tremaining: 781ms\n",
      "916:\tlearn: 529974.7779184\ttotal: 8.52s\tremaining: 772ms\n",
      "917:\tlearn: 529965.9264154\ttotal: 8.53s\tremaining: 762ms\n",
      "918:\tlearn: 529940.2902169\ttotal: 8.54s\tremaining: 752ms\n",
      "919:\tlearn: 529924.8568936\ttotal: 8.54s\tremaining: 743ms\n",
      "920:\tlearn: 529897.9005923\ttotal: 8.55s\tremaining: 733ms\n",
      "921:\tlearn: 529871.8361748\ttotal: 8.55s\tremaining: 724ms\n",
      "922:\tlearn: 529859.6601562\ttotal: 8.56s\tremaining: 714ms\n",
      "923:\tlearn: 529836.4306954\ttotal: 8.57s\tremaining: 705ms\n",
      "924:\tlearn: 529831.9121141\ttotal: 8.58s\tremaining: 696ms\n",
      "925:\tlearn: 529819.2424053\ttotal: 8.59s\tremaining: 686ms\n",
      "926:\tlearn: 529817.3175757\ttotal: 8.6s\tremaining: 677ms\n",
      "927:\tlearn: 529796.2658061\ttotal: 8.61s\tremaining: 668ms\n",
      "928:\tlearn: 529789.1762227\ttotal: 8.62s\tremaining: 659ms\n",
      "929:\tlearn: 529786.2683625\ttotal: 8.63s\tremaining: 649ms\n",
      "930:\tlearn: 529781.9285582\ttotal: 8.64s\tremaining: 640ms\n",
      "931:\tlearn: 529774.9543277\ttotal: 8.65s\tremaining: 631ms\n",
      "932:\tlearn: 529764.9034623\ttotal: 8.65s\tremaining: 622ms\n",
      "933:\tlearn: 529762.5565157\ttotal: 8.67s\tremaining: 612ms\n",
      "934:\tlearn: 529759.0283705\ttotal: 8.68s\tremaining: 603ms\n",
      "935:\tlearn: 529751.2589614\ttotal: 8.69s\tremaining: 594ms\n",
      "936:\tlearn: 529748.9091980\ttotal: 8.69s\tremaining: 585ms\n",
      "937:\tlearn: 529743.5725221\ttotal: 8.71s\tremaining: 576ms\n",
      "938:\tlearn: 529739.5981413\ttotal: 8.72s\tremaining: 566ms\n",
      "939:\tlearn: 529735.1965252\ttotal: 8.72s\tremaining: 557ms\n",
      "940:\tlearn: 529717.2587856\ttotal: 8.73s\tremaining: 548ms\n",
      "941:\tlearn: 529708.0305685\ttotal: 8.74s\tremaining: 538ms\n",
      "942:\tlearn: 529701.3054876\ttotal: 8.75s\tremaining: 529ms\n",
      "943:\tlearn: 529699.7217787\ttotal: 8.75s\tremaining: 519ms\n",
      "944:\tlearn: 529687.3042603\ttotal: 8.76s\tremaining: 510ms\n",
      "945:\tlearn: 529680.4896554\ttotal: 8.78s\tremaining: 501ms\n",
      "946:\tlearn: 529675.7667368\ttotal: 8.78s\tremaining: 492ms\n",
      "947:\tlearn: 529672.9832873\ttotal: 8.79s\tremaining: 482ms\n",
      "948:\tlearn: 529656.5677057\ttotal: 8.8s\tremaining: 473ms\n",
      "949:\tlearn: 529641.2724959\ttotal: 8.81s\tremaining: 464ms\n",
      "950:\tlearn: 529635.2795483\ttotal: 8.82s\tremaining: 454ms\n",
      "951:\tlearn: 529608.5225756\ttotal: 8.83s\tremaining: 445ms\n",
      "952:\tlearn: 529604.4724448\ttotal: 8.84s\tremaining: 436ms\n",
      "953:\tlearn: 529588.5215734\ttotal: 8.85s\tremaining: 427ms\n",
      "954:\tlearn: 529582.8390831\ttotal: 8.85s\tremaining: 417ms\n",
      "955:\tlearn: 529567.7807094\ttotal: 8.86s\tremaining: 408ms\n",
      "956:\tlearn: 529557.2032861\ttotal: 8.87s\tremaining: 399ms\n",
      "957:\tlearn: 529553.7623419\ttotal: 8.88s\tremaining: 389ms\n",
      "958:\tlearn: 529547.4549363\ttotal: 8.89s\tremaining: 380ms\n",
      "959:\tlearn: 529536.3639682\ttotal: 8.9s\tremaining: 371ms\n",
      "960:\tlearn: 529524.9675144\ttotal: 8.9s\tremaining: 361ms\n",
      "961:\tlearn: 529504.8474067\ttotal: 8.91s\tremaining: 352ms\n",
      "962:\tlearn: 529496.2015693\ttotal: 8.92s\tremaining: 343ms\n",
      "963:\tlearn: 529487.9386037\ttotal: 8.93s\tremaining: 334ms\n",
      "964:\tlearn: 529480.3934920\ttotal: 8.94s\tremaining: 324ms\n",
      "965:\tlearn: 529451.8424050\ttotal: 8.94s\tremaining: 315ms\n",
      "966:\tlearn: 529448.7503910\ttotal: 8.95s\tremaining: 305ms\n",
      "967:\tlearn: 529432.4651851\ttotal: 8.96s\tremaining: 296ms\n",
      "968:\tlearn: 529426.6496044\ttotal: 8.97s\tremaining: 287ms\n",
      "969:\tlearn: 529400.8792482\ttotal: 8.98s\tremaining: 278ms\n",
      "970:\tlearn: 529376.6321658\ttotal: 8.99s\tremaining: 269ms\n",
      "971:\tlearn: 529373.6933886\ttotal: 9s\tremaining: 259ms\n",
      "972:\tlearn: 529366.2364418\ttotal: 9.01s\tremaining: 250ms\n",
      "973:\tlearn: 529357.8704182\ttotal: 9.02s\tremaining: 241ms\n",
      "974:\tlearn: 529333.3680333\ttotal: 9.03s\tremaining: 232ms\n",
      "975:\tlearn: 529303.1428644\ttotal: 9.04s\tremaining: 222ms\n",
      "976:\tlearn: 529282.0334225\ttotal: 9.04s\tremaining: 213ms\n",
      "977:\tlearn: 529262.1903459\ttotal: 9.05s\tremaining: 204ms\n",
      "978:\tlearn: 529247.1375620\ttotal: 9.06s\tremaining: 194ms\n",
      "979:\tlearn: 529219.3830402\ttotal: 9.06s\tremaining: 185ms\n",
      "980:\tlearn: 529202.0598633\ttotal: 9.07s\tremaining: 176ms\n",
      "981:\tlearn: 529179.5820859\ttotal: 9.08s\tremaining: 166ms\n",
      "982:\tlearn: 529159.7602313\ttotal: 9.09s\tremaining: 157ms\n",
      "983:\tlearn: 529131.1986259\ttotal: 9.1s\tremaining: 148ms\n",
      "984:\tlearn: 529116.4564090\ttotal: 9.11s\tremaining: 139ms\n",
      "985:\tlearn: 529070.5152446\ttotal: 9.11s\tremaining: 129ms\n",
      "986:\tlearn: 529050.5471742\ttotal: 9.12s\tremaining: 120ms\n",
      "987:\tlearn: 529003.8481520\ttotal: 9.13s\tremaining: 111ms\n",
      "988:\tlearn: 528979.5794261\ttotal: 9.13s\tremaining: 102ms\n",
      "989:\tlearn: 528966.3532105\ttotal: 9.14s\tremaining: 92.3ms\n",
      "990:\tlearn: 528953.7458182\ttotal: 9.15s\tremaining: 83.1ms\n",
      "991:\tlearn: 528926.9138342\ttotal: 9.16s\tremaining: 73.9ms\n",
      "992:\tlearn: 528923.5232840\ttotal: 9.17s\tremaining: 64.6ms\n",
      "993:\tlearn: 528920.1242214\ttotal: 9.17s\tremaining: 55.4ms\n",
      "994:\tlearn: 528911.4292062\ttotal: 9.19s\tremaining: 46.2ms\n",
      "995:\tlearn: 528907.3153512\ttotal: 9.19s\tremaining: 36.9ms\n",
      "996:\tlearn: 528904.6014399\ttotal: 9.2s\tremaining: 27.7ms\n",
      "997:\tlearn: 528896.2855713\ttotal: 9.22s\tremaining: 18.5ms\n",
      "998:\tlearn: 528870.2025877\ttotal: 9.22s\tremaining: 9.23ms\n",
      "999:\tlearn: 528866.0091614\ttotal: 9.23s\tremaining: 0us\n",
      "meta 0.13552640766121854\n"
     ]
    }
   ],
   "source": [
    "estimators = (\n",
    "    (\"lr\", lr),\n",
    "    (\"knn\", knn),\n",
    "    (\"lightgbm\", lightgbm),\n",
    "    (\"catboost\", catboost),\n",
    "    (\"rf\", rf),\n",
    ")\n",
    "\n",
    "meta = StackingRegressor(estimators=estimators, final_estimator=CatBoostRegressor(), n_jobs=-1)\n",
    "meta.fit(X_train, y_train)\n",
    "\n",
    "print(\"meta\", mean_absolute_percentage_error(y_valid, meta.predict(X_valid)))\n",
    "submit(test, meta, \"meta\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "326a131e1315163df5847284d7bac20ddee532ca1eaccb72a712d33a5c79e104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
