{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [previous file - EDA](2022-03-31_train-test_EDA.ipynb)\n",
    "- [next tile - models with pre-tuned parameters and ensembles](2022-04-15_ensemble.ipynb)\n",
    "\n",
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from warnings import filterwarnings, simplefilter\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import RobustScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, StackingRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from lib.model_related import *\n",
    "\n",
    "sns.set()\n",
    "filterwarnings(\"ignore\")\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((115367, 30), (34686, 28))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw = pd.read_parquet(\"data/2022-04-08_train_pre-model.parquet\")\n",
    "test_raw = pd.read_parquet(\"data/2022-04-08_test_pre-model.parquet\")\n",
    "\n",
    "train_raw.shape, test_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "currency_dict = {\n",
    "    \"2020-10-20\": 77.9241,\n",
    "    \"2020-10-19\": 77.9644,\n",
    "    \"2020-10-21\": 77.7780,\n",
    "    \"2020-10-25\": 76.4667,\n",
    "    \"2020-10-24\": 76.4667,\n",
    "    \"2020-10-26\": 76.4667,\n",
    "    \"2020-09-09\": 75.9645,\n",
    "    \"2021-09-27\": 73.0081,\n",
    "    \"2021-09-30\": 72.7608,\n",
    "    \"2021-09-26\": 73.0081,\n",
    "    \"2021-09-28\": 72.6613,\n",
    "    \"2021-09-29\": 72.5083,\n",
    "    \"2021-10-01\": 72.6642,\n",
    "}\n",
    "\n",
    "\n",
    "def submit(hold_out: pd.DataFrame, model, name=\"submission\"):\n",
    "    preds = model.predict(hold_out)\n",
    "    submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "    submission[\"price\"] = preds\n",
    "    submission.to_csv(f\"{name}.csv\", index=False)\n",
    "    \n",
    "    \n",
    "def submit_log(hold_out: pd.DataFrame, model, name=\"submission\"):\n",
    "    preds = model.predict(hold_out)\n",
    "    submission = pd.read_csv(\"data/sample_submission.csv\")\n",
    "    submission[\"price\"] = np.exp(preds)\n",
    "    submission.to_csv(f\"{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "158409758714.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_raw[\"price\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw[\"train/test\"] = \"train\"\n",
    "test_raw[\"train/test\"] = \"test\"\n",
    "\n",
    "data = train_raw.append(test_raw)\n",
    "data[\"ptc\"].fillna(\"Оригинал\", inplace=True)\n",
    "\n",
    "data[data.select_dtypes(\"object\").columns.tolist()] = data[\n",
    "    data.select_dtypes(\"object\").columns.tolist()\n",
    "].astype(str)\n",
    "\n",
    "for col in set(data.select_dtypes(exclude=(\"object\")).columns) - {\"price\"}:\n",
    "    data[col] = (\n",
    "        RobustScaler().fit_transform(data[col].values.reshape(-1, 1)).reshape(-1, 1)\n",
    "    )\n",
    "\n",
    "for col in [\"model_name\"]:\n",
    "    data[col] = LabelEncoder().fit_transform(data[col].astype(\"str\"))\n",
    "\n",
    "data = pd.get_dummies(\n",
    "    data,\n",
    "    columns=[\n",
    "        \"vehicle_transmission\",\n",
    "        \"vendor\",\n",
    "        \"brand\",\n",
    "        \"fuel_type\",\n",
    "        \"body_type\",\n",
    "        \"color\",\n",
    "        \"ptc\",\n",
    "        \"drive\",\n",
    "        \"wheel\",\n",
    "        \"age_cat\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "train = data.loc[data[\"train/test\"] == \"train\"]\n",
    "\n",
    "train_jane = train.loc[train[\"sample\"] == \"jane\"]\n",
    "train_sokolov = train.loc[train[\"sample\"] == \"sokolov\"]\n",
    "train_jane[\"price\"] = train_jane[\"price\"] * 0.86\n",
    "train = train_jane.append(train_sokolov)\n",
    "\n",
    "train.drop(columns=[\"sample\", \"description\", \"train/test\"], inplace=True)\n",
    "test = data.loc[data[\"train/test\"] == \"test\"].drop(\n",
    "    columns=[\"sample\", \"description\", \"train/test\", \"price\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "151033359642.84"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"price\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((86525, 112), (86525,), (28842, 112), (28842,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop(columns=\"price\"), train[\"price\"], random_state = 42, shuffle=True)\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "knn = KNeighborsRegressor().fit(X_train, y_train)\n",
    "lightgbm = LGBMRegressor(random_state=42, silent=True).fit(X_train, y_train)\n",
    "catboost = CatBoostRegressor(random_state=42, silent=True).fit(X_train, y_train)\n",
    "rf = RandomForestRegressor(random_state=42).fit(X_train, y_train)\n",
    "rf_log = RandomForestRegressor(random_state=42).fit(X_train, np.log(y_train))\n",
    "etr = ExtraTreesRegressor(random_state=42).fit(X_train, y_train)\n",
    "etr_log = ExtraTreesRegressor(random_state=42).fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 0.7946185682561607\n",
      "knn 0.16951330279094057\n",
      "lightgbm 0.19102466397466208\n",
      "catboost 0.1584574973807607\n",
      "rf 0.13804863667174702\n"
     ]
    }
   ],
   "source": [
    "print(\"lr\", mean_absolute_percentage_error(y_valid, lr.predict(X_valid)))\n",
    "print(\"knn\", mean_absolute_percentage_error(y_valid, knn.predict(X_valid)))\n",
    "print(\"lightgbm\", mean_absolute_percentage_error(y_valid, lightgbm.predict(X_valid)))\n",
    "print(\"catboost\", mean_absolute_percentage_error(y_valid, catboost.predict(X_valid)))\n",
    "print(\"rf\", mean_absolute_percentage_error(y_valid, rf.predict(X_valid)))\n",
    "print(\"rf_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_log.predict(X_valid))))\n",
    "print(\"etr\", mean_absolute_percentage_error(y_valid, etr.predict(X_valid)))\n",
    "print(\"etr_log\", mean_absolute_percentage_error(y_valid, np.exp(etr.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dumb model submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(test, lr, \"lr\")\n",
    "submit(test, knn, \"knn\")\n",
    "submit(test, lightgbm, \"lightgbm\")\n",
    "submit(test, catboost, \"catboost\")\n",
    "submit(test, rf, \"rf\")\n",
    "submit(test, etr, \"etr\")\n",
    "submit_log(test, rf_log, \"rf_log\")\n",
    "submit_log(test, etr_log, \"etr_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit(test, etr, \"etr\")\n",
    "submit_log(test, etr_log, \"etr_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lightgbm\n",
    "\n",
    "[notebook with related experiments](model_LightGBM_optuna.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:35:33,204]\u001b[0m Using an existing study with name 'LGBMClassifier' instead of creating a new one.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8695690383435876, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8695690383435876\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.012791850966944924, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.012791850966944924\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8270468476213303e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8270468476213303e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7698606143353843, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7698606143353843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:35:47,095]\u001b[0m Trial 5 finished with value: -0.20253670583254396 and parameters: {'learning_rate': 0.07992724445501892, 'lambda_l1': 1.8270468476213303e-05, 'lambda_l2': 0.012791850966944924, 'num_leaves': 28, 'feature_fraction': 0.7698606143353843, 'bagging_fraction': 0.8695690383435876, 'bagging_freq': 2, 'min_child_samples': 48}. Best is trial 5 with value: -0.20253670583254396.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6079090066839168, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6079090066839168\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.9963207632140944e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.9963207632140944e-05\n",
      "[LightGBM] [Warning] lambda_l1 is set=7.552664420954056e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=7.552664420954056e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7340966128567723, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7340966128567723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:35:59,590]\u001b[0m Trial 6 finished with value: -0.257565168367874 and parameters: {'learning_rate': 0.744263685304623, 'lambda_l1': 7.552664420954056e-07, 'lambda_l2': 1.9963207632140944e-05, 'num_leaves': 201, 'feature_fraction': 0.7340966128567723, 'bagging_fraction': 0.6079090066839168, 'bagging_freq': 1, 'min_child_samples': 52}. Best is trial 5 with value: -0.20253670583254396.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6354145080468188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6354145080468188\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.49107163604631077, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.49107163604631077\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.529044942764546e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.529044942764546e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5426396065593337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5426396065593337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:08,280]\u001b[0m Trial 7 finished with value: -0.1745456552518454 and parameters: {'learning_rate': 0.4216546930140595, 'lambda_l1': 5.529044942764546e-08, 'lambda_l2': 0.49107163604631077, 'num_leaves': 142, 'feature_fraction': 0.5426396065593337, 'bagging_fraction': 0.6354145080468188, 'bagging_freq': 3, 'min_child_samples': 12}. Best is trial 7 with value: -0.1745456552518454.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6779233529792716, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6779233529792716\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9449322532268776e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9449322532268776e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.858478690290897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.858478690290897e-06\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.679286165875125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.679286165875125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:18,834]\u001b[0m Trial 8 finished with value: -0.2432717613049581 and parameters: {'learning_rate': 0.7172956964597691, 'lambda_l1': 5.858478690290897e-06, 'lambda_l2': 3.9449322532268776e-08, 'num_leaves': 154, 'feature_fraction': 0.679286165875125, 'bagging_fraction': 0.6779233529792716, 'bagging_freq': 4, 'min_child_samples': 70}. Best is trial 7 with value: -0.1745456552518454.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:28,581]\u001b[0m Trial 9 finished with value: -0.1567960005144171 and parameters: {'learning_rate': 0.24273738931459424, 'lambda_l1': 0.0007127314011370048, 'lambda_l2': 1.4991431139899208e-08, 'num_leaves': 129, 'feature_fraction': 0.716472706585253, 'bagging_fraction': 0.9079273070338828, 'bagging_freq': 4, 'min_child_samples': 27}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.52462564650187, subsample=1.0 will be ignored. Current value: bagging_fraction=0.52462564650187\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.00024184845376432643, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00024184845376432643\n",
      "[LightGBM] [Warning] lambda_l1 is set=8.976874193475037e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.976874193475037e-05\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6342281343794924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6342281343794924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:38,610]\u001b[0m Trial 10 finished with value: -0.3571169344261295 and parameters: {'learning_rate': 0.9494423379774705, 'lambda_l1': 8.976874193475037e-05, 'lambda_l2': 0.00024184845376432643, 'num_leaves': 160, 'feature_fraction': 0.6342281343794924, 'bagging_fraction': 0.52462564650187, 'bagging_freq': 5, 'min_child_samples': 74}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7728914806928449, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7728914806928449\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.646369546324295e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.646369546324295e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.8437884236649082, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.8437884236649082\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6137958863887523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6137958863887523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:36:50,387]\u001b[0m Trial 11 finished with value: -0.22698765690534695 and parameters: {'learning_rate': 0.773164422222387, 'lambda_l1': 1.8437884236649082, 'lambda_l2': 5.646369546324295e-07, 'num_leaves': 225, 'feature_fraction': 0.6137958863887523, 'bagging_fraction': 0.7728914806928449, 'bagging_freq': 6, 'min_child_samples': 22}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4972661166651129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4972661166651129\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.8521960471096605e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.8521960471096605e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=0.655717669029221, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.655717669029221\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7442760753734905, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7442760753734905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:37:03,343]\u001b[0m Trial 12 finished with value: -0.25967795465332394 and parameters: {'learning_rate': 0.02716689002528746, 'lambda_l1': 0.655717669029221, 'lambda_l2': 3.8521960471096605e-07, 'num_leaves': 225, 'feature_fraction': 0.7442760753734905, 'bagging_fraction': 0.4972661166651129, 'bagging_freq': 2, 'min_child_samples': 78}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636[LightGBM] [Warning] bagging_fraction is set=0.9710703037180636, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9710703037180636\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n",
      "\n",
      "[LightGBM] [Warning] lambda_l2 is set=5.616679588596495e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=5.616679588596495e-07\n",
      "[LightGBM] [Warning] lambda_l1 is set=5.5278340137009336e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.5278340137009336e-08\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7415789372960532, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7415789372960532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:37:13,613]\u001b[0m Trial 13 finished with value: -0.15895263105959045 and parameters: {'learning_rate': 0.25542847231451854, 'lambda_l1': 5.5278340137009336e-08, 'lambda_l2': 5.616679588596495e-07, 'num_leaves': 112, 'feature_fraction': 0.7415789372960532, 'bagging_fraction': 0.9710703037180636, 'bagging_freq': 4, 'min_child_samples': 42}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "/home/user/Documents/sf_project_6/venv/lib64/python3.10/site-packages/lightgbm/sklearn.py:598: UserWarning: 'silent' argument is deprecated and will be removed in a future release of LightGBM. Pass 'verbose' parameter via keyword arguments instead.\n",
      "  _log_warning(\"'silent' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8175936493895224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8175936493895224\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.001308364765353021, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001308364765353021\n",
      "[LightGBM] [Warning] lambda_l1 is set=1.31641269168062e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.31641269168062e-07\n",
      "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
      "[LightGBM] [Warning] feature_fraction is set=0.814929774720756, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.814929774720756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-12 22:37:24,776]\u001b[0m Trial 14 finished with value: -0.25642212193797126 and parameters: {'learning_rate': 0.9889916200650344, 'lambda_l1': 1.31641269168062e-07, 'lambda_l2': 0.001308364765353021, 'num_leaves': 181, 'feature_fraction': 0.814929774720756, 'bagging_fraction': 0.8175936493895224, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 9 with value: -0.1567960005144171.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"objective\": \"regression\",\n",
    "        \"metric\": \"mape\",\n",
    "        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.001, 1.0),\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "        \"verbosity\": -1,\n",
    "    }\n",
    "\n",
    "    gbm = LGBMRegressor(**param, silent=True)\n",
    "    cv_roc_auc = cross_val_score(gbm, X_train, y_train, cv=8, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///LGBMRegressor.db\",\n",
    "    study_name=\"LGBMRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, timeout=600, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.9079273070338828,\n",
       " 'bagging_freq': 4,\n",
       " 'feature_fraction': 0.716472706585253,\n",
       " 'lambda_l1': 0.0007127314011370048,\n",
       " 'lambda_l2': 1.4991431139899208e-08,\n",
       " 'learning_rate': 0.24273738931459424,\n",
       " 'min_child_samples': 27,\n",
       " 'num_leaves': 129}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] lambda_l1 is set=0.0007127314011370048, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007127314011370048\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9079273070338828, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9079273070338828\n",
      "[LightGBM] [Warning] feature_fraction is set=0.716472706585253, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.716472706585253\n",
      "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
      "[LightGBM] [Warning] lambda_l2 is set=1.4991431139899208e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4991431139899208e-08\n",
      "lightgbm_optuned 0.1562352982059385\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned = LGBMRegressor(\n",
    "    **{\n",
    "        \"bagging_fraction\": 0.9079273070338828,\n",
    "        \"bagging_freq\": 4,\n",
    "        \"feature_fraction\": 0.716472706585253,\n",
    "        \"lambda_l1\": 0.0007127314011370048,\n",
    "        \"lambda_l2\": 1.4991431139899208e-08,\n",
    "        \"learning_rate\": 0.24273738931459424,\n",
    "        \"min_child_samples\": 27,\n",
    "        \"num_leaves\": 129,\n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True,\n",
    "    }\n",
    ").fit(X_train, y_train)\n",
    "\n",
    "print(\"lightgbm_optuned\", mean_absolute_percentage_error(y_valid, lightgbm_optuned.predict(X_valid)))\n",
    "submit(test, lightgbm_optuned, \"lightgbm_optuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7849386830734889, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7849386830734889\n",
      "[LightGBM] [Warning] lambda_l1 is set=3.6405456215002115e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.6405456215002115e-08\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.999471799816821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.999471799816821\n",
      "[LightGBM] [Warning] lambda_l2 is set=3.9256724979441087, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.9256724979441087\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "lightgbm_optuned_1899_log 0.1266083430966481\n"
     ]
    }
   ],
   "source": [
    "lightgbm_optuned_1899 = LGBMRegressor(\n",
    "    **{\n",
    "        'learning_rate': 0.2200394016092361, \n",
    "        'lambda_l1': 3.6405456215002115e-08, \n",
    "        'lambda_l2': 3.9256724979441087, \n",
    "        'num_leaves': 251, \n",
    "        'feature_fraction': 0.7849386830734889, \n",
    "        'bagging_fraction': 0.999471799816821, \n",
    "        'bagging_freq': 7, \n",
    "        'min_child_samples': 5, \n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))\n",
    "\n",
    "print(\"lightgbm_optuned_1899_log\", mean_absolute_percentage_error(y_valid, np.exp(lightgbm_optuned_1899.predict(X_valid))))\n",
    "submit_log(test, lightgbm_optuned_1899, \"lightgbm_optuned_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN\n",
    "\n",
    "[notebook with related experiments](model_KNN_optuna.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-13 18:13:06,186]\u001b[0m Using an existing study with name 'KNNRegressor' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:23:22,123]\u001b[0m Trial 47 finished with value: -0.1642623637534808 and parameters: {'n_neighbors': 7, 'leaf_size': 38, 'p': 2, 'weights': 'uniform', 'metric': 'manhattan'}. Best is trial 44 with value: -0.15464020043822252.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:33:32,685]\u001b[0m Trial 48 finished with value: -0.1582071567694789 and parameters: {'n_neighbors': 8, 'leaf_size': 45, 'p': 2, 'weights': 'distance', 'metric': 'manhattan'}. Best is trial 44 with value: -0.15464020043822252.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        'n_neighbors': trial.suggest_int(\"n_neighbors\", 1, 30),\n",
    "        'leaf_size': trial.suggest_int(\"leaf_size\", 1, 50),\n",
    "        'p': trial.suggest_int(\"p\", 1, 2),\n",
    "        'weights': trial.suggest_categorical(\"weights\", ['uniform', 'distance']),\n",
    "        'metric': trial.suggest_categorical(\"metric\", ['euclidean', 'manhattan', 'minkowski'])\n",
    "    }\n",
    "\n",
    "    knn = KNeighborsRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(knn, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///KNNRegressor.db\",\n",
    "    study_name=\"KNNRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'leaf_size': 41,\n",
       " 'metric': 'manhattan',\n",
       " 'n_neighbors': 8,\n",
       " 'p': 2,\n",
       " 'weights': 'distance'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn_optuned_32 0.14258679506496774\n"
     ]
    }
   ],
   "source": [
    "knn_optuned_32 = KNeighborsRegressor(\n",
    "    **{\n",
    "        'n_neighbors': 9, \n",
    "        'leaf_size': 41, \n",
    "        'p': 1, \n",
    "        'weights': 'distance', \n",
    "        'metric': 'manhattan'\n",
    "    }\n",
    ").fit(X_train, np.log(y_train))\n",
    "\n",
    "print(\"knn_optuned_32\", mean_absolute_percentage_error(y_valid, np.exp(knn_optuned_32.predict(X_valid))))\n",
    "submit_log(test, knn_optuned_32, \"knn_optuned_32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest\n",
    "\n",
    "[notebook with relative experiments](model_RandomForest_optuna.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-13 18:46:09,425]\u001b[0m Using an existing study with name 'RFRRegressor' instead of creating a new one.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:46:22,263]\u001b[0m Trial 7 finished with value: -0.2503358825689884 and parameters: {'n_estimators': 209, 'min_samples_split': 12, 'min_samples_leaf': 7, 'max_samples': 0.6170731668968928, 'max_features': 'log2'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:46:41,167]\u001b[0m Trial 8 finished with value: -0.20956902989733972 and parameters: {'n_estimators': 239, 'min_samples_split': 8, 'min_samples_leaf': 11, 'max_samples': 0.6960737412613612, 'max_features': 'sqrt'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:47:20,333]\u001b[0m Trial 9 finished with value: -0.18754078091628576 and parameters: {'n_estimators': 472, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_samples': 0.9109759310947507, 'max_features': 'log2'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n",
      "\u001b[32m[I 2022-04-13 18:47:39,851]\u001b[0m Trial 10 finished with value: -0.20136877770336822 and parameters: {'n_estimators': 226, 'min_samples_split': 9, 'min_samples_leaf': 10, 'max_samples': 0.8806474785871083, 'max_features': 'sqrt'}. Best is trial 3 with value: -0.15965928060336795.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "        'max_samples': trial.suggest_uniform('max_samples', 0.6, 0.99),\n",
    "        'max_features': trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", 'log2']),\n",
    "        'max_depth': None,\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    rfr_o = RandomForestRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(rfr_o, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///RFRRegressor.db\",\n",
    "    study_name=\"RFRRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuned by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_tuned = RandomForestRegressor(\n",
    "    random_state=42,\n",
    "    n_estimators=800,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='log2',\n",
    "    max_depth=None,\n",
    "    bootstrap=True\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf_tuned_log 0.1315354887566232\n"
     ]
    }
   ],
   "source": [
    "print(\"rf_tuned_log\", mean_absolute_percentage_error(y_valid, np.exp(rf_tuned.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree Regressor\n",
    "\n",
    "[notebook with related experiments](model_ExtraTrees_optuna.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 14),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 14),\n",
    "        'max_samples': trial.suggest_uniform('max_samples', 0.6, 0.99),\n",
    "        'max_features': trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", 'log2']),\n",
    "        'max_depth': None,\n",
    "        'bootstrap': True,\n",
    "        'random_state': 42\n",
    "    }\n",
    "\n",
    "    etr_o = ExtraTreesRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(etr_o, X_train, y_train, cv=3, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///ETRRegressor.db\",\n",
    "    study_name=\"ETRRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.0s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed:  5.1min finished\n"
     ]
    }
   ],
   "source": [
    "etr_cust = ExtraTreesRegressor(\n",
    "    n_estimators=800,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='auto',\n",
    "    max_depth=15,\n",
    "    bootstrap=True,\n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done 192 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=4)]: Done 442 tasks      | elapsed:    0.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "etr_cust_log 0.1376278076519815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done 792 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=4)]: Done 800 out of 800 | elapsed:    1.8s finished\n"
     ]
    }
   ],
   "source": [
    "print(\"etr_cust_log\", mean_absolute_percentage_error(y_valid, np.exp(etr_cust.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "[notebook with related experiments](2022-04-12_experiments-sklearn.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbgr_custom = xgb.XGBRegressor(\n",
    "    objective='reg:squarederror',\n",
    "    colsample_bytree=0.5,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=12,\n",
    "    alpha=1,\n",
    "    n_estimators=1000,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ").fit(X_train, np.log(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xbgr_custom_log 0.1196754346388126\n"
     ]
    }
   ],
   "source": [
    "print(\"xbgr_custom_log\", mean_absolute_percentage_error(y_valid, np.exp(xbgr_custom.predict(X_valid))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_log(test, xbgr_custom, \"xbgr_custom_log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-04-17 10:00:54,618]\u001b[0m Using an existing study with name 'XGBRegressor' instead of creating a new one.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    param = {\n",
    "        \"verbosity\": 0,\n",
    "        \"gpu_id\": 0,\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "        \"random_state\": 42,\n",
    "        \"silent\": True,\n",
    "        \"n_jobs\": -1,\n",
    "        \"objective\": trial.suggest_categorical(\"objective\", [\"reg:linear\", \"reg:squaredlogerror\", \"reg:squarederror\"]),\n",
    "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
    "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
    "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 100, 1200),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-8, 1.0, log=True),\n",
    "    }\n",
    "\n",
    "    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
    "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
    "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
    "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
    "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
    "\n",
    "    if param[\"booster\"] == \"dart\":\n",
    "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
    "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
    "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
    "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
    "\n",
    "    bst = xgb.XGBRegressor(**param)\n",
    "    cv_roc_auc = cross_val_score(bst, X_train, np.log(y_train), cv=5, scoring=\"neg_mean_absolute_percentage_error\", n_jobs=-1)\n",
    "\n",
    "    return np.mean(cv_roc_auc)\n",
    "\n",
    "\n",
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    storage=\"sqlite:///XGBRegressor.db\",\n",
    "    study_name=\"XGBRegressor\",\n",
    "    load_if_exists=True,\n",
    ")\n",
    "study.optimize(objective, timeout=300000, n_trials=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>132</th>\n",
       "      <th>139</th>\n",
       "      <th>134</th>\n",
       "      <th>138</th>\n",
       "      <th>135</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>132</td>\n",
       "      <td>139</td>\n",
       "      <td>134</td>\n",
       "      <td>138</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>value</th>\n",
       "      <td>-0.009002</td>\n",
       "      <td>-0.009009</td>\n",
       "      <td>-0.00901</td>\n",
       "      <td>-0.00901</td>\n",
       "      <td>-0.009012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_start</th>\n",
       "      <td>2022-04-16 12:05:04.824973</td>\n",
       "      <td>2022-04-16 13:10:35.521157</td>\n",
       "      <td>2022-04-16 12:22:37.886102</td>\n",
       "      <td>2022-04-16 13:00:47.757864</td>\n",
       "      <td>2022-04-16 12:32:32.251526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime_complete</th>\n",
       "      <td>2022-04-16 12:14:01.571815</td>\n",
       "      <td>2022-04-16 13:21:37.360942</td>\n",
       "      <td>2022-04-16 12:32:32.163352</td>\n",
       "      <td>2022-04-16 13:10:35.454031</td>\n",
       "      <td>2022-04-16 12:41:59.566287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0 days 00:08:56.746842</td>\n",
       "      <td>0 days 00:11:01.839785</td>\n",
       "      <td>0 days 00:09:54.277250</td>\n",
       "      <td>0 days 00:09:47.696167</td>\n",
       "      <td>0 days 00:09:27.314761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_alpha</th>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.044903</td>\n",
       "      <td>0.040829</td>\n",
       "      <td>0.051765</td>\n",
       "      <td>0.038873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_booster</th>\n",
       "      <td>gbtree</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>gbtree</td>\n",
       "      <td>gbtree</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_colsample_bytree</th>\n",
       "      <td>0.260759</td>\n",
       "      <td>0.278286</td>\n",
       "      <td>0.226234</td>\n",
       "      <td>0.221294</td>\n",
       "      <td>0.225607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_eta</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_gamma</th>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.00048</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.002135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_grow_policy</th>\n",
       "      <td>depthwise</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>depthwise</td>\n",
       "      <td>depthwise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_lambda</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_learning_rate</th>\n",
       "      <td>0.024233</td>\n",
       "      <td>0.029622</td>\n",
       "      <td>0.025823</td>\n",
       "      <td>0.026813</td>\n",
       "      <td>0.026185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_max_depth</th>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_min_child_weight</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_n_estimators</th>\n",
       "      <td>690</td>\n",
       "      <td>736</td>\n",
       "      <td>737</td>\n",
       "      <td>768</td>\n",
       "      <td>729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_normalize_type</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_objective</th>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>reg:squarederror</td>\n",
       "      <td>reg:squarederror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_rate_drop</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_sample_type</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_skip_drop</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>params_subsample</th>\n",
       "      <td>0.7188</td>\n",
       "      <td>0.720311</td>\n",
       "      <td>0.717036</td>\n",
       "      <td>0.71195</td>\n",
       "      <td>0.709882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system_attrs_fixed_params</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>COMPLETE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  132  \\\n",
       "number                                            132   \n",
       "value                                       -0.009002   \n",
       "datetime_start             2022-04-16 12:05:04.824973   \n",
       "datetime_complete          2022-04-16 12:14:01.571815   \n",
       "duration                       0 days 00:08:56.746842   \n",
       "params_alpha                                 0.039254   \n",
       "params_booster                                 gbtree   \n",
       "params_colsample_bytree                      0.260759   \n",
       "params_eta                                        0.0   \n",
       "params_gamma                                 0.001405   \n",
       "params_grow_policy                          depthwise   \n",
       "params_lambda                                     0.0   \n",
       "params_learning_rate                         0.024233   \n",
       "params_max_depth                                 15.0   \n",
       "params_min_child_weight                           7.0   \n",
       "params_n_estimators                               690   \n",
       "params_normalize_type                             NaN   \n",
       "params_objective                     reg:squarederror   \n",
       "params_rate_drop                                  NaN   \n",
       "params_sample_type                                NaN   \n",
       "params_skip_drop                                  NaN   \n",
       "params_subsample                               0.7188   \n",
       "system_attrs_fixed_params                         NaN   \n",
       "state                                        COMPLETE   \n",
       "\n",
       "                                                  139  \\\n",
       "number                                            139   \n",
       "value                                       -0.009009   \n",
       "datetime_start             2022-04-16 13:10:35.521157   \n",
       "datetime_complete          2022-04-16 13:21:37.360942   \n",
       "duration                       0 days 00:11:01.839785   \n",
       "params_alpha                                 0.044903   \n",
       "params_booster                                 gbtree   \n",
       "params_colsample_bytree                      0.278286   \n",
       "params_eta                                        0.0   \n",
       "params_gamma                                  0.00048   \n",
       "params_grow_policy                          depthwise   \n",
       "params_lambda                                     0.0   \n",
       "params_learning_rate                         0.029622   \n",
       "params_max_depth                                 15.0   \n",
       "params_min_child_weight                           6.0   \n",
       "params_n_estimators                               736   \n",
       "params_normalize_type                             NaN   \n",
       "params_objective                     reg:squarederror   \n",
       "params_rate_drop                                  NaN   \n",
       "params_sample_type                                NaN   \n",
       "params_skip_drop                                  NaN   \n",
       "params_subsample                             0.720311   \n",
       "system_attrs_fixed_params                         NaN   \n",
       "state                                        COMPLETE   \n",
       "\n",
       "                                                  134  \\\n",
       "number                                            134   \n",
       "value                                        -0.00901   \n",
       "datetime_start             2022-04-16 12:22:37.886102   \n",
       "datetime_complete          2022-04-16 12:32:32.163352   \n",
       "duration                       0 days 00:09:54.277250   \n",
       "params_alpha                                 0.040829   \n",
       "params_booster                                 gbtree   \n",
       "params_colsample_bytree                      0.226234   \n",
       "params_eta                                        0.0   \n",
       "params_gamma                                 0.000689   \n",
       "params_grow_policy                          depthwise   \n",
       "params_lambda                                     0.0   \n",
       "params_learning_rate                         0.025823   \n",
       "params_max_depth                                 15.0   \n",
       "params_min_child_weight                           6.0   \n",
       "params_n_estimators                               737   \n",
       "params_normalize_type                             NaN   \n",
       "params_objective                     reg:squarederror   \n",
       "params_rate_drop                                  NaN   \n",
       "params_sample_type                                NaN   \n",
       "params_skip_drop                                  NaN   \n",
       "params_subsample                             0.717036   \n",
       "system_attrs_fixed_params                         NaN   \n",
       "state                                        COMPLETE   \n",
       "\n",
       "                                                  138  \\\n",
       "number                                            138   \n",
       "value                                        -0.00901   \n",
       "datetime_start             2022-04-16 13:00:47.757864   \n",
       "datetime_complete          2022-04-16 13:10:35.454031   \n",
       "duration                       0 days 00:09:47.696167   \n",
       "params_alpha                                 0.051765   \n",
       "params_booster                                 gbtree   \n",
       "params_colsample_bytree                      0.221294   \n",
       "params_eta                                        0.0   \n",
       "params_gamma                                 0.000608   \n",
       "params_grow_policy                          depthwise   \n",
       "params_lambda                                     0.0   \n",
       "params_learning_rate                         0.026813   \n",
       "params_max_depth                                 15.0   \n",
       "params_min_child_weight                           6.0   \n",
       "params_n_estimators                               768   \n",
       "params_normalize_type                             NaN   \n",
       "params_objective                     reg:squarederror   \n",
       "params_rate_drop                                  NaN   \n",
       "params_sample_type                                NaN   \n",
       "params_skip_drop                                  NaN   \n",
       "params_subsample                              0.71195   \n",
       "system_attrs_fixed_params                         NaN   \n",
       "state                                        COMPLETE   \n",
       "\n",
       "                                                  135  \n",
       "number                                            135  \n",
       "value                                       -0.009012  \n",
       "datetime_start             2022-04-16 12:32:32.251526  \n",
       "datetime_complete          2022-04-16 12:41:59.566287  \n",
       "duration                       0 days 00:09:27.314761  \n",
       "params_alpha                                 0.038873  \n",
       "params_booster                                 gbtree  \n",
       "params_colsample_bytree                      0.225607  \n",
       "params_eta                                        0.0  \n",
       "params_gamma                                 0.002135  \n",
       "params_grow_policy                          depthwise  \n",
       "params_lambda                                     0.0  \n",
       "params_learning_rate                         0.026185  \n",
       "params_max_depth                                 15.0  \n",
       "params_min_child_weight                           6.0  \n",
       "params_n_estimators                               729  \n",
       "params_normalize_type                             NaN  \n",
       "params_objective                     reg:squarederror  \n",
       "params_rate_drop                                  NaN  \n",
       "params_sample_type                                NaN  \n",
       "params_skip_drop                                  NaN  \n",
       "params_subsample                             0.709882  \n",
       "system_attrs_fixed_params                         NaN  \n",
       "state                                        COMPLETE  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.trials_dataframe().sort_values([\"value\"], ascending=False).head(5).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### xgb_top_5_trials_2022-04-17_02:33\n",
    "\n",
    "- 132, MAPE: 11.966969441437784, kaggle: 11.96653\n",
    "- 139, MAPE: 11.97832901549609,  kaggle: 11.74262\n",
    "- 134, MAPE: 11.985533638729201, kaggle: 11.95685\n",
    "- 138, MAPE: 11.966599705599973, kaggle: 11.96863\n",
    "- 135, MAPE: 11.981782802335061, kaggle: 11.96509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132 \n",
      " {'alpha': 0.03925389731467428, 'booster': 'gbtree', 'colsample_bytree': 0.26075928432491174, 'eta': 3.3548685374081315e-08, 'gamma': 0.001404801600815511, 'grow_policy': 'depthwise', 'lambda': 1.0060252873701642e-07, 'learning_rate': 0.024232938602382983, 'max_depth': 15, 'min_child_weight': 7, 'n_estimators': 690, 'objective': 'reg:squarederror', 'subsample': 0.7188003743982521}\n",
      "xgb_v2_trial_132 0.11966969441437784\n",
      "\n",
      "139 \n",
      " {'alpha': 0.044903341303693216, 'booster': 'gbtree', 'colsample_bytree': 0.2782856821187278, 'eta': 3.4353303842042365e-08, 'gamma': 0.00048033429580361897, 'grow_policy': 'depthwise', 'lambda': 4.940599898474283e-07, 'learning_rate': 0.029621998365714833, 'max_depth': 15, 'min_child_weight': 6, 'n_estimators': 736, 'objective': 'reg:squarederror', 'subsample': 0.7203114713416401}\n",
      "xgb_v2_trial_139 0.1197832901549609\n",
      "\n",
      "134 \n",
      " {'alpha': 0.04082934708230299, 'booster': 'gbtree', 'colsample_bytree': 0.22623415245800638, 'eta': 1.0664131679536447e-07, 'gamma': 0.000689270859560641, 'grow_policy': 'depthwise', 'lambda': 6.770838081121939e-08, 'learning_rate': 0.025822685876121236, 'max_depth': 15, 'min_child_weight': 6, 'n_estimators': 737, 'objective': 'reg:squarederror', 'subsample': 0.7170355892394429}\n",
      "xgb_v2_trial_134 0.11985533638729201\n",
      "\n",
      "138 \n",
      " {'alpha': 0.051765277735018364, 'booster': 'gbtree', 'colsample_bytree': 0.2212940434925123, 'eta': 3.3507098214272523e-08, 'gamma': 0.0006079680292075562, 'grow_policy': 'depthwise', 'lambda': 6.763906359768837e-08, 'learning_rate': 0.02681287169343113, 'max_depth': 15, 'min_child_weight': 6, 'n_estimators': 768, 'objective': 'reg:squarederror', 'subsample': 0.7119504575515015}\n",
      "xgb_v2_trial_138 0.11966599705599973\n",
      "\n",
      "135 \n",
      " {'alpha': 0.038873001965465656, 'booster': 'gbtree', 'colsample_bytree': 0.22560678633244335, 'eta': 3.1083179079427506e-08, 'gamma': 0.0021350897675073985, 'grow_policy': 'depthwise', 'lambda': 7.313189453294979e-08, 'learning_rate': 0.026184874827013874, 'max_depth': 15, 'min_child_weight': 6, 'n_estimators': 729, 'objective': 'reg:squarederror', 'subsample': 0.709882475594411}\n",
      "xgb_v2_trial_135 0.11981782802335061\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for p in (\n",
    "    study.trials_dataframe().sort_values([\"value\"], ascending=False).head(5).number\n",
    "):\n",
    "    print(p, \"\\n\", study.trials[p].params)\n",
    "\n",
    "    xgboost_log = xgb.XGBRegressor(\n",
    "        verbosity=0,\n",
    "        gpu_id=0,\n",
    "        tree_method=\"gpu_hist\",\n",
    "        random_state=42,\n",
    "        silent=True,\n",
    "        n_jobs=-1,\n",
    "        **study.trials[p].params,\n",
    "    ).fit(X_train, np.log(y_train))\n",
    "\n",
    "    print(\n",
    "        f\"xgb_v2_trial_{p}\",\n",
    "        mean_absolute_percentage_error(y_valid, np.exp(xgboost_log.predict(X_valid))),\n",
    "        end=\"\\n\\n\",\n",
    "    )\n",
    "\n",
    "    submit_log(test, xgboost_log, f\"xgb_v2_trial_{p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.082841\n",
      "0:\tlearn: 1707761.0355068\ttotal: 7.34ms\tremaining: 7.34s\n",
      "1:\tlearn: 1591308.9956367\ttotal: 18.8ms\tremaining: 9.37s\n",
      "2:\tlearn: 1485016.6045297\ttotal: 27.9ms\tremaining: 9.26s\n",
      "3:\tlearn: 1389132.0663577\ttotal: 33.5ms\tremaining: 8.34s\n",
      "4:\tlearn: 1301083.1721720\ttotal: 39.4ms\tremaining: 7.85s\n",
      "5:\tlearn: 1222258.3138665\ttotal: 49.4ms\tremaining: 8.19s\n",
      "6:\tlearn: 1151623.2575788\ttotal: 60.6ms\tremaining: 8.59s\n",
      "7:\tlearn: 1087972.9192920\ttotal: 68ms\tremaining: 8.43s\n",
      "8:\tlearn: 1031155.5343144\ttotal: 75.5ms\tremaining: 8.32s\n",
      "9:\tlearn: 979258.6823138\ttotal: 87.1ms\tremaining: 8.62s\n",
      "10:\tlearn: 932809.8153230\ttotal: 97.4ms\tremaining: 8.75s\n",
      "11:\tlearn: 891337.1185731\ttotal: 104ms\tremaining: 8.53s\n",
      "12:\tlearn: 854549.2845555\ttotal: 115ms\tremaining: 8.75s\n",
      "13:\tlearn: 821883.9703170\ttotal: 125ms\tremaining: 8.78s\n",
      "14:\tlearn: 792350.4434531\ttotal: 131ms\tremaining: 8.58s\n",
      "15:\tlearn: 766710.8522203\ttotal: 137ms\tremaining: 8.4s\n",
      "16:\tlearn: 744290.4031460\ttotal: 147ms\tremaining: 8.52s\n",
      "17:\tlearn: 724742.0957451\ttotal: 157ms\tremaining: 8.58s\n",
      "18:\tlearn: 706692.4037712\ttotal: 163ms\tremaining: 8.43s\n",
      "19:\tlearn: 690999.1293535\ttotal: 169ms\tremaining: 8.26s\n",
      "20:\tlearn: 678075.1999889\ttotal: 180ms\tremaining: 8.4s\n",
      "21:\tlearn: 666118.7658835\ttotal: 192ms\tremaining: 8.53s\n",
      "22:\tlearn: 656446.0935742\ttotal: 200ms\tremaining: 8.5s\n",
      "23:\tlearn: 647975.6075938\ttotal: 213ms\tremaining: 8.66s\n",
      "24:\tlearn: 640145.7065022\ttotal: 224ms\tremaining: 8.73s\n",
      "25:\tlearn: 633896.4711586\ttotal: 232ms\tremaining: 8.69s\n",
      "26:\tlearn: 627724.9457684\ttotal: 243ms\tremaining: 8.76s\n",
      "27:\tlearn: 622667.1620037\ttotal: 255ms\tremaining: 8.84s\n",
      "28:\tlearn: 618316.6749124\ttotal: 264ms\tremaining: 8.84s\n",
      "29:\tlearn: 614679.0694758\ttotal: 277ms\tremaining: 8.96s\n",
      "30:\tlearn: 611456.1659712\ttotal: 290ms\tremaining: 9.07s\n",
      "31:\tlearn: 608073.7229648\ttotal: 298ms\tremaining: 9s\n",
      "32:\tlearn: 605862.4680825\ttotal: 310ms\tremaining: 9.09s\n",
      "33:\tlearn: 603197.2341765\ttotal: 323ms\tremaining: 9.17s\n",
      "34:\tlearn: 601185.1880461\ttotal: 331ms\tremaining: 9.12s\n",
      "35:\tlearn: 599254.6218741\ttotal: 344ms\tremaining: 9.2s\n",
      "36:\tlearn: 597582.0207128\ttotal: 356ms\tremaining: 9.27s\n",
      "37:\tlearn: 596394.2339303\ttotal: 365ms\tremaining: 9.24s\n",
      "38:\tlearn: 595464.6155259\ttotal: 383ms\tremaining: 9.43s\n",
      "39:\tlearn: 593817.8372398\ttotal: 404ms\tremaining: 9.7s\n",
      "40:\tlearn: 592567.2728344\ttotal: 421ms\tremaining: 9.85s\n",
      "41:\tlearn: 591858.1562677\ttotal: 434ms\tremaining: 9.9s\n",
      "42:\tlearn: 591150.5409063\ttotal: 454ms\tremaining: 10.1s\n",
      "43:\tlearn: 589905.7413134\ttotal: 468ms\tremaining: 10.2s\n",
      "44:\tlearn: 589368.9446530\ttotal: 488ms\tremaining: 10.4s\n",
      "45:\tlearn: 588365.9904203\ttotal: 502ms\tremaining: 10.4s\n",
      "46:\tlearn: 587863.3434828\ttotal: 518ms\tremaining: 10.5s\n",
      "47:\tlearn: 587482.9842910\ttotal: 533ms\tremaining: 10.6s\n",
      "48:\tlearn: 586672.1003254\ttotal: 550ms\tremaining: 10.7s\n",
      "49:\tlearn: 586342.9053082\ttotal: 565ms\tremaining: 10.7s\n",
      "50:\tlearn: 586005.9708095\ttotal: 583ms\tremaining: 10.8s\n",
      "51:\tlearn: 585740.8685774\ttotal: 599ms\tremaining: 10.9s\n",
      "52:\tlearn: 585013.2271195\ttotal: 620ms\tremaining: 11.1s\n",
      "53:\tlearn: 584718.4812970\ttotal: 639ms\tremaining: 11.2s\n",
      "54:\tlearn: 583997.8681836\ttotal: 652ms\tremaining: 11.2s\n",
      "55:\tlearn: 583434.3395654\ttotal: 664ms\tremaining: 11.2s\n",
      "56:\tlearn: 582993.9295036\ttotal: 680ms\tremaining: 11.2s\n",
      "57:\tlearn: 582817.5044718\ttotal: 690ms\tremaining: 11.2s\n",
      "58:\tlearn: 582260.8961948\ttotal: 698ms\tremaining: 11.1s\n",
      "59:\tlearn: 582017.7265508\ttotal: 712ms\tremaining: 11.2s\n",
      "60:\tlearn: 581725.4481631\ttotal: 730ms\tremaining: 11.2s\n",
      "61:\tlearn: 581064.5161028\ttotal: 744ms\tremaining: 11.3s\n",
      "62:\tlearn: 580935.2188386\ttotal: 761ms\tremaining: 11.3s\n",
      "63:\tlearn: 580363.3298322\ttotal: 776ms\tremaining: 11.3s\n",
      "64:\tlearn: 579942.0771184\ttotal: 791ms\tremaining: 11.4s\n",
      "65:\tlearn: 579839.7460124\ttotal: 805ms\tremaining: 11.4s\n",
      "66:\tlearn: 579417.1974053\ttotal: 821ms\tremaining: 11.4s\n",
      "67:\tlearn: 579288.1034855\ttotal: 833ms\tremaining: 11.4s\n",
      "68:\tlearn: 578853.1611817\ttotal: 852ms\tremaining: 11.5s\n",
      "69:\tlearn: 578233.5569761\ttotal: 861ms\tremaining: 11.4s\n",
      "70:\tlearn: 578129.1476794\ttotal: 873ms\tremaining: 11.4s\n",
      "71:\tlearn: 578040.8220263\ttotal: 886ms\tremaining: 11.4s\n",
      "72:\tlearn: 577947.4359740\ttotal: 897ms\tremaining: 11.4s\n",
      "73:\tlearn: 577874.3792402\ttotal: 911ms\tremaining: 11.4s\n",
      "74:\tlearn: 577798.3923441\ttotal: 922ms\tremaining: 11.4s\n",
      "75:\tlearn: 577462.9929015\ttotal: 934ms\tremaining: 11.4s\n",
      "76:\tlearn: 577076.3484135\ttotal: 946ms\tremaining: 11.3s\n",
      "77:\tlearn: 576955.1956198\ttotal: 954ms\tremaining: 11.3s\n",
      "78:\tlearn: 576699.9446231\ttotal: 969ms\tremaining: 11.3s\n",
      "79:\tlearn: 576626.7095964\ttotal: 985ms\tremaining: 11.3s\n",
      "80:\tlearn: 575803.5934140\ttotal: 995ms\tremaining: 11.3s\n",
      "81:\tlearn: 575711.2019290\ttotal: 1.02s\tremaining: 11.4s\n",
      "82:\tlearn: 575645.9626618\ttotal: 1.04s\tremaining: 11.5s\n",
      "83:\tlearn: 575326.5509329\ttotal: 1.05s\tremaining: 11.5s\n",
      "84:\tlearn: 575296.1876752\ttotal: 1.07s\tremaining: 11.5s\n",
      "85:\tlearn: 574869.1451908\ttotal: 1.08s\tremaining: 11.5s\n",
      "86:\tlearn: 574576.7847852\ttotal: 1.09s\tremaining: 11.4s\n",
      "87:\tlearn: 574351.3526442\ttotal: 1.1s\tremaining: 11.4s\n",
      "88:\tlearn: 573669.9427206\ttotal: 1.11s\tremaining: 11.4s\n",
      "89:\tlearn: 573613.4903643\ttotal: 1.12s\tremaining: 11.3s\n",
      "90:\tlearn: 573561.4232504\ttotal: 1.13s\tremaining: 11.3s\n",
      "91:\tlearn: 573106.3817740\ttotal: 1.14s\tremaining: 11.3s\n",
      "92:\tlearn: 572993.4698453\ttotal: 1.15s\tremaining: 11.2s\n",
      "93:\tlearn: 572892.4053610\ttotal: 1.16s\tremaining: 11.2s\n",
      "94:\tlearn: 572797.3363973\ttotal: 1.18s\tremaining: 11.2s\n",
      "95:\tlearn: 572382.7803655\ttotal: 1.18s\tremaining: 11.1s\n",
      "96:\tlearn: 571920.1749744\ttotal: 1.2s\tremaining: 11.1s\n",
      "97:\tlearn: 571680.1651560\ttotal: 1.21s\tremaining: 11.1s\n",
      "98:\tlearn: 571471.6015136\ttotal: 1.21s\tremaining: 11s\n",
      "99:\tlearn: 571437.4305755\ttotal: 1.23s\tremaining: 11.1s\n",
      "100:\tlearn: 571250.6811455\ttotal: 1.24s\tremaining: 11.1s\n",
      "101:\tlearn: 571134.8074885\ttotal: 1.25s\tremaining: 11s\n",
      "102:\tlearn: 571036.7340015\ttotal: 1.27s\tremaining: 11.1s\n",
      "103:\tlearn: 570731.5543788\ttotal: 1.28s\tremaining: 11s\n",
      "104:\tlearn: 570505.7397752\ttotal: 1.3s\tremaining: 11.1s\n",
      "105:\tlearn: 570473.9556182\ttotal: 1.31s\tremaining: 11s\n",
      "106:\tlearn: 570407.3926257\ttotal: 1.32s\tremaining: 11s\n",
      "107:\tlearn: 570356.9277656\ttotal: 1.34s\tremaining: 11.1s\n",
      "108:\tlearn: 570234.6655303\ttotal: 1.35s\tremaining: 11.1s\n",
      "109:\tlearn: 570184.3856185\ttotal: 1.37s\tremaining: 11.1s\n",
      "110:\tlearn: 569980.6735612\ttotal: 1.37s\tremaining: 11s\n",
      "111:\tlearn: 569478.8877689\ttotal: 1.38s\tremaining: 11s\n",
      "112:\tlearn: 569466.0634916\ttotal: 1.4s\tremaining: 11s\n",
      "113:\tlearn: 569110.7563831\ttotal: 1.41s\tremaining: 10.9s\n",
      "114:\tlearn: 568848.9761462\ttotal: 1.42s\tremaining: 10.9s\n",
      "115:\tlearn: 568736.9903783\ttotal: 1.43s\tremaining: 10.9s\n",
      "116:\tlearn: 568691.1200314\ttotal: 1.44s\tremaining: 10.9s\n",
      "117:\tlearn: 568573.6801096\ttotal: 1.46s\tremaining: 10.9s\n",
      "118:\tlearn: 568517.1955322\ttotal: 1.47s\tremaining: 10.9s\n",
      "119:\tlearn: 568483.3349218\ttotal: 1.48s\tremaining: 10.8s\n",
      "120:\tlearn: 568360.7691325\ttotal: 1.49s\tremaining: 10.8s\n",
      "121:\tlearn: 568276.3582029\ttotal: 1.5s\tremaining: 10.8s\n",
      "122:\tlearn: 568227.2534572\ttotal: 1.51s\tremaining: 10.8s\n",
      "123:\tlearn: 568085.4375155\ttotal: 1.53s\tremaining: 10.8s\n",
      "124:\tlearn: 568062.1675843\ttotal: 1.53s\tremaining: 10.7s\n",
      "125:\tlearn: 567864.2499375\ttotal: 1.54s\tremaining: 10.7s\n",
      "126:\tlearn: 567428.8553376\ttotal: 1.55s\tremaining: 10.7s\n",
      "127:\tlearn: 567366.3087547\ttotal: 1.56s\tremaining: 10.6s\n",
      "128:\tlearn: 567118.6563033\ttotal: 1.57s\tremaining: 10.6s\n",
      "129:\tlearn: 567067.4049017\ttotal: 1.57s\tremaining: 10.5s\n",
      "130:\tlearn: 567040.2812115\ttotal: 1.59s\tremaining: 10.5s\n",
      "131:\tlearn: 566623.3830289\ttotal: 1.59s\tremaining: 10.5s\n",
      "132:\tlearn: 566569.6713343\ttotal: 1.6s\tremaining: 10.4s\n",
      "133:\tlearn: 566514.3548411\ttotal: 1.6s\tremaining: 10.4s\n",
      "134:\tlearn: 566454.6542255\ttotal: 1.62s\tremaining: 10.4s\n",
      "135:\tlearn: 566383.9290872\ttotal: 1.63s\tremaining: 10.3s\n",
      "136:\tlearn: 566290.9367772\ttotal: 1.63s\tremaining: 10.3s\n",
      "137:\tlearn: 566079.4602598\ttotal: 1.65s\tremaining: 10.3s\n",
      "138:\tlearn: 565986.2799350\ttotal: 1.66s\tremaining: 10.3s\n",
      "139:\tlearn: 565921.6151774\ttotal: 1.67s\tremaining: 10.2s\n",
      "140:\tlearn: 565851.3034377\ttotal: 1.68s\tremaining: 10.2s\n",
      "141:\tlearn: 565624.3115119\ttotal: 1.69s\tremaining: 10.2s\n",
      "142:\tlearn: 565564.7608014\ttotal: 1.7s\tremaining: 10.2s\n",
      "143:\tlearn: 565228.1658117\ttotal: 1.71s\tremaining: 10.1s\n",
      "144:\tlearn: 565172.7209381\ttotal: 1.72s\tremaining: 10.1s\n",
      "145:\tlearn: 564857.4122376\ttotal: 1.72s\tremaining: 10.1s\n",
      "146:\tlearn: 564803.7752737\ttotal: 1.73s\tremaining: 10.1s\n",
      "147:\tlearn: 564725.5643339\ttotal: 1.75s\tremaining: 10.1s\n",
      "148:\tlearn: 564566.3040882\ttotal: 1.75s\tremaining: 10s\n",
      "149:\tlearn: 564210.7206582\ttotal: 1.76s\tremaining: 9.98s\n",
      "150:\tlearn: 564125.4753767\ttotal: 1.77s\tremaining: 9.98s\n",
      "151:\tlearn: 563843.6819062\ttotal: 1.78s\tremaining: 9.95s\n",
      "152:\tlearn: 563642.4780509\ttotal: 1.79s\tremaining: 9.91s\n",
      "153:\tlearn: 563411.6330742\ttotal: 1.8s\tremaining: 9.87s\n",
      "154:\tlearn: 563015.0543511\ttotal: 1.8s\tremaining: 9.84s\n",
      "155:\tlearn: 562811.2675655\ttotal: 1.81s\tremaining: 9.82s\n",
      "156:\tlearn: 562608.9266563\ttotal: 1.82s\tremaining: 9.78s\n",
      "157:\tlearn: 562405.6473028\ttotal: 1.83s\tremaining: 9.76s\n",
      "158:\tlearn: 562115.0510021\ttotal: 1.84s\tremaining: 9.75s\n",
      "159:\tlearn: 561896.4847302\ttotal: 1.85s\tremaining: 9.71s\n",
      "160:\tlearn: 561551.2652601\ttotal: 1.86s\tremaining: 9.68s\n",
      "161:\tlearn: 561514.7077302\ttotal: 1.86s\tremaining: 9.64s\n",
      "162:\tlearn: 561310.8827170\ttotal: 1.88s\tremaining: 9.64s\n",
      "163:\tlearn: 561026.1990209\ttotal: 1.88s\tremaining: 9.6s\n",
      "164:\tlearn: 560882.3911256\ttotal: 1.89s\tremaining: 9.57s\n",
      "165:\tlearn: 560817.9686000\ttotal: 1.9s\tremaining: 9.56s\n",
      "166:\tlearn: 560614.6443414\ttotal: 1.91s\tremaining: 9.54s\n",
      "167:\tlearn: 560429.8919755\ttotal: 1.92s\tremaining: 9.51s\n",
      "168:\tlearn: 560257.4262769\ttotal: 1.93s\tremaining: 9.47s\n",
      "169:\tlearn: 560114.4987214\ttotal: 1.94s\tremaining: 9.47s\n",
      "170:\tlearn: 560057.3117608\ttotal: 1.95s\tremaining: 9.44s\n",
      "171:\tlearn: 559866.1294250\ttotal: 1.95s\tremaining: 9.4s\n",
      "172:\tlearn: 559809.3512687\ttotal: 1.96s\tremaining: 9.38s\n",
      "173:\tlearn: 559617.1522802\ttotal: 1.97s\tremaining: 9.37s\n",
      "174:\tlearn: 559571.9180149\ttotal: 1.99s\tremaining: 9.36s\n",
      "175:\tlearn: 559412.2618666\ttotal: 1.99s\tremaining: 9.32s\n",
      "176:\tlearn: 559302.1197847\ttotal: 2s\tremaining: 9.32s\n",
      "177:\tlearn: 558995.3935550\ttotal: 2.01s\tremaining: 9.28s\n",
      "178:\tlearn: 558865.6038784\ttotal: 2.02s\tremaining: 9.25s\n",
      "179:\tlearn: 558687.9031820\ttotal: 2.02s\tremaining: 9.22s\n",
      "180:\tlearn: 558642.9442527\ttotal: 2.04s\tremaining: 9.24s\n",
      "181:\tlearn: 558501.9322921\ttotal: 2.05s\tremaining: 9.21s\n",
      "182:\tlearn: 558282.9212186\ttotal: 2.06s\tremaining: 9.19s\n",
      "183:\tlearn: 558252.7943801\ttotal: 2.07s\tremaining: 9.18s\n",
      "184:\tlearn: 558195.3025903\ttotal: 2.08s\tremaining: 9.15s\n",
      "185:\tlearn: 558145.1479888\ttotal: 2.08s\tremaining: 9.12s\n",
      "186:\tlearn: 557953.2312390\ttotal: 2.09s\tremaining: 9.09s\n",
      "187:\tlearn: 557811.9574720\ttotal: 2.1s\tremaining: 9.08s\n",
      "188:\tlearn: 557620.2015681\ttotal: 2.11s\tremaining: 9.05s\n",
      "189:\tlearn: 557495.4363739\ttotal: 2.12s\tremaining: 9.02s\n",
      "190:\tlearn: 557324.8719059\ttotal: 2.13s\tremaining: 9.01s\n",
      "191:\tlearn: 557181.0556276\ttotal: 2.13s\tremaining: 8.99s\n",
      "192:\tlearn: 557132.3855578\ttotal: 2.14s\tremaining: 8.96s\n",
      "193:\tlearn: 557018.1771092\ttotal: 2.15s\tremaining: 8.93s\n",
      "194:\tlearn: 556991.6036212\ttotal: 2.16s\tremaining: 8.92s\n",
      "195:\tlearn: 556833.5241229\ttotal: 2.17s\tremaining: 8.9s\n",
      "196:\tlearn: 556772.2655777\ttotal: 2.18s\tremaining: 8.88s\n",
      "197:\tlearn: 556696.0938832\ttotal: 2.19s\tremaining: 8.85s\n",
      "198:\tlearn: 556583.8641088\ttotal: 2.2s\tremaining: 8.85s\n",
      "199:\tlearn: 556270.2515045\ttotal: 2.21s\tremaining: 8.84s\n",
      "200:\tlearn: 556090.2964282\ttotal: 2.22s\tremaining: 8.82s\n",
      "201:\tlearn: 555962.8610817\ttotal: 2.23s\tremaining: 8.81s\n",
      "202:\tlearn: 555895.1435750\ttotal: 2.24s\tremaining: 8.8s\n",
      "203:\tlearn: 555681.8018169\ttotal: 2.26s\tremaining: 8.82s\n",
      "204:\tlearn: 555651.8576829\ttotal: 2.27s\tremaining: 8.82s\n",
      "205:\tlearn: 555604.6104375\ttotal: 2.29s\tremaining: 8.81s\n",
      "206:\tlearn: 555532.5690814\ttotal: 2.3s\tremaining: 8.8s\n",
      "207:\tlearn: 555508.4613637\ttotal: 2.3s\tremaining: 8.78s\n",
      "208:\tlearn: 555331.8668196\ttotal: 2.31s\tremaining: 8.75s\n",
      "209:\tlearn: 555193.9201394\ttotal: 2.32s\tremaining: 8.73s\n",
      "210:\tlearn: 555006.0826205\ttotal: 2.33s\tremaining: 8.73s\n",
      "211:\tlearn: 554928.1551242\ttotal: 2.34s\tremaining: 8.71s\n",
      "212:\tlearn: 554743.4691701\ttotal: 2.35s\tremaining: 8.69s\n",
      "213:\tlearn: 554691.0756652\ttotal: 2.36s\tremaining: 8.68s\n",
      "214:\tlearn: 554553.2595626\ttotal: 2.37s\tremaining: 8.66s\n",
      "215:\tlearn: 554518.2188789\ttotal: 2.38s\tremaining: 8.66s\n",
      "216:\tlearn: 554467.3391535\ttotal: 2.4s\tremaining: 8.65s\n",
      "217:\tlearn: 554358.4079945\ttotal: 2.41s\tremaining: 8.63s\n",
      "218:\tlearn: 554337.1357208\ttotal: 2.42s\tremaining: 8.63s\n",
      "219:\tlearn: 554283.7056604\ttotal: 2.43s\tremaining: 8.62s\n",
      "220:\tlearn: 554156.3486563\ttotal: 2.44s\tremaining: 8.59s\n",
      "221:\tlearn: 553987.9346553\ttotal: 2.44s\tremaining: 8.57s\n",
      "222:\tlearn: 553950.5192523\ttotal: 2.46s\tremaining: 8.56s\n",
      "223:\tlearn: 553742.5753085\ttotal: 2.46s\tremaining: 8.54s\n",
      "224:\tlearn: 553658.0963057\ttotal: 2.47s\tremaining: 8.51s\n",
      "225:\tlearn: 553608.0254306\ttotal: 2.48s\tremaining: 8.5s\n",
      "226:\tlearn: 553447.5075313\ttotal: 2.5s\tremaining: 8.5s\n",
      "227:\tlearn: 553425.4519415\ttotal: 2.5s\tremaining: 8.48s\n",
      "228:\tlearn: 553336.5927709\ttotal: 2.51s\tremaining: 8.45s\n",
      "229:\tlearn: 553251.6353318\ttotal: 2.52s\tremaining: 8.45s\n",
      "230:\tlearn: 553231.7026469\ttotal: 2.53s\tremaining: 8.43s\n",
      "231:\tlearn: 553208.7347058\ttotal: 2.54s\tremaining: 8.41s\n",
      "232:\tlearn: 553152.8744836\ttotal: 2.56s\tremaining: 8.42s\n",
      "233:\tlearn: 553107.7066654\ttotal: 2.56s\tremaining: 8.4s\n",
      "234:\tlearn: 553064.4766869\ttotal: 2.57s\tremaining: 8.37s\n",
      "235:\tlearn: 553027.8665228\ttotal: 2.59s\tremaining: 8.37s\n",
      "236:\tlearn: 552959.7299239\ttotal: 2.6s\tremaining: 8.37s\n",
      "237:\tlearn: 552843.5907204\ttotal: 2.6s\tremaining: 8.34s\n",
      "238:\tlearn: 552739.4982200\ttotal: 2.62s\tremaining: 8.34s\n",
      "239:\tlearn: 552597.9680809\ttotal: 2.63s\tremaining: 8.31s\n",
      "240:\tlearn: 552510.3235357\ttotal: 2.63s\tremaining: 8.29s\n",
      "241:\tlearn: 552484.5510454\ttotal: 2.65s\tremaining: 8.29s\n",
      "242:\tlearn: 552438.8375228\ttotal: 2.66s\tremaining: 8.29s\n",
      "243:\tlearn: 552372.6827266\ttotal: 2.67s\tremaining: 8.27s\n",
      "244:\tlearn: 552357.1090272\ttotal: 2.68s\tremaining: 8.27s\n",
      "245:\tlearn: 552200.4460055\ttotal: 2.69s\tremaining: 8.25s\n",
      "246:\tlearn: 552008.4422250\ttotal: 2.7s\tremaining: 8.22s\n",
      "247:\tlearn: 551957.2501427\ttotal: 2.71s\tremaining: 8.22s\n",
      "248:\tlearn: 551781.0536568\ttotal: 2.72s\tremaining: 8.21s\n",
      "249:\tlearn: 551722.8837691\ttotal: 2.73s\tremaining: 8.19s\n",
      "250:\tlearn: 551645.3656186\ttotal: 2.74s\tremaining: 8.17s\n",
      "251:\tlearn: 551540.8802225\ttotal: 2.75s\tremaining: 8.15s\n",
      "252:\tlearn: 551401.1125020\ttotal: 2.75s\tremaining: 8.14s\n",
      "253:\tlearn: 551289.8598244\ttotal: 2.76s\tremaining: 8.11s\n",
      "254:\tlearn: 551252.2881470\ttotal: 2.77s\tremaining: 8.1s\n",
      "255:\tlearn: 551188.9990109\ttotal: 2.78s\tremaining: 8.09s\n",
      "256:\tlearn: 551046.7753880\ttotal: 2.79s\tremaining: 8.06s\n",
      "257:\tlearn: 551006.0711514\ttotal: 2.79s\tremaining: 8.04s\n",
      "258:\tlearn: 550883.3981483\ttotal: 2.8s\tremaining: 8.02s\n",
      "259:\tlearn: 550760.3834095\ttotal: 2.81s\tremaining: 8.01s\n",
      "260:\tlearn: 550590.3126585\ttotal: 2.82s\tremaining: 7.99s\n",
      "261:\tlearn: 550495.1064472\ttotal: 2.83s\tremaining: 7.96s\n",
      "262:\tlearn: 550460.8679982\ttotal: 2.84s\tremaining: 7.95s\n",
      "263:\tlearn: 550428.7603618\ttotal: 2.85s\tremaining: 7.95s\n",
      "264:\tlearn: 550360.1525133\ttotal: 2.86s\tremaining: 7.92s\n",
      "265:\tlearn: 550285.5881843\ttotal: 2.86s\tremaining: 7.91s\n",
      "266:\tlearn: 550177.8912975\ttotal: 2.88s\tremaining: 7.9s\n",
      "267:\tlearn: 550160.3787204\ttotal: 2.88s\tremaining: 7.88s\n",
      "268:\tlearn: 550050.0935547\ttotal: 2.89s\tremaining: 7.85s\n",
      "269:\tlearn: 549964.4488865\ttotal: 2.9s\tremaining: 7.84s\n",
      "270:\tlearn: 549903.8285369\ttotal: 2.92s\tremaining: 7.85s\n",
      "271:\tlearn: 549886.1525026\ttotal: 2.92s\tremaining: 7.83s\n",
      "272:\tlearn: 549846.0858058\ttotal: 2.94s\tremaining: 7.83s\n",
      "273:\tlearn: 549797.2189264\ttotal: 2.95s\tremaining: 7.82s\n",
      "274:\tlearn: 549723.6567892\ttotal: 2.96s\tremaining: 7.8s\n",
      "275:\tlearn: 549609.5619078\ttotal: 2.97s\tremaining: 7.79s\n",
      "276:\tlearn: 549576.1346785\ttotal: 2.98s\tremaining: 7.78s\n",
      "277:\tlearn: 549456.7584253\ttotal: 2.99s\tremaining: 7.76s\n",
      "278:\tlearn: 549396.2016571\ttotal: 3s\tremaining: 7.75s\n",
      "279:\tlearn: 549350.7995796\ttotal: 3.02s\tremaining: 7.75s\n",
      "280:\tlearn: 549332.4556915\ttotal: 3.02s\tremaining: 7.74s\n",
      "281:\tlearn: 549279.7568224\ttotal: 3.04s\tremaining: 7.74s\n",
      "282:\tlearn: 549223.0956332\ttotal: 3.05s\tremaining: 7.72s\n",
      "283:\tlearn: 549185.3414669\ttotal: 3.06s\tremaining: 7.71s\n",
      "284:\tlearn: 549080.1978363\ttotal: 3.07s\tremaining: 7.7s\n",
      "285:\tlearn: 549010.6255410\ttotal: 3.08s\tremaining: 7.68s\n",
      "286:\tlearn: 548998.9564636\ttotal: 3.08s\tremaining: 7.67s\n",
      "287:\tlearn: 548972.5858636\ttotal: 3.1s\tremaining: 7.66s\n",
      "288:\tlearn: 548955.2304136\ttotal: 3.11s\tremaining: 7.64s\n",
      "289:\tlearn: 548930.7850918\ttotal: 3.11s\tremaining: 7.62s\n",
      "290:\tlearn: 548831.1612597\ttotal: 3.12s\tremaining: 7.61s\n",
      "291:\tlearn: 548781.5410034\ttotal: 3.13s\tremaining: 7.6s\n",
      "292:\tlearn: 548744.3206110\ttotal: 3.14s\tremaining: 7.58s\n",
      "293:\tlearn: 548650.9285073\ttotal: 3.15s\tremaining: 7.56s\n",
      "294:\tlearn: 548634.4210410\ttotal: 3.16s\tremaining: 7.55s\n",
      "295:\tlearn: 548492.5772064\ttotal: 3.17s\tremaining: 7.54s\n",
      "296:\tlearn: 548409.1768300\ttotal: 3.18s\tremaining: 7.52s\n",
      "297:\tlearn: 548371.2031598\ttotal: 3.18s\tremaining: 7.5s\n",
      "298:\tlearn: 548300.2033299\ttotal: 3.19s\tremaining: 7.48s\n",
      "299:\tlearn: 548193.7722481\ttotal: 3.2s\tremaining: 7.47s\n",
      "300:\tlearn: 548064.1498064\ttotal: 3.21s\tremaining: 7.45s\n",
      "301:\tlearn: 547976.3176809\ttotal: 3.21s\tremaining: 7.43s\n",
      "302:\tlearn: 547878.7597606\ttotal: 3.23s\tremaining: 7.42s\n",
      "303:\tlearn: 547843.1128897\ttotal: 3.23s\tremaining: 7.41s\n",
      "304:\tlearn: 547810.3213424\ttotal: 3.24s\tremaining: 7.39s\n",
      "305:\tlearn: 547692.6010025\ttotal: 3.25s\tremaining: 7.37s\n",
      "306:\tlearn: 547646.4987007\ttotal: 3.26s\tremaining: 7.37s\n",
      "307:\tlearn: 547620.6141397\ttotal: 3.27s\tremaining: 7.35s\n",
      "308:\tlearn: 547536.5903816\ttotal: 3.28s\tremaining: 7.33s\n",
      "309:\tlearn: 547441.1682313\ttotal: 3.29s\tremaining: 7.33s\n",
      "310:\tlearn: 547433.3166655\ttotal: 3.3s\tremaining: 7.31s\n",
      "311:\tlearn: 547418.2194263\ttotal: 3.31s\tremaining: 7.3s\n",
      "312:\tlearn: 547355.9983527\ttotal: 3.32s\tremaining: 7.28s\n",
      "313:\tlearn: 547342.7756355\ttotal: 3.33s\tremaining: 7.28s\n",
      "314:\tlearn: 547301.0473341\ttotal: 3.34s\tremaining: 7.26s\n",
      "315:\tlearn: 547262.2170988\ttotal: 3.35s\tremaining: 7.25s\n",
      "316:\tlearn: 547188.4856194\ttotal: 3.36s\tremaining: 7.25s\n",
      "317:\tlearn: 547140.3892032\ttotal: 3.37s\tremaining: 7.23s\n",
      "318:\tlearn: 547072.1041072\ttotal: 3.38s\tremaining: 7.21s\n",
      "319:\tlearn: 547029.0713362\ttotal: 3.39s\tremaining: 7.2s\n",
      "320:\tlearn: 546936.8263603\ttotal: 3.4s\tremaining: 7.18s\n",
      "321:\tlearn: 546859.6957777\ttotal: 3.4s\tremaining: 7.16s\n",
      "322:\tlearn: 546755.3980806\ttotal: 3.41s\tremaining: 7.14s\n",
      "323:\tlearn: 546732.2832856\ttotal: 3.42s\tremaining: 7.14s\n",
      "324:\tlearn: 546627.7327271\ttotal: 3.43s\tremaining: 7.13s\n",
      "325:\tlearn: 546549.0193076\ttotal: 3.44s\tremaining: 7.11s\n",
      "326:\tlearn: 546458.1367522\ttotal: 3.44s\tremaining: 7.09s\n",
      "327:\tlearn: 546402.0885009\ttotal: 3.45s\tremaining: 7.07s\n",
      "328:\tlearn: 546339.7726092\ttotal: 3.46s\tremaining: 7.06s\n",
      "329:\tlearn: 546320.9057911\ttotal: 3.47s\tremaining: 7.04s\n",
      "330:\tlearn: 546255.3411198\ttotal: 3.48s\tremaining: 7.03s\n",
      "331:\tlearn: 546204.5514050\ttotal: 3.49s\tremaining: 7.02s\n",
      "332:\tlearn: 546168.9492908\ttotal: 3.5s\tremaining: 7s\n",
      "333:\tlearn: 546128.1691158\ttotal: 3.5s\tremaining: 6.99s\n",
      "334:\tlearn: 546107.8923256\ttotal: 3.52s\tremaining: 6.98s\n",
      "335:\tlearn: 546080.7196975\ttotal: 3.53s\tremaining: 6.97s\n",
      "336:\tlearn: 546025.3650099\ttotal: 3.53s\tremaining: 6.95s\n",
      "337:\tlearn: 545953.7333819\ttotal: 3.54s\tremaining: 6.94s\n",
      "338:\tlearn: 545908.9905759\ttotal: 3.56s\tremaining: 6.93s\n",
      "339:\tlearn: 545805.0431750\ttotal: 3.56s\tremaining: 6.91s\n",
      "340:\tlearn: 545722.8848619\ttotal: 3.57s\tremaining: 6.89s\n",
      "341:\tlearn: 545703.5112381\ttotal: 3.58s\tremaining: 6.88s\n",
      "342:\tlearn: 545692.0695717\ttotal: 3.59s\tremaining: 6.87s\n",
      "343:\tlearn: 545675.7048524\ttotal: 3.6s\tremaining: 6.86s\n",
      "344:\tlearn: 545637.1728752\ttotal: 3.6s\tremaining: 6.84s\n",
      "345:\tlearn: 545593.4123400\ttotal: 3.61s\tremaining: 6.83s\n",
      "346:\tlearn: 545581.7222330\ttotal: 3.63s\tremaining: 6.83s\n",
      "347:\tlearn: 545543.3200391\ttotal: 3.63s\tremaining: 6.81s\n",
      "348:\tlearn: 545529.8319387\ttotal: 3.65s\tremaining: 6.81s\n",
      "349:\tlearn: 545446.8241385\ttotal: 3.66s\tremaining: 6.8s\n",
      "350:\tlearn: 545373.4517575\ttotal: 3.67s\tremaining: 6.78s\n",
      "351:\tlearn: 545364.4805661\ttotal: 3.68s\tremaining: 6.77s\n",
      "352:\tlearn: 545351.0954709\ttotal: 3.69s\tremaining: 6.76s\n",
      "353:\tlearn: 545322.7058286\ttotal: 3.69s\tremaining: 6.74s\n",
      "354:\tlearn: 545304.3701663\ttotal: 3.71s\tremaining: 6.73s\n",
      "355:\tlearn: 545247.7573150\ttotal: 3.72s\tremaining: 6.72s\n",
      "356:\tlearn: 545225.8114355\ttotal: 3.72s\tremaining: 6.71s\n",
      "357:\tlearn: 545193.1547103\ttotal: 3.73s\tremaining: 6.69s\n",
      "358:\tlearn: 545149.9190496\ttotal: 3.75s\tremaining: 6.69s\n",
      "359:\tlearn: 545084.2579158\ttotal: 3.76s\tremaining: 6.68s\n",
      "360:\tlearn: 544997.7230561\ttotal: 3.76s\tremaining: 6.66s\n",
      "361:\tlearn: 544941.7809562\ttotal: 3.77s\tremaining: 6.64s\n",
      "362:\tlearn: 544864.8013158\ttotal: 3.78s\tremaining: 6.63s\n",
      "363:\tlearn: 544774.1163429\ttotal: 3.79s\tremaining: 6.62s\n",
      "364:\tlearn: 544680.5971961\ttotal: 3.79s\tremaining: 6.6s\n",
      "365:\tlearn: 544591.3145175\ttotal: 3.8s\tremaining: 6.59s\n",
      "366:\tlearn: 544582.1226634\ttotal: 3.81s\tremaining: 6.58s\n",
      "367:\tlearn: 544521.5057432\ttotal: 3.82s\tremaining: 6.56s\n",
      "368:\tlearn: 544465.7253839\ttotal: 3.83s\tremaining: 6.55s\n",
      "369:\tlearn: 544456.3245245\ttotal: 3.84s\tremaining: 6.54s\n",
      "370:\tlearn: 544444.4760575\ttotal: 3.85s\tremaining: 6.53s\n",
      "371:\tlearn: 544367.5208396\ttotal: 3.86s\tremaining: 6.51s\n",
      "372:\tlearn: 544350.2303334\ttotal: 3.87s\tremaining: 6.5s\n",
      "373:\tlearn: 544330.8921689\ttotal: 3.88s\tremaining: 6.49s\n",
      "374:\tlearn: 544280.9738697\ttotal: 3.88s\tremaining: 6.47s\n",
      "375:\tlearn: 544172.7494402\ttotal: 3.89s\tremaining: 6.46s\n",
      "376:\tlearn: 544102.8080329\ttotal: 3.9s\tremaining: 6.44s\n",
      "377:\tlearn: 544055.2995067\ttotal: 3.91s\tremaining: 6.43s\n",
      "378:\tlearn: 544023.1357394\ttotal: 3.92s\tremaining: 6.42s\n",
      "379:\tlearn: 543944.8724906\ttotal: 3.92s\tremaining: 6.4s\n",
      "380:\tlearn: 543877.7925072\ttotal: 3.93s\tremaining: 6.39s\n",
      "381:\tlearn: 543853.7746515\ttotal: 3.94s\tremaining: 6.38s\n",
      "382:\tlearn: 543798.6738957\ttotal: 3.95s\tremaining: 6.36s\n",
      "383:\tlearn: 543744.3131853\ttotal: 3.95s\tremaining: 6.34s\n",
      "384:\tlearn: 543713.4104355\ttotal: 3.96s\tremaining: 6.33s\n",
      "385:\tlearn: 543681.2829815\ttotal: 3.97s\tremaining: 6.32s\n",
      "386:\tlearn: 543613.5789062\ttotal: 3.98s\tremaining: 6.3s\n",
      "387:\tlearn: 543593.8739671\ttotal: 3.99s\tremaining: 6.29s\n",
      "388:\tlearn: 543530.2543587\ttotal: 4s\tremaining: 6.28s\n",
      "389:\tlearn: 543456.7538691\ttotal: 4s\tremaining: 6.26s\n",
      "390:\tlearn: 543389.3245331\ttotal: 4.01s\tremaining: 6.25s\n",
      "391:\tlearn: 543331.2493652\ttotal: 4.02s\tremaining: 6.24s\n",
      "392:\tlearn: 543311.7163008\ttotal: 4.04s\tremaining: 6.23s\n",
      "393:\tlearn: 543270.5958974\ttotal: 4.05s\tremaining: 6.23s\n",
      "394:\tlearn: 543161.3839377\ttotal: 4.05s\tremaining: 6.21s\n",
      "395:\tlearn: 543132.6178024\ttotal: 4.07s\tremaining: 6.21s\n",
      "396:\tlearn: 543080.3019105\ttotal: 4.08s\tremaining: 6.19s\n",
      "397:\tlearn: 543052.8643783\ttotal: 4.08s\tremaining: 6.18s\n",
      "398:\tlearn: 543016.4242742\ttotal: 4.09s\tremaining: 6.16s\n",
      "399:\tlearn: 543004.6664325\ttotal: 4.11s\tremaining: 6.16s\n",
      "400:\tlearn: 542936.3253473\ttotal: 4.11s\tremaining: 6.14s\n",
      "401:\tlearn: 542927.4095351\ttotal: 4.12s\tremaining: 6.12s\n",
      "402:\tlearn: 542866.5047604\ttotal: 4.13s\tremaining: 6.11s\n",
      "403:\tlearn: 542855.5514189\ttotal: 4.13s\tremaining: 6.1s\n",
      "404:\tlearn: 542796.8966706\ttotal: 4.14s\tremaining: 6.08s\n",
      "405:\tlearn: 542766.4454285\ttotal: 4.15s\tremaining: 6.07s\n",
      "406:\tlearn: 542693.5467846\ttotal: 4.15s\tremaining: 6.05s\n",
      "407:\tlearn: 542621.5210662\ttotal: 4.17s\tremaining: 6.04s\n",
      "408:\tlearn: 542560.6082028\ttotal: 4.17s\tremaining: 6.03s\n",
      "409:\tlearn: 542535.8542979\ttotal: 4.18s\tremaining: 6.02s\n",
      "410:\tlearn: 542527.0607207\ttotal: 4.19s\tremaining: 6.01s\n",
      "411:\tlearn: 542464.4386091\ttotal: 4.2s\tremaining: 6s\n",
      "412:\tlearn: 542422.8839808\ttotal: 4.21s\tremaining: 5.98s\n",
      "413:\tlearn: 542359.4590917\ttotal: 4.21s\tremaining: 5.96s\n",
      "414:\tlearn: 542347.9759894\ttotal: 4.22s\tremaining: 5.96s\n",
      "415:\tlearn: 542306.6681721\ttotal: 4.23s\tremaining: 5.94s\n",
      "416:\tlearn: 542297.6561081\ttotal: 4.24s\tremaining: 5.93s\n",
      "417:\tlearn: 542272.6874387\ttotal: 4.25s\tremaining: 5.92s\n",
      "418:\tlearn: 542244.2363055\ttotal: 4.26s\tremaining: 5.91s\n",
      "419:\tlearn: 542203.7966091\ttotal: 4.27s\tremaining: 5.9s\n",
      "420:\tlearn: 542110.8341030\ttotal: 4.28s\tremaining: 5.88s\n",
      "421:\tlearn: 542044.4842172\ttotal: 4.29s\tremaining: 5.87s\n",
      "422:\tlearn: 542012.1824079\ttotal: 4.3s\tremaining: 5.86s\n",
      "423:\tlearn: 541916.2113467\ttotal: 4.3s\tremaining: 5.84s\n",
      "424:\tlearn: 541860.4090849\ttotal: 4.31s\tremaining: 5.83s\n",
      "425:\tlearn: 541855.5240605\ttotal: 4.31s\tremaining: 5.81s\n",
      "426:\tlearn: 541817.2154441\ttotal: 4.32s\tremaining: 5.8s\n",
      "427:\tlearn: 541790.7441178\ttotal: 4.33s\tremaining: 5.79s\n",
      "428:\tlearn: 541721.7624822\ttotal: 4.34s\tremaining: 5.77s\n",
      "429:\tlearn: 541693.0315476\ttotal: 4.34s\tremaining: 5.76s\n",
      "430:\tlearn: 541670.5003753\ttotal: 4.36s\tremaining: 5.75s\n",
      "431:\tlearn: 541590.0031251\ttotal: 4.36s\tremaining: 5.74s\n",
      "432:\tlearn: 541570.4789768\ttotal: 4.37s\tremaining: 5.72s\n",
      "433:\tlearn: 541506.7210564\ttotal: 4.37s\tremaining: 5.7s\n",
      "434:\tlearn: 541465.9740839\ttotal: 4.38s\tremaining: 5.69s\n",
      "435:\tlearn: 541441.6536791\ttotal: 4.39s\tremaining: 5.68s\n",
      "436:\tlearn: 541436.0630094\ttotal: 4.4s\tremaining: 5.67s\n",
      "437:\tlearn: 541385.9517415\ttotal: 4.4s\tremaining: 5.65s\n",
      "438:\tlearn: 541344.2541670\ttotal: 4.42s\tremaining: 5.64s\n",
      "439:\tlearn: 541289.3635281\ttotal: 4.43s\tremaining: 5.63s\n",
      "440:\tlearn: 541273.6810377\ttotal: 4.44s\tremaining: 5.62s\n",
      "441:\tlearn: 541246.0405045\ttotal: 4.45s\tremaining: 5.61s\n",
      "442:\tlearn: 541189.3542819\ttotal: 4.46s\tremaining: 5.6s\n",
      "443:\tlearn: 541102.2814344\ttotal: 4.46s\tremaining: 5.59s\n",
      "444:\tlearn: 541054.7942227\ttotal: 4.47s\tremaining: 5.58s\n",
      "445:\tlearn: 541034.7261946\ttotal: 4.48s\tremaining: 5.57s\n",
      "446:\tlearn: 540959.9245585\ttotal: 4.49s\tremaining: 5.55s\n",
      "447:\tlearn: 540929.1651059\ttotal: 4.5s\tremaining: 5.54s\n",
      "448:\tlearn: 540885.0688959\ttotal: 4.5s\tremaining: 5.52s\n",
      "449:\tlearn: 540866.8566374\ttotal: 4.51s\tremaining: 5.51s\n",
      "450:\tlearn: 540815.8898874\ttotal: 4.52s\tremaining: 5.5s\n",
      "451:\tlearn: 540747.4292234\ttotal: 4.52s\tremaining: 5.49s\n",
      "452:\tlearn: 540687.6758256\ttotal: 4.53s\tremaining: 5.47s\n",
      "453:\tlearn: 540668.2214514\ttotal: 4.54s\tremaining: 5.46s\n",
      "454:\tlearn: 540639.7748695\ttotal: 4.55s\tremaining: 5.45s\n",
      "455:\tlearn: 540630.8202893\ttotal: 4.56s\tremaining: 5.44s\n",
      "456:\tlearn: 540610.1659068\ttotal: 4.57s\tremaining: 5.43s\n",
      "457:\tlearn: 540547.7774210\ttotal: 4.58s\tremaining: 5.42s\n",
      "458:\tlearn: 540540.3801376\ttotal: 4.59s\tremaining: 5.41s\n",
      "459:\tlearn: 540517.3406733\ttotal: 4.59s\tremaining: 5.39s\n",
      "460:\tlearn: 540491.3538557\ttotal: 4.6s\tremaining: 5.38s\n",
      "461:\tlearn: 540472.9026389\ttotal: 4.61s\tremaining: 5.37s\n",
      "462:\tlearn: 540441.0551548\ttotal: 4.62s\tremaining: 5.36s\n",
      "463:\tlearn: 540416.8421978\ttotal: 4.63s\tremaining: 5.35s\n",
      "464:\tlearn: 540353.1783803\ttotal: 4.64s\tremaining: 5.34s\n",
      "465:\tlearn: 540343.8278908\ttotal: 4.65s\tremaining: 5.33s\n",
      "466:\tlearn: 540306.4320450\ttotal: 4.66s\tremaining: 5.32s\n",
      "467:\tlearn: 540272.1230920\ttotal: 4.67s\tremaining: 5.3s\n",
      "468:\tlearn: 540256.5089313\ttotal: 4.68s\tremaining: 5.3s\n",
      "469:\tlearn: 540252.2319833\ttotal: 4.69s\tremaining: 5.29s\n",
      "470:\tlearn: 540194.9923181\ttotal: 4.7s\tremaining: 5.28s\n",
      "471:\tlearn: 540108.4334168\ttotal: 4.71s\tremaining: 5.27s\n",
      "472:\tlearn: 540061.9228747\ttotal: 4.72s\tremaining: 5.26s\n",
      "473:\tlearn: 540017.5173635\ttotal: 4.73s\tremaining: 5.25s\n",
      "474:\tlearn: 539995.9485365\ttotal: 4.74s\tremaining: 5.24s\n",
      "475:\tlearn: 539978.8110056\ttotal: 4.75s\tremaining: 5.23s\n",
      "476:\tlearn: 539959.0040373\ttotal: 4.76s\tremaining: 5.22s\n",
      "477:\tlearn: 539950.3536857\ttotal: 4.77s\tremaining: 5.21s\n",
      "478:\tlearn: 539930.2728204\ttotal: 4.78s\tremaining: 5.2s\n",
      "479:\tlearn: 539924.0075293\ttotal: 4.79s\tremaining: 5.19s\n",
      "480:\tlearn: 539920.0134203\ttotal: 4.8s\tremaining: 5.18s\n",
      "481:\tlearn: 539903.8397391\ttotal: 4.81s\tremaining: 5.17s\n",
      "482:\tlearn: 539866.7116034\ttotal: 4.82s\tremaining: 5.16s\n",
      "483:\tlearn: 539832.5195782\ttotal: 4.83s\tremaining: 5.15s\n",
      "484:\tlearn: 539787.2014901\ttotal: 4.84s\tremaining: 5.14s\n",
      "485:\tlearn: 539761.8113675\ttotal: 4.86s\tremaining: 5.14s\n",
      "486:\tlearn: 539749.3422551\ttotal: 4.87s\tremaining: 5.13s\n",
      "487:\tlearn: 539721.0597258\ttotal: 4.88s\tremaining: 5.12s\n",
      "488:\tlearn: 539673.5081531\ttotal: 4.89s\tremaining: 5.11s\n",
      "489:\tlearn: 539659.3917147\ttotal: 4.9s\tremaining: 5.1s\n",
      "490:\tlearn: 539547.3400996\ttotal: 4.91s\tremaining: 5.08s\n",
      "491:\tlearn: 539453.3755597\ttotal: 4.91s\tremaining: 5.07s\n",
      "492:\tlearn: 539403.7340532\ttotal: 4.92s\tremaining: 5.06s\n",
      "493:\tlearn: 539382.2071434\ttotal: 4.93s\tremaining: 5.05s\n",
      "494:\tlearn: 539348.7781444\ttotal: 4.94s\tremaining: 5.04s\n",
      "495:\tlearn: 539292.5974980\ttotal: 4.94s\tremaining: 5.02s\n",
      "496:\tlearn: 539227.4030942\ttotal: 4.95s\tremaining: 5.01s\n",
      "497:\tlearn: 539144.9018012\ttotal: 4.96s\tremaining: 5s\n",
      "498:\tlearn: 539123.7592440\ttotal: 4.97s\tremaining: 4.99s\n",
      "499:\tlearn: 539073.1970282\ttotal: 4.98s\tremaining: 4.98s\n",
      "500:\tlearn: 539059.8952083\ttotal: 4.99s\tremaining: 4.97s\n",
      "501:\tlearn: 539035.8398027\ttotal: 5s\tremaining: 4.96s\n",
      "502:\tlearn: 538921.3970431\ttotal: 5.01s\tremaining: 4.95s\n",
      "503:\tlearn: 538890.6769342\ttotal: 5.02s\tremaining: 4.94s\n",
      "504:\tlearn: 538861.3331968\ttotal: 5.03s\tremaining: 4.93s\n",
      "505:\tlearn: 538819.6697189\ttotal: 5.04s\tremaining: 4.92s\n",
      "506:\tlearn: 538792.4657693\ttotal: 5.04s\tremaining: 4.91s\n",
      "507:\tlearn: 538772.2639970\ttotal: 5.05s\tremaining: 4.89s\n",
      "508:\tlearn: 538750.4822721\ttotal: 5.07s\tremaining: 4.88s\n",
      "509:\tlearn: 538688.0799856\ttotal: 5.07s\tremaining: 4.87s\n",
      "510:\tlearn: 538672.9902604\ttotal: 5.08s\tremaining: 4.86s\n",
      "511:\tlearn: 538633.6131595\ttotal: 5.08s\tremaining: 4.84s\n",
      "512:\tlearn: 538614.7440881\ttotal: 5.09s\tremaining: 4.84s\n",
      "513:\tlearn: 538594.8246372\ttotal: 5.1s\tremaining: 4.83s\n",
      "514:\tlearn: 538540.0438527\ttotal: 5.11s\tremaining: 4.81s\n",
      "515:\tlearn: 538516.6817035\ttotal: 5.12s\tremaining: 4.8s\n",
      "516:\tlearn: 538508.9060991\ttotal: 5.13s\tremaining: 4.79s\n",
      "517:\tlearn: 538476.8209857\ttotal: 5.14s\tremaining: 4.78s\n",
      "518:\tlearn: 538441.6181392\ttotal: 5.15s\tremaining: 4.77s\n",
      "519:\tlearn: 538375.1693343\ttotal: 5.16s\tremaining: 4.76s\n",
      "520:\tlearn: 538336.7517297\ttotal: 5.17s\tremaining: 4.75s\n",
      "521:\tlearn: 538294.6025911\ttotal: 5.17s\tremaining: 4.74s\n",
      "522:\tlearn: 538233.5763043\ttotal: 5.18s\tremaining: 4.72s\n",
      "523:\tlearn: 538220.1874481\ttotal: 5.19s\tremaining: 4.71s\n",
      "524:\tlearn: 538200.9200346\ttotal: 5.2s\tremaining: 4.7s\n",
      "525:\tlearn: 538186.2306176\ttotal: 5.21s\tremaining: 4.69s\n",
      "526:\tlearn: 538133.0949283\ttotal: 5.22s\tremaining: 4.68s\n",
      "527:\tlearn: 538123.3533248\ttotal: 5.23s\tremaining: 4.67s\n",
      "528:\tlearn: 538117.9065573\ttotal: 5.24s\tremaining: 4.66s\n",
      "529:\tlearn: 538110.3674876\ttotal: 5.25s\tremaining: 4.65s\n",
      "530:\tlearn: 538102.8602745\ttotal: 5.26s\tremaining: 4.64s\n",
      "531:\tlearn: 538075.6571814\ttotal: 5.27s\tremaining: 4.63s\n",
      "532:\tlearn: 538057.3315941\ttotal: 5.27s\tremaining: 4.62s\n",
      "533:\tlearn: 538051.1712717\ttotal: 5.28s\tremaining: 4.61s\n",
      "534:\tlearn: 538034.8882906\ttotal: 5.29s\tremaining: 4.6s\n",
      "535:\tlearn: 538024.4939525\ttotal: 5.3s\tremaining: 4.58s\n",
      "536:\tlearn: 537924.2751276\ttotal: 5.3s\tremaining: 4.57s\n",
      "537:\tlearn: 537885.4996948\ttotal: 5.31s\tremaining: 4.56s\n",
      "538:\tlearn: 537856.9569798\ttotal: 5.32s\tremaining: 4.55s\n",
      "539:\tlearn: 537848.7062677\ttotal: 5.33s\tremaining: 4.54s\n",
      "540:\tlearn: 537840.8413526\ttotal: 5.34s\tremaining: 4.53s\n",
      "541:\tlearn: 537816.8258469\ttotal: 5.35s\tremaining: 4.52s\n",
      "542:\tlearn: 537811.2046724\ttotal: 5.36s\tremaining: 4.51s\n",
      "543:\tlearn: 537793.7584346\ttotal: 5.36s\tremaining: 4.49s\n",
      "544:\tlearn: 537772.8360010\ttotal: 5.37s\tremaining: 4.48s\n",
      "545:\tlearn: 537769.9359789\ttotal: 5.38s\tremaining: 4.47s\n",
      "546:\tlearn: 537763.5293259\ttotal: 5.39s\tremaining: 4.46s\n",
      "547:\tlearn: 537757.3506713\ttotal: 5.39s\tremaining: 4.45s\n",
      "548:\tlearn: 537738.8763909\ttotal: 5.4s\tremaining: 4.44s\n",
      "549:\tlearn: 537707.6695279\ttotal: 5.41s\tremaining: 4.43s\n",
      "550:\tlearn: 537664.1318967\ttotal: 5.42s\tremaining: 4.42s\n",
      "551:\tlearn: 537656.6695908\ttotal: 5.43s\tremaining: 4.41s\n",
      "552:\tlearn: 537653.1671793\ttotal: 5.44s\tremaining: 4.4s\n",
      "553:\tlearn: 537631.7310067\ttotal: 5.46s\tremaining: 4.39s\n",
      "554:\tlearn: 537610.5915776\ttotal: 5.46s\tremaining: 4.38s\n",
      "555:\tlearn: 537590.7937110\ttotal: 5.47s\tremaining: 4.37s\n",
      "556:\tlearn: 537547.6456912\ttotal: 5.48s\tremaining: 4.36s\n",
      "557:\tlearn: 537524.1405886\ttotal: 5.49s\tremaining: 4.34s\n",
      "558:\tlearn: 537457.4451742\ttotal: 5.49s\tremaining: 4.33s\n",
      "559:\tlearn: 537436.2605247\ttotal: 5.5s\tremaining: 4.32s\n",
      "560:\tlearn: 537379.7090734\ttotal: 5.51s\tremaining: 4.31s\n",
      "561:\tlearn: 537332.9980724\ttotal: 5.51s\tremaining: 4.3s\n",
      "562:\tlearn: 537318.5992191\ttotal: 5.52s\tremaining: 4.29s\n",
      "563:\tlearn: 537300.5695782\ttotal: 5.53s\tremaining: 4.27s\n",
      "564:\tlearn: 537291.5971720\ttotal: 5.54s\tremaining: 4.26s\n",
      "565:\tlearn: 537285.1244528\ttotal: 5.55s\tremaining: 4.25s\n",
      "566:\tlearn: 537278.7073407\ttotal: 5.55s\tremaining: 4.24s\n",
      "567:\tlearn: 537263.4036922\ttotal: 5.56s\tremaining: 4.23s\n",
      "568:\tlearn: 537247.6930449\ttotal: 5.57s\tremaining: 4.22s\n",
      "569:\tlearn: 537240.2280991\ttotal: 5.58s\tremaining: 4.21s\n",
      "570:\tlearn: 537215.6857332\ttotal: 5.59s\tremaining: 4.2s\n",
      "571:\tlearn: 537128.8420618\ttotal: 5.6s\tremaining: 4.19s\n",
      "572:\tlearn: 537064.6139623\ttotal: 5.61s\tremaining: 4.18s\n",
      "573:\tlearn: 537043.3229641\ttotal: 5.62s\tremaining: 4.17s\n",
      "574:\tlearn: 536991.0030104\ttotal: 5.63s\tremaining: 4.16s\n",
      "575:\tlearn: 536957.2944820\ttotal: 5.64s\tremaining: 4.15s\n",
      "576:\tlearn: 536935.9604583\ttotal: 5.65s\tremaining: 4.14s\n",
      "577:\tlearn: 536928.2960154\ttotal: 5.66s\tremaining: 4.13s\n",
      "578:\tlearn: 536916.7347878\ttotal: 5.66s\tremaining: 4.12s\n",
      "579:\tlearn: 536907.2726214\ttotal: 5.67s\tremaining: 4.11s\n",
      "580:\tlearn: 536860.9764246\ttotal: 5.68s\tremaining: 4.1s\n",
      "581:\tlearn: 536839.3771851\ttotal: 5.69s\tremaining: 4.08s\n",
      "582:\tlearn: 536824.0636265\ttotal: 5.69s\tremaining: 4.07s\n",
      "583:\tlearn: 536781.7420749\ttotal: 5.7s\tremaining: 4.06s\n",
      "584:\tlearn: 536752.7957431\ttotal: 5.71s\tremaining: 4.05s\n",
      "585:\tlearn: 536715.2431459\ttotal: 5.72s\tremaining: 4.04s\n",
      "586:\tlearn: 536705.0256596\ttotal: 5.72s\tremaining: 4.03s\n",
      "587:\tlearn: 536672.7461742\ttotal: 5.73s\tremaining: 4.02s\n",
      "588:\tlearn: 536632.9435235\ttotal: 5.74s\tremaining: 4.01s\n",
      "589:\tlearn: 536595.7484905\ttotal: 5.75s\tremaining: 3.99s\n",
      "590:\tlearn: 536584.1601189\ttotal: 5.75s\tremaining: 3.98s\n",
      "591:\tlearn: 536575.0771156\ttotal: 5.76s\tremaining: 3.97s\n",
      "592:\tlearn: 536566.2506587\ttotal: 5.77s\tremaining: 3.96s\n",
      "593:\tlearn: 536557.6995576\ttotal: 5.78s\tremaining: 3.95s\n",
      "594:\tlearn: 536528.0530879\ttotal: 5.79s\tremaining: 3.94s\n",
      "595:\tlearn: 536479.3512089\ttotal: 5.79s\tremaining: 3.93s\n",
      "596:\tlearn: 536454.3974875\ttotal: 5.81s\tremaining: 3.92s\n",
      "597:\tlearn: 536408.9687629\ttotal: 5.81s\tremaining: 3.91s\n",
      "598:\tlearn: 536361.5962225\ttotal: 5.82s\tremaining: 3.9s\n",
      "599:\tlearn: 536344.0848590\ttotal: 5.83s\tremaining: 3.89s\n",
      "600:\tlearn: 536311.8398732\ttotal: 5.84s\tremaining: 3.88s\n",
      "601:\tlearn: 536305.4004703\ttotal: 5.85s\tremaining: 3.87s\n",
      "602:\tlearn: 536226.9393286\ttotal: 5.86s\tremaining: 3.85s\n",
      "603:\tlearn: 536180.9175293\ttotal: 5.87s\tremaining: 3.85s\n",
      "604:\tlearn: 536136.3674228\ttotal: 5.87s\tremaining: 3.83s\n",
      "605:\tlearn: 536104.1329800\ttotal: 5.88s\tremaining: 3.82s\n",
      "606:\tlearn: 536095.1266159\ttotal: 5.88s\tremaining: 3.81s\n",
      "607:\tlearn: 536089.8789907\ttotal: 5.89s\tremaining: 3.8s\n",
      "608:\tlearn: 536072.2074268\ttotal: 5.9s\tremaining: 3.79s\n",
      "609:\tlearn: 536055.1783855\ttotal: 5.91s\tremaining: 3.78s\n",
      "610:\tlearn: 536017.3450612\ttotal: 5.92s\tremaining: 3.77s\n",
      "611:\tlearn: 536014.4903812\ttotal: 5.92s\tremaining: 3.75s\n",
      "612:\tlearn: 535970.2812265\ttotal: 5.93s\tremaining: 3.75s\n",
      "613:\tlearn: 535952.5841414\ttotal: 5.94s\tremaining: 3.73s\n",
      "614:\tlearn: 535914.6581250\ttotal: 5.95s\tremaining: 3.72s\n",
      "615:\tlearn: 535897.1623559\ttotal: 5.95s\tremaining: 3.71s\n",
      "616:\tlearn: 535862.2754929\ttotal: 5.96s\tremaining: 3.7s\n",
      "617:\tlearn: 535847.6716785\ttotal: 5.97s\tremaining: 3.69s\n",
      "618:\tlearn: 535840.5537367\ttotal: 5.98s\tremaining: 3.68s\n",
      "619:\tlearn: 535826.1452785\ttotal: 5.99s\tremaining: 3.67s\n",
      "620:\tlearn: 535794.5276226\ttotal: 6s\tremaining: 3.66s\n",
      "621:\tlearn: 535733.2362594\ttotal: 6.01s\tremaining: 3.65s\n",
      "622:\tlearn: 535702.4872411\ttotal: 6.01s\tremaining: 3.64s\n",
      "623:\tlearn: 535694.2333947\ttotal: 6.03s\tremaining: 3.63s\n",
      "624:\tlearn: 535665.1703463\ttotal: 6.04s\tremaining: 3.62s\n",
      "625:\tlearn: 535642.4558779\ttotal: 6.04s\tremaining: 3.61s\n",
      "626:\tlearn: 535623.7136695\ttotal: 6.05s\tremaining: 3.6s\n",
      "627:\tlearn: 535590.8215420\ttotal: 6.06s\tremaining: 3.59s\n",
      "628:\tlearn: 535565.6593403\ttotal: 6.07s\tremaining: 3.58s\n",
      "629:\tlearn: 535542.1284381\ttotal: 6.07s\tremaining: 3.57s\n",
      "630:\tlearn: 535537.9350178\ttotal: 6.08s\tremaining: 3.56s\n",
      "631:\tlearn: 535510.7231084\ttotal: 6.09s\tremaining: 3.55s\n",
      "632:\tlearn: 535500.0277899\ttotal: 6.1s\tremaining: 3.54s\n",
      "633:\tlearn: 535482.1170136\ttotal: 6.11s\tremaining: 3.52s\n",
      "634:\tlearn: 535454.8157677\ttotal: 6.12s\tremaining: 3.52s\n",
      "635:\tlearn: 535441.0132000\ttotal: 6.13s\tremaining: 3.51s\n",
      "636:\tlearn: 535435.8700697\ttotal: 6.13s\tremaining: 3.5s\n",
      "637:\tlearn: 535406.9994175\ttotal: 6.14s\tremaining: 3.48s\n",
      "638:\tlearn: 535405.4386553\ttotal: 6.15s\tremaining: 3.47s\n",
      "639:\tlearn: 535390.2931443\ttotal: 6.16s\tremaining: 3.46s\n",
      "640:\tlearn: 535374.5942259\ttotal: 6.16s\tremaining: 3.45s\n",
      "641:\tlearn: 535338.0815883\ttotal: 6.17s\tremaining: 3.44s\n",
      "642:\tlearn: 535310.3657224\ttotal: 6.18s\tremaining: 3.43s\n",
      "643:\tlearn: 535232.2263460\ttotal: 6.19s\tremaining: 3.42s\n",
      "644:\tlearn: 535205.9252412\ttotal: 6.2s\tremaining: 3.41s\n",
      "645:\tlearn: 535180.4360209\ttotal: 6.2s\tremaining: 3.4s\n",
      "646:\tlearn: 535170.9599407\ttotal: 6.22s\tremaining: 3.39s\n",
      "647:\tlearn: 535161.3904467\ttotal: 6.23s\tremaining: 3.38s\n",
      "648:\tlearn: 535137.3175995\ttotal: 6.24s\tremaining: 3.37s\n",
      "649:\tlearn: 535134.9218712\ttotal: 6.25s\tremaining: 3.36s\n",
      "650:\tlearn: 535089.3629587\ttotal: 6.25s\tremaining: 3.35s\n",
      "651:\tlearn: 535076.8972300\ttotal: 6.26s\tremaining: 3.34s\n",
      "652:\tlearn: 535053.2657049\ttotal: 6.27s\tremaining: 3.33s\n",
      "653:\tlearn: 535017.3243760\ttotal: 6.27s\tremaining: 3.32s\n",
      "654:\tlearn: 535011.5304109\ttotal: 6.29s\tremaining: 3.31s\n",
      "655:\tlearn: 534975.4545640\ttotal: 6.29s\tremaining: 3.3s\n",
      "656:\tlearn: 534939.2554661\ttotal: 6.3s\tremaining: 3.29s\n",
      "657:\tlearn: 534905.5211806\ttotal: 6.3s\tremaining: 3.27s\n",
      "658:\tlearn: 534891.5364015\ttotal: 6.31s\tremaining: 3.27s\n",
      "659:\tlearn: 534872.9506469\ttotal: 6.32s\tremaining: 3.25s\n",
      "660:\tlearn: 534844.5592893\ttotal: 6.33s\tremaining: 3.24s\n",
      "661:\tlearn: 534842.6786611\ttotal: 6.33s\tremaining: 3.23s\n",
      "662:\tlearn: 534827.6099255\ttotal: 6.34s\tremaining: 3.22s\n",
      "663:\tlearn: 534818.9548971\ttotal: 6.35s\tremaining: 3.21s\n",
      "664:\tlearn: 534809.8641065\ttotal: 6.36s\tremaining: 3.2s\n",
      "665:\tlearn: 534795.1983813\ttotal: 6.36s\tremaining: 3.19s\n",
      "666:\tlearn: 534773.8659404\ttotal: 6.37s\tremaining: 3.18s\n",
      "667:\tlearn: 534768.0172116\ttotal: 6.38s\tremaining: 3.17s\n",
      "668:\tlearn: 534761.1105993\ttotal: 6.39s\tremaining: 3.16s\n",
      "669:\tlearn: 534751.4465128\ttotal: 6.4s\tremaining: 3.15s\n",
      "670:\tlearn: 534737.9574821\ttotal: 6.41s\tremaining: 3.14s\n",
      "671:\tlearn: 534710.2386727\ttotal: 6.42s\tremaining: 3.13s\n",
      "672:\tlearn: 534698.6131510\ttotal: 6.43s\tremaining: 3.12s\n",
      "673:\tlearn: 534673.9733200\ttotal: 6.44s\tremaining: 3.11s\n",
      "674:\tlearn: 534634.3396944\ttotal: 6.44s\tremaining: 3.1s\n",
      "675:\tlearn: 534620.4672182\ttotal: 6.45s\tremaining: 3.09s\n",
      "676:\tlearn: 534600.4019933\ttotal: 6.46s\tremaining: 3.08s\n",
      "677:\tlearn: 534580.7402965\ttotal: 6.46s\tremaining: 3.07s\n",
      "678:\tlearn: 534513.6089754\ttotal: 6.47s\tremaining: 3.06s\n",
      "679:\tlearn: 534492.9233982\ttotal: 6.48s\tremaining: 3.05s\n",
      "680:\tlearn: 534481.5469067\ttotal: 6.49s\tremaining: 3.04s\n",
      "681:\tlearn: 534448.8225995\ttotal: 6.49s\tremaining: 3.03s\n",
      "682:\tlearn: 534417.9399013\ttotal: 6.5s\tremaining: 3.02s\n",
      "683:\tlearn: 534363.6147558\ttotal: 6.51s\tremaining: 3.01s\n",
      "684:\tlearn: 534342.1043239\ttotal: 6.51s\tremaining: 3s\n",
      "685:\tlearn: 534297.1286006\ttotal: 6.52s\tremaining: 2.98s\n",
      "686:\tlearn: 534236.4458367\ttotal: 6.53s\tremaining: 2.97s\n",
      "687:\tlearn: 534194.9564934\ttotal: 6.54s\tremaining: 2.96s\n",
      "688:\tlearn: 534153.8491821\ttotal: 6.55s\tremaining: 2.96s\n",
      "689:\tlearn: 534132.2188441\ttotal: 6.55s\tremaining: 2.94s\n",
      "690:\tlearn: 534109.7920772\ttotal: 6.56s\tremaining: 2.94s\n",
      "691:\tlearn: 534091.9049598\ttotal: 6.57s\tremaining: 2.92s\n",
      "692:\tlearn: 534082.5017990\ttotal: 6.58s\tremaining: 2.92s\n",
      "693:\tlearn: 534070.0300026\ttotal: 6.59s\tremaining: 2.9s\n",
      "694:\tlearn: 534036.9229478\ttotal: 6.6s\tremaining: 2.9s\n",
      "695:\tlearn: 534017.9811438\ttotal: 6.62s\tremaining: 2.89s\n",
      "696:\tlearn: 534005.1285045\ttotal: 6.63s\tremaining: 2.88s\n",
      "697:\tlearn: 533990.8259549\ttotal: 6.64s\tremaining: 2.87s\n",
      "698:\tlearn: 533977.0598585\ttotal: 6.65s\tremaining: 2.86s\n",
      "699:\tlearn: 533964.2949372\ttotal: 6.66s\tremaining: 2.85s\n",
      "700:\tlearn: 533945.8298222\ttotal: 6.67s\tremaining: 2.84s\n",
      "701:\tlearn: 533893.0897794\ttotal: 6.67s\tremaining: 2.83s\n",
      "702:\tlearn: 533875.1948026\ttotal: 6.68s\tremaining: 2.82s\n",
      "703:\tlearn: 533865.7841166\ttotal: 6.68s\tremaining: 2.81s\n",
      "704:\tlearn: 533849.7659826\ttotal: 6.69s\tremaining: 2.8s\n",
      "705:\tlearn: 533836.3283337\ttotal: 6.7s\tremaining: 2.79s\n",
      "706:\tlearn: 533789.1011886\ttotal: 6.71s\tremaining: 2.78s\n",
      "707:\tlearn: 533774.4588466\ttotal: 6.71s\tremaining: 2.77s\n",
      "708:\tlearn: 533766.4063083\ttotal: 6.72s\tremaining: 2.76s\n",
      "709:\tlearn: 533758.3656025\ttotal: 6.73s\tremaining: 2.75s\n",
      "710:\tlearn: 533746.4527548\ttotal: 6.74s\tremaining: 2.74s\n",
      "711:\tlearn: 533738.6589659\ttotal: 6.75s\tremaining: 2.73s\n",
      "712:\tlearn: 533733.4919216\ttotal: 6.76s\tremaining: 2.72s\n",
      "713:\tlearn: 533720.5296954\ttotal: 6.77s\tremaining: 2.71s\n",
      "714:\tlearn: 533707.5324222\ttotal: 6.78s\tremaining: 2.7s\n",
      "715:\tlearn: 533698.6348988\ttotal: 6.79s\tremaining: 2.69s\n",
      "716:\tlearn: 533690.7518350\ttotal: 6.8s\tremaining: 2.69s\n",
      "717:\tlearn: 533686.4473219\ttotal: 6.81s\tremaining: 2.67s\n",
      "718:\tlearn: 533681.6920109\ttotal: 6.83s\tremaining: 2.67s\n",
      "719:\tlearn: 533651.1380119\ttotal: 6.84s\tremaining: 2.66s\n",
      "720:\tlearn: 533633.2777036\ttotal: 6.85s\tremaining: 2.65s\n",
      "721:\tlearn: 533607.9229029\ttotal: 6.86s\tremaining: 2.64s\n",
      "722:\tlearn: 533601.9473765\ttotal: 6.87s\tremaining: 2.63s\n",
      "723:\tlearn: 533547.5761653\ttotal: 6.88s\tremaining: 2.62s\n",
      "724:\tlearn: 533530.2263865\ttotal: 6.88s\tremaining: 2.61s\n",
      "725:\tlearn: 533517.7051928\ttotal: 6.89s\tremaining: 2.6s\n",
      "726:\tlearn: 533495.9949170\ttotal: 6.9s\tremaining: 2.59s\n",
      "727:\tlearn: 533490.7201362\ttotal: 6.91s\tremaining: 2.58s\n",
      "728:\tlearn: 533448.9983616\ttotal: 6.91s\tremaining: 2.57s\n",
      "729:\tlearn: 533400.3772315\ttotal: 6.92s\tremaining: 2.56s\n",
      "730:\tlearn: 533376.4530399\ttotal: 6.93s\tremaining: 2.55s\n",
      "731:\tlearn: 533355.5988911\ttotal: 6.94s\tremaining: 2.54s\n",
      "732:\tlearn: 533326.0242525\ttotal: 6.95s\tremaining: 2.53s\n",
      "733:\tlearn: 533308.2725330\ttotal: 6.96s\tremaining: 2.52s\n",
      "734:\tlearn: 533290.5773128\ttotal: 6.96s\tremaining: 2.51s\n",
      "735:\tlearn: 533278.4765609\ttotal: 6.97s\tremaining: 2.5s\n",
      "736:\tlearn: 533273.2605026\ttotal: 6.98s\tremaining: 2.49s\n",
      "737:\tlearn: 533265.5000221\ttotal: 6.99s\tremaining: 2.48s\n",
      "738:\tlearn: 533228.5148102\ttotal: 7s\tremaining: 2.47s\n",
      "739:\tlearn: 533206.7606808\ttotal: 7.01s\tremaining: 2.46s\n",
      "740:\tlearn: 533186.7781948\ttotal: 7.02s\tremaining: 2.45s\n",
      "741:\tlearn: 533181.7566958\ttotal: 7.03s\tremaining: 2.44s\n",
      "742:\tlearn: 533132.0524951\ttotal: 7.04s\tremaining: 2.43s\n",
      "743:\tlearn: 533107.6049078\ttotal: 7.04s\tremaining: 2.42s\n",
      "744:\tlearn: 533079.1529498\ttotal: 7.05s\tremaining: 2.41s\n",
      "745:\tlearn: 533059.9134319\ttotal: 7.06s\tremaining: 2.4s\n",
      "746:\tlearn: 533032.1503840\ttotal: 7.07s\tremaining: 2.4s\n",
      "747:\tlearn: 533010.1676788\ttotal: 7.08s\tremaining: 2.38s\n",
      "748:\tlearn: 533003.3882224\ttotal: 7.09s\tremaining: 2.38s\n",
      "749:\tlearn: 532991.1105569\ttotal: 7.1s\tremaining: 2.37s\n",
      "750:\tlearn: 532922.4561818\ttotal: 7.1s\tremaining: 2.35s\n",
      "751:\tlearn: 532918.7732436\ttotal: 7.11s\tremaining: 2.35s\n",
      "752:\tlearn: 532898.2965830\ttotal: 7.12s\tremaining: 2.34s\n",
      "753:\tlearn: 532878.4317672\ttotal: 7.13s\tremaining: 2.33s\n",
      "754:\tlearn: 532840.2586332\ttotal: 7.14s\tremaining: 2.31s\n",
      "755:\tlearn: 532792.4481317\ttotal: 7.14s\tremaining: 2.31s\n",
      "756:\tlearn: 532781.6051324\ttotal: 7.16s\tremaining: 2.3s\n",
      "757:\tlearn: 532773.3124596\ttotal: 7.17s\tremaining: 2.29s\n",
      "758:\tlearn: 532769.7487148\ttotal: 7.17s\tremaining: 2.28s\n",
      "759:\tlearn: 532723.8167044\ttotal: 7.19s\tremaining: 2.27s\n",
      "760:\tlearn: 532706.1302890\ttotal: 7.2s\tremaining: 2.26s\n",
      "761:\tlearn: 532667.6731256\ttotal: 7.21s\tremaining: 2.25s\n",
      "762:\tlearn: 532598.7021083\ttotal: 7.22s\tremaining: 2.24s\n",
      "763:\tlearn: 532570.8524648\ttotal: 7.23s\tremaining: 2.23s\n",
      "764:\tlearn: 532565.6757136\ttotal: 7.24s\tremaining: 2.22s\n",
      "765:\tlearn: 532533.5351002\ttotal: 7.24s\tremaining: 2.21s\n",
      "766:\tlearn: 532529.9046140\ttotal: 7.25s\tremaining: 2.2s\n",
      "767:\tlearn: 532507.0766617\ttotal: 7.26s\tremaining: 2.19s\n",
      "768:\tlearn: 532502.2555166\ttotal: 7.27s\tremaining: 2.18s\n",
      "769:\tlearn: 532483.1790798\ttotal: 7.28s\tremaining: 2.17s\n",
      "770:\tlearn: 532441.9482617\ttotal: 7.28s\tremaining: 2.16s\n",
      "771:\tlearn: 532423.1822352\ttotal: 7.29s\tremaining: 2.15s\n",
      "772:\tlearn: 532408.5026124\ttotal: 7.3s\tremaining: 2.14s\n",
      "773:\tlearn: 532394.7984732\ttotal: 7.31s\tremaining: 2.13s\n",
      "774:\tlearn: 532368.1818988\ttotal: 7.32s\tremaining: 2.12s\n",
      "775:\tlearn: 532333.1216066\ttotal: 7.33s\tremaining: 2.11s\n",
      "776:\tlearn: 532329.2794239\ttotal: 7.33s\tremaining: 2.1s\n",
      "777:\tlearn: 532263.1638433\ttotal: 7.34s\tremaining: 2.09s\n",
      "778:\tlearn: 532244.5670831\ttotal: 7.35s\tremaining: 2.08s\n",
      "779:\tlearn: 532232.2379802\ttotal: 7.36s\tremaining: 2.07s\n",
      "780:\tlearn: 532170.0098076\ttotal: 7.36s\tremaining: 2.06s\n",
      "781:\tlearn: 532152.8154857\ttotal: 7.37s\tremaining: 2.05s\n",
      "782:\tlearn: 532113.2929667\ttotal: 7.37s\tremaining: 2.04s\n",
      "783:\tlearn: 532107.4095399\ttotal: 7.38s\tremaining: 2.03s\n",
      "784:\tlearn: 532096.9448800\ttotal: 7.39s\tremaining: 2.02s\n",
      "785:\tlearn: 532092.7139291\ttotal: 7.4s\tremaining: 2.02s\n",
      "786:\tlearn: 532087.3314050\ttotal: 7.41s\tremaining: 2.01s\n",
      "787:\tlearn: 532070.6215612\ttotal: 7.42s\tremaining: 2s\n",
      "788:\tlearn: 532068.5248516\ttotal: 7.43s\tremaining: 1.99s\n",
      "789:\tlearn: 532045.4662705\ttotal: 7.44s\tremaining: 1.98s\n",
      "790:\tlearn: 532028.6200522\ttotal: 7.45s\tremaining: 1.97s\n",
      "791:\tlearn: 532000.5159930\ttotal: 7.46s\tremaining: 1.96s\n",
      "792:\tlearn: 531978.9501253\ttotal: 7.46s\tremaining: 1.95s\n",
      "793:\tlearn: 531974.9122474\ttotal: 7.47s\tremaining: 1.94s\n",
      "794:\tlearn: 531938.0230338\ttotal: 7.48s\tremaining: 1.93s\n",
      "795:\tlearn: 531926.4335886\ttotal: 7.48s\tremaining: 1.92s\n",
      "796:\tlearn: 531879.5266438\ttotal: 7.49s\tremaining: 1.91s\n",
      "797:\tlearn: 531860.5897765\ttotal: 7.5s\tremaining: 1.9s\n",
      "798:\tlearn: 531845.8467161\ttotal: 7.5s\tremaining: 1.89s\n",
      "799:\tlearn: 531822.5239586\ttotal: 7.51s\tremaining: 1.88s\n",
      "800:\tlearn: 531807.3769563\ttotal: 7.52s\tremaining: 1.87s\n",
      "801:\tlearn: 531778.9386573\ttotal: 7.53s\tremaining: 1.86s\n",
      "802:\tlearn: 531747.9851956\ttotal: 7.54s\tremaining: 1.85s\n",
      "803:\tlearn: 531737.8723367\ttotal: 7.55s\tremaining: 1.84s\n",
      "804:\tlearn: 531732.9364470\ttotal: 7.56s\tremaining: 1.83s\n",
      "805:\tlearn: 531719.9529075\ttotal: 7.57s\tremaining: 1.82s\n",
      "806:\tlearn: 531693.7673038\ttotal: 7.58s\tremaining: 1.81s\n",
      "807:\tlearn: 531657.1957765\ttotal: 7.58s\tremaining: 1.8s\n",
      "808:\tlearn: 531633.6523832\ttotal: 7.59s\tremaining: 1.79s\n",
      "809:\tlearn: 531622.0242812\ttotal: 7.6s\tremaining: 1.78s\n",
      "810:\tlearn: 531578.7362939\ttotal: 7.61s\tremaining: 1.77s\n",
      "811:\tlearn: 531562.3142149\ttotal: 7.62s\tremaining: 1.76s\n",
      "812:\tlearn: 531556.1697033\ttotal: 7.62s\tremaining: 1.75s\n",
      "813:\tlearn: 531550.1569606\ttotal: 7.63s\tremaining: 1.74s\n",
      "814:\tlearn: 531538.5912417\ttotal: 7.64s\tremaining: 1.74s\n",
      "815:\tlearn: 531517.3193436\ttotal: 7.65s\tremaining: 1.73s\n",
      "816:\tlearn: 531484.7306801\ttotal: 7.66s\tremaining: 1.72s\n",
      "817:\tlearn: 531475.8710483\ttotal: 7.68s\tremaining: 1.71s\n",
      "818:\tlearn: 531456.1476750\ttotal: 7.69s\tremaining: 1.7s\n",
      "819:\tlearn: 531427.2434692\ttotal: 7.7s\tremaining: 1.69s\n",
      "820:\tlearn: 531417.6799753\ttotal: 7.71s\tremaining: 1.68s\n",
      "821:\tlearn: 531401.3717659\ttotal: 7.72s\tremaining: 1.67s\n",
      "822:\tlearn: 531374.1711454\ttotal: 7.72s\tremaining: 1.66s\n",
      "823:\tlearn: 531370.5682192\ttotal: 7.74s\tremaining: 1.65s\n",
      "824:\tlearn: 531344.6434794\ttotal: 7.74s\tremaining: 1.64s\n",
      "825:\tlearn: 531335.9213090\ttotal: 7.75s\tremaining: 1.63s\n",
      "826:\tlearn: 531325.2382756\ttotal: 7.76s\tremaining: 1.62s\n",
      "827:\tlearn: 531306.5082061\ttotal: 7.77s\tremaining: 1.61s\n",
      "828:\tlearn: 531271.5066021\ttotal: 7.77s\tremaining: 1.6s\n",
      "829:\tlearn: 531248.9784305\ttotal: 7.78s\tremaining: 1.59s\n",
      "830:\tlearn: 531216.7160237\ttotal: 7.79s\tremaining: 1.58s\n",
      "831:\tlearn: 531185.8088658\ttotal: 7.8s\tremaining: 1.57s\n",
      "832:\tlearn: 531167.0990719\ttotal: 7.81s\tremaining: 1.56s\n",
      "833:\tlearn: 531146.4729693\ttotal: 7.82s\tremaining: 1.55s\n",
      "834:\tlearn: 531117.5261200\ttotal: 7.82s\tremaining: 1.54s\n",
      "835:\tlearn: 531084.0768522\ttotal: 7.83s\tremaining: 1.54s\n",
      "836:\tlearn: 531076.5888248\ttotal: 7.84s\tremaining: 1.53s\n",
      "837:\tlearn: 531065.9499772\ttotal: 7.85s\tremaining: 1.52s\n",
      "838:\tlearn: 531052.2042453\ttotal: 7.85s\tremaining: 1.51s\n",
      "839:\tlearn: 531037.6249566\ttotal: 7.87s\tremaining: 1.5s\n",
      "840:\tlearn: 531027.3899691\ttotal: 7.88s\tremaining: 1.49s\n",
      "841:\tlearn: 531016.6296456\ttotal: 7.88s\tremaining: 1.48s\n",
      "842:\tlearn: 530992.9863747\ttotal: 7.89s\tremaining: 1.47s\n",
      "843:\tlearn: 530973.4618712\ttotal: 7.91s\tremaining: 1.46s\n",
      "844:\tlearn: 530966.9723447\ttotal: 7.92s\tremaining: 1.45s\n",
      "845:\tlearn: 530943.0644883\ttotal: 7.93s\tremaining: 1.44s\n",
      "846:\tlearn: 530929.3918143\ttotal: 7.93s\tremaining: 1.43s\n",
      "847:\tlearn: 530919.0144492\ttotal: 7.94s\tremaining: 1.42s\n",
      "848:\tlearn: 530909.1413563\ttotal: 7.95s\tremaining: 1.41s\n",
      "849:\tlearn: 530892.4257910\ttotal: 7.96s\tremaining: 1.4s\n",
      "850:\tlearn: 530889.3435423\ttotal: 7.97s\tremaining: 1.39s\n",
      "851:\tlearn: 530867.4088745\ttotal: 7.97s\tremaining: 1.38s\n",
      "852:\tlearn: 530852.3965812\ttotal: 7.98s\tremaining: 1.38s\n",
      "853:\tlearn: 530833.9759113\ttotal: 7.99s\tremaining: 1.37s\n",
      "854:\tlearn: 530829.3395920\ttotal: 8s\tremaining: 1.36s\n",
      "855:\tlearn: 530817.6650002\ttotal: 8.01s\tremaining: 1.35s\n",
      "856:\tlearn: 530802.5581057\ttotal: 8.02s\tremaining: 1.34s\n",
      "857:\tlearn: 530797.2898284\ttotal: 8.03s\tremaining: 1.33s\n",
      "858:\tlearn: 530785.1842706\ttotal: 8.04s\tremaining: 1.32s\n",
      "859:\tlearn: 530771.4352805\ttotal: 8.05s\tremaining: 1.31s\n",
      "860:\tlearn: 530762.2690066\ttotal: 8.06s\tremaining: 1.3s\n",
      "861:\tlearn: 530745.7204721\ttotal: 8.07s\tremaining: 1.29s\n",
      "862:\tlearn: 530742.6545280\ttotal: 8.07s\tremaining: 1.28s\n",
      "863:\tlearn: 530730.7444990\ttotal: 8.08s\tremaining: 1.27s\n",
      "864:\tlearn: 530714.6271207\ttotal: 8.09s\tremaining: 1.26s\n",
      "865:\tlearn: 530710.9075211\ttotal: 8.1s\tremaining: 1.25s\n",
      "866:\tlearn: 530674.1218294\ttotal: 8.11s\tremaining: 1.24s\n",
      "867:\tlearn: 530664.7327060\ttotal: 8.11s\tremaining: 1.23s\n",
      "868:\tlearn: 530634.2510638\ttotal: 8.13s\tremaining: 1.23s\n",
      "869:\tlearn: 530598.5393983\ttotal: 8.13s\tremaining: 1.22s\n",
      "870:\tlearn: 530582.6833607\ttotal: 8.14s\tremaining: 1.21s\n",
      "871:\tlearn: 530569.9863406\ttotal: 8.14s\tremaining: 1.2s\n",
      "872:\tlearn: 530548.4047221\ttotal: 8.16s\tremaining: 1.19s\n",
      "873:\tlearn: 530532.0360996\ttotal: 8.17s\tremaining: 1.18s\n",
      "874:\tlearn: 530499.2983884\ttotal: 8.17s\tremaining: 1.17s\n",
      "875:\tlearn: 530490.6383435\ttotal: 8.19s\tremaining: 1.16s\n",
      "876:\tlearn: 530478.8227033\ttotal: 8.2s\tremaining: 1.15s\n",
      "877:\tlearn: 530462.9605033\ttotal: 8.2s\tremaining: 1.14s\n",
      "878:\tlearn: 530434.2887896\ttotal: 8.21s\tremaining: 1.13s\n",
      "879:\tlearn: 530417.9306549\ttotal: 8.22s\tremaining: 1.12s\n",
      "880:\tlearn: 530406.7969604\ttotal: 8.23s\tremaining: 1.11s\n",
      "881:\tlearn: 530376.6543623\ttotal: 8.24s\tremaining: 1.1s\n",
      "882:\tlearn: 530373.4006058\ttotal: 8.25s\tremaining: 1.09s\n",
      "883:\tlearn: 530364.2558689\ttotal: 8.26s\tremaining: 1.08s\n",
      "884:\tlearn: 530346.4711191\ttotal: 8.27s\tremaining: 1.07s\n",
      "885:\tlearn: 530344.7782680\ttotal: 8.27s\tremaining: 1.06s\n",
      "886:\tlearn: 530337.5245976\ttotal: 8.28s\tremaining: 1.05s\n",
      "887:\tlearn: 530324.7484459\ttotal: 8.29s\tremaining: 1.04s\n",
      "888:\tlearn: 530314.7344979\ttotal: 8.3s\tremaining: 1.04s\n",
      "889:\tlearn: 530302.7829082\ttotal: 8.3s\tremaining: 1.03s\n",
      "890:\tlearn: 530292.1453582\ttotal: 8.31s\tremaining: 1.02s\n",
      "891:\tlearn: 530276.4599274\ttotal: 8.32s\tremaining: 1.01s\n",
      "892:\tlearn: 530260.3853486\ttotal: 8.33s\tremaining: 998ms\n",
      "893:\tlearn: 530232.4145166\ttotal: 8.33s\tremaining: 988ms\n",
      "894:\tlearn: 530222.5286896\ttotal: 8.34s\tremaining: 979ms\n",
      "895:\tlearn: 530218.0425878\ttotal: 8.35s\tremaining: 969ms\n",
      "896:\tlearn: 530212.2507443\ttotal: 8.36s\tremaining: 960ms\n",
      "897:\tlearn: 530203.1056713\ttotal: 8.37s\tremaining: 950ms\n",
      "898:\tlearn: 530176.4733858\ttotal: 8.37s\tremaining: 941ms\n",
      "899:\tlearn: 530165.5997482\ttotal: 8.39s\tremaining: 932ms\n",
      "900:\tlearn: 530157.0459153\ttotal: 8.39s\tremaining: 922ms\n",
      "901:\tlearn: 530148.6479090\ttotal: 8.4s\tremaining: 913ms\n",
      "902:\tlearn: 530144.5893522\ttotal: 8.42s\tremaining: 904ms\n",
      "903:\tlearn: 530128.8322395\ttotal: 8.43s\tremaining: 895ms\n",
      "904:\tlearn: 530118.8034462\ttotal: 8.43s\tremaining: 885ms\n",
      "905:\tlearn: 530095.0594040\ttotal: 8.44s\tremaining: 876ms\n",
      "906:\tlearn: 530091.9493247\ttotal: 8.45s\tremaining: 866ms\n",
      "907:\tlearn: 530079.6419076\ttotal: 8.45s\tremaining: 857ms\n",
      "908:\tlearn: 530070.8682416\ttotal: 8.46s\tremaining: 847ms\n",
      "909:\tlearn: 530054.9501685\ttotal: 8.47s\tremaining: 837ms\n",
      "910:\tlearn: 530042.8732684\ttotal: 8.48s\tremaining: 828ms\n",
      "911:\tlearn: 530028.8714020\ttotal: 8.49s\tremaining: 819ms\n",
      "912:\tlearn: 530024.4629273\ttotal: 8.49s\tremaining: 809ms\n",
      "913:\tlearn: 529999.8791015\ttotal: 8.5s\tremaining: 800ms\n",
      "914:\tlearn: 529987.2251453\ttotal: 8.51s\tremaining: 790ms\n",
      "915:\tlearn: 529979.3776970\ttotal: 8.52s\tremaining: 781ms\n",
      "916:\tlearn: 529974.7779184\ttotal: 8.52s\tremaining: 772ms\n",
      "917:\tlearn: 529965.9264154\ttotal: 8.53s\tremaining: 762ms\n",
      "918:\tlearn: 529940.2902169\ttotal: 8.54s\tremaining: 752ms\n",
      "919:\tlearn: 529924.8568936\ttotal: 8.54s\tremaining: 743ms\n",
      "920:\tlearn: 529897.9005923\ttotal: 8.55s\tremaining: 733ms\n",
      "921:\tlearn: 529871.8361748\ttotal: 8.55s\tremaining: 724ms\n",
      "922:\tlearn: 529859.6601562\ttotal: 8.56s\tremaining: 714ms\n",
      "923:\tlearn: 529836.4306954\ttotal: 8.57s\tremaining: 705ms\n",
      "924:\tlearn: 529831.9121141\ttotal: 8.58s\tremaining: 696ms\n",
      "925:\tlearn: 529819.2424053\ttotal: 8.59s\tremaining: 686ms\n",
      "926:\tlearn: 529817.3175757\ttotal: 8.6s\tremaining: 677ms\n",
      "927:\tlearn: 529796.2658061\ttotal: 8.61s\tremaining: 668ms\n",
      "928:\tlearn: 529789.1762227\ttotal: 8.62s\tremaining: 659ms\n",
      "929:\tlearn: 529786.2683625\ttotal: 8.63s\tremaining: 649ms\n",
      "930:\tlearn: 529781.9285582\ttotal: 8.64s\tremaining: 640ms\n",
      "931:\tlearn: 529774.9543277\ttotal: 8.65s\tremaining: 631ms\n",
      "932:\tlearn: 529764.9034623\ttotal: 8.65s\tremaining: 622ms\n",
      "933:\tlearn: 529762.5565157\ttotal: 8.67s\tremaining: 612ms\n",
      "934:\tlearn: 529759.0283705\ttotal: 8.68s\tremaining: 603ms\n",
      "935:\tlearn: 529751.2589614\ttotal: 8.69s\tremaining: 594ms\n",
      "936:\tlearn: 529748.9091980\ttotal: 8.69s\tremaining: 585ms\n",
      "937:\tlearn: 529743.5725221\ttotal: 8.71s\tremaining: 576ms\n",
      "938:\tlearn: 529739.5981413\ttotal: 8.72s\tremaining: 566ms\n",
      "939:\tlearn: 529735.1965252\ttotal: 8.72s\tremaining: 557ms\n",
      "940:\tlearn: 529717.2587856\ttotal: 8.73s\tremaining: 548ms\n",
      "941:\tlearn: 529708.0305685\ttotal: 8.74s\tremaining: 538ms\n",
      "942:\tlearn: 529701.3054876\ttotal: 8.75s\tremaining: 529ms\n",
      "943:\tlearn: 529699.7217787\ttotal: 8.75s\tremaining: 519ms\n",
      "944:\tlearn: 529687.3042603\ttotal: 8.76s\tremaining: 510ms\n",
      "945:\tlearn: 529680.4896554\ttotal: 8.78s\tremaining: 501ms\n",
      "946:\tlearn: 529675.7667368\ttotal: 8.78s\tremaining: 492ms\n",
      "947:\tlearn: 529672.9832873\ttotal: 8.79s\tremaining: 482ms\n",
      "948:\tlearn: 529656.5677057\ttotal: 8.8s\tremaining: 473ms\n",
      "949:\tlearn: 529641.2724959\ttotal: 8.81s\tremaining: 464ms\n",
      "950:\tlearn: 529635.2795483\ttotal: 8.82s\tremaining: 454ms\n",
      "951:\tlearn: 529608.5225756\ttotal: 8.83s\tremaining: 445ms\n",
      "952:\tlearn: 529604.4724448\ttotal: 8.84s\tremaining: 436ms\n",
      "953:\tlearn: 529588.5215734\ttotal: 8.85s\tremaining: 427ms\n",
      "954:\tlearn: 529582.8390831\ttotal: 8.85s\tremaining: 417ms\n",
      "955:\tlearn: 529567.7807094\ttotal: 8.86s\tremaining: 408ms\n",
      "956:\tlearn: 529557.2032861\ttotal: 8.87s\tremaining: 399ms\n",
      "957:\tlearn: 529553.7623419\ttotal: 8.88s\tremaining: 389ms\n",
      "958:\tlearn: 529547.4549363\ttotal: 8.89s\tremaining: 380ms\n",
      "959:\tlearn: 529536.3639682\ttotal: 8.9s\tremaining: 371ms\n",
      "960:\tlearn: 529524.9675144\ttotal: 8.9s\tremaining: 361ms\n",
      "961:\tlearn: 529504.8474067\ttotal: 8.91s\tremaining: 352ms\n",
      "962:\tlearn: 529496.2015693\ttotal: 8.92s\tremaining: 343ms\n",
      "963:\tlearn: 529487.9386037\ttotal: 8.93s\tremaining: 334ms\n",
      "964:\tlearn: 529480.3934920\ttotal: 8.94s\tremaining: 324ms\n",
      "965:\tlearn: 529451.8424050\ttotal: 8.94s\tremaining: 315ms\n",
      "966:\tlearn: 529448.7503910\ttotal: 8.95s\tremaining: 305ms\n",
      "967:\tlearn: 529432.4651851\ttotal: 8.96s\tremaining: 296ms\n",
      "968:\tlearn: 529426.6496044\ttotal: 8.97s\tremaining: 287ms\n",
      "969:\tlearn: 529400.8792482\ttotal: 8.98s\tremaining: 278ms\n",
      "970:\tlearn: 529376.6321658\ttotal: 8.99s\tremaining: 269ms\n",
      "971:\tlearn: 529373.6933886\ttotal: 9s\tremaining: 259ms\n",
      "972:\tlearn: 529366.2364418\ttotal: 9.01s\tremaining: 250ms\n",
      "973:\tlearn: 529357.8704182\ttotal: 9.02s\tremaining: 241ms\n",
      "974:\tlearn: 529333.3680333\ttotal: 9.03s\tremaining: 232ms\n",
      "975:\tlearn: 529303.1428644\ttotal: 9.04s\tremaining: 222ms\n",
      "976:\tlearn: 529282.0334225\ttotal: 9.04s\tremaining: 213ms\n",
      "977:\tlearn: 529262.1903459\ttotal: 9.05s\tremaining: 204ms\n",
      "978:\tlearn: 529247.1375620\ttotal: 9.06s\tremaining: 194ms\n",
      "979:\tlearn: 529219.3830402\ttotal: 9.06s\tremaining: 185ms\n",
      "980:\tlearn: 529202.0598633\ttotal: 9.07s\tremaining: 176ms\n",
      "981:\tlearn: 529179.5820859\ttotal: 9.08s\tremaining: 166ms\n",
      "982:\tlearn: 529159.7602313\ttotal: 9.09s\tremaining: 157ms\n",
      "983:\tlearn: 529131.1986259\ttotal: 9.1s\tremaining: 148ms\n",
      "984:\tlearn: 529116.4564090\ttotal: 9.11s\tremaining: 139ms\n",
      "985:\tlearn: 529070.5152446\ttotal: 9.11s\tremaining: 129ms\n",
      "986:\tlearn: 529050.5471742\ttotal: 9.12s\tremaining: 120ms\n",
      "987:\tlearn: 529003.8481520\ttotal: 9.13s\tremaining: 111ms\n",
      "988:\tlearn: 528979.5794261\ttotal: 9.13s\tremaining: 102ms\n",
      "989:\tlearn: 528966.3532105\ttotal: 9.14s\tremaining: 92.3ms\n",
      "990:\tlearn: 528953.7458182\ttotal: 9.15s\tremaining: 83.1ms\n",
      "991:\tlearn: 528926.9138342\ttotal: 9.16s\tremaining: 73.9ms\n",
      "992:\tlearn: 528923.5232840\ttotal: 9.17s\tremaining: 64.6ms\n",
      "993:\tlearn: 528920.1242214\ttotal: 9.17s\tremaining: 55.4ms\n",
      "994:\tlearn: 528911.4292062\ttotal: 9.19s\tremaining: 46.2ms\n",
      "995:\tlearn: 528907.3153512\ttotal: 9.19s\tremaining: 36.9ms\n",
      "996:\tlearn: 528904.6014399\ttotal: 9.2s\tremaining: 27.7ms\n",
      "997:\tlearn: 528896.2855713\ttotal: 9.22s\tremaining: 18.5ms\n",
      "998:\tlearn: 528870.2025877\ttotal: 9.22s\tremaining: 9.23ms\n",
      "999:\tlearn: 528866.0091614\ttotal: 9.23s\tremaining: 0us\n",
      "meta 0.13552640766121854\n"
     ]
    }
   ],
   "source": [
    "estimators = (\n",
    "    (\"lr\", lr),\n",
    "    (\"knn\", knn),\n",
    "    (\"lightgbm\", lightgbm),\n",
    "    (\"catboost\", catboost),\n",
    "    (\"rf\", rf),\n",
    ")\n",
    "\n",
    "meta = StackingRegressor(estimators=estimators, final_estimator=CatBoostRegressor(), n_jobs=-1)\n",
    "meta.fit(X_train, y_train)\n",
    "\n",
    "print(\"meta\", mean_absolute_percentage_error(y_valid, meta.predict(X_valid)))\n",
    "submit(test, meta, \"meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[next tile - models with pre-tuned parameters and ensembles](2022-04-15_ensemble.ipynb)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "326a131e1315163df5847284d7bac20ddee532ca1eaccb72a712d33a5c79e104"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
